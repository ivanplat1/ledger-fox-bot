import asyncio
import base64
import csv
import hashlib
import io
import json
import logging
import mimetypes
import os
import re
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

import cv2
import numpy as np
from aiogram import Bot, Dispatcher, F, Router
from aiogram.filters import Command, CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import BufferedInputFile, Message, CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton, BotCommand
from dotenv import load_dotenv
import requests

try:
    import pdfplumber
    PDF_SUPPORT = True
except ModuleNotFoundError:  # pragma: no cover - import guard
    pdfplumber = None  # type: ignore
    PDF_SUPPORT = False

try:
    import pytesseract
    from pytesseract import Output
    from PIL import Image, ImageOps, ImageFilter, ImageDraw, ImageFont
    TESSERACT_AVAILABLE = True
except ModuleNotFoundError:  # pragma: no cover - import guard
    pytesseract = None  # type: ignore
    Output = None  # type: ignore
    Image = None  # type: ignore
    ImageOps = None  # type: ignore
    ImageFilter = None  # type: ignore
    TESSERACT_AVAILABLE = False

try:
    from pillow_heif import read_heif
    HEIF_SUPPORT = True
except ModuleNotFoundError:  # pragma: no cover - import guard
    read_heif = None  # type: ignore
    HEIF_SUPPORT = False

try:
    from supabase import Client, create_client
    SUPABASE_AVAILABLE = True
except ModuleNotFoundError:  # pragma: no cover - import guard
    Client = Any  # type: ignore
    create_client = None  # type: ignore
    SUPABASE_AVAILABLE = False

try:
    from deep_translator import GoogleTranslator
    TRANSLATION_AVAILABLE = True
except ModuleNotFoundError:  # pragma: no cover - import guard
    GoogleTranslator = None  # type: ignore
    TRANSLATION_AVAILABLE = False

try:
    from paddleocr import PaddleOCR
    PADDLEOCR_AVAILABLE = True
except ModuleNotFoundError:  # pragma: no cover - import guard
    PaddleOCR = None  # type: ignore
    PADDLEOCR_AVAILABLE = False

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–∏ –∫ zbar –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –¥–ª—è macOS
if os.name == "posix" and os.path.exists("/opt/homebrew/lib/libzbar.dylib"):
    os.environ.setdefault("DYLD_LIBRARY_PATH", "/opt/homebrew/lib")

try:
    from pyzbar.pyzbar import decode as pyzbar_decode
    QR_READER_AVAILABLE = True
except (ModuleNotFoundError, ImportError, OSError):  # pragma: no cover - import guard
    # ImportError –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –µ—Å–ª–∏ zbar –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–Ω–æ
    pyzbar_decode = None  # type: ignore
    QR_READER_AVAILABLE = False
    logging.warning("pyzbar –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ zbar: brew install zbar –Ω–∞ macOS)")

try:
    from qreader import QReader
    QREADER_AVAILABLE = True
    qreader_instance = QReader()
except (ModuleNotFoundError, ImportError):  # pragma: no cover - import guard
    QReader = None  # type: ignore
    qreader_instance = None  # type: ignore
    QREADER_AVAILABLE = False
    logging.warning("qreader –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install qreader)")


load_dotenv()
log_level_name = os.getenv("LEDGERFOX_LOG_LEVEL", "INFO").upper()
log_level = getattr(logging, log_level_name, logging.INFO)
logging.basicConfig(level=log_level, format="%(asctime)s %(levelname)s %(message)s")
log_dir = Path(os.getenv("LEDGERFOX_LOG_DIR", "logs"))
log_dir.mkdir(parents=True, exist_ok=True)
file_handler = logging.FileHandler(log_dir / "ocr_debug.log")
file_handler.setLevel(log_level)
file_handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
logging.getLogger().addHandler(file_handler)
logging.info("LedgerFox logging configured at %s", log_level_name)
logging.info("Active preprocess pipeline hash marker: portrait-fix-v3")


class ReceiptStates(StatesGroup):
    waiting_for_photo = State()
    waiting_for_confirmation = State()


class StatementStates(StatesGroup):
    waiting_for_statement = State()


class DeleteStates(StatesGroup):
    waiting_for_confirmation = State()


@dataclass
class ParsedReceiptItem:
    name: str
    quantity: float
    price: float
    category: Optional[str] = None


@dataclass
class ParsedReceipt:
    store: str
    total: float
    currency: str
    purchased_at: datetime
    tax_amount: Optional[float]
    items: List[ParsedReceiptItem]
    merchant_address: Optional[str] = None
    external_id: Optional[str] = None


@dataclass
class ParsedBankTransaction:
    amount: float
    currency: str
    merchant: str
    booked_at: datetime
    description: str
    source_id: str


@dataclass
class ParsedManualExpense:
    store: str
    amount: float
    currency: str
    occurred_at: datetime
    note: Optional[str] = None


@dataclass
class ProcessingResult:
    success: bool
    summary: Optional[str] = None
    error: Optional[str] = None
    parsed_receipt: Optional[ParsedReceipt] = None
    receipt_payload: Optional[Dict[str, Any]] = None


@dataclass
class Snapshot:
    step: str
    pil_image: "Image.Image"
    description: str


@dataclass
class Snapshot:
    step: str
    pil_image: "Image.Image"
    description: str


# –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —á–µ–∫–∞ (–æ–±—â–∏–π –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ URL)
RECEIPT_BASE_PROMPT = (
    "–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π: "
    "{\"store\": str, \"merchant_address\": str | null, "
    "\"purchased_at\": iso8601 datetime (UTC –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–∞—è –∑–æ–Ω–∞), \"currency\": ISO4217, "
    "\"total\": float, \"tax_amount\": float | null, "
    "\"items\": [{\"name\": str, \"quantity\": float, \"price\": float, \"category\": str | null}]}."
    "\n\n–í–ê–ñ–ù–û: "
    "- \"quantity\" - —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2, 3, 1.5)"
    "- \"price\" - —ç—Ç–æ –û–ë–©–ê–Ø —Å—É–º–º–∞ –∑–∞ –ø–æ–∑–∏—Ü–∏—é (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ √ó —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É), –∞ –Ω–µ —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É"
    "- –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –æ–ø—Ä–µ–¥–µ–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è. "
    "–ò—Å–ø–æ–ª—å–∑—É–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: \"–ü—Ä–æ–¥—É–∫—Ç—ã\", \"–ú—è—Å–æ/–†—ã–±–∞\", \"–ú–æ–ª–æ—á–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã\", \"–•–ª–µ–±/–í—ã–ø–µ—á–∫–∞\", "
    "\"–û–≤–æ—â–∏/–§—Ä—É–∫—Ç—ã\", \"–ù–∞–ø–∏—Ç–∫–∏\", \"–ê–ª–∫–æ–≥–æ–ª—å\", \"–°–ª–∞–¥–æ—Å—Ç–∏\", \"–û–¥–µ–∂–¥–∞\", \"–û–±—É–≤—å\", "
    "\"–ë—ã—Ç–æ–≤–∞—è —Ö–∏–º–∏—è\", \"–ö–æ—Å–º–µ—Ç–∏–∫–∞/–ì–∏–≥–∏–µ–Ω–∞\", \"–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞\", \"–¢–µ—Ö–Ω–∏–∫–∞\", \"–ú–µ–±–µ–ª—å\", "
    "\"–†–µ—Å—Ç–æ—Ä–∞–Ω/–ö–∞—Ñ–µ\", \"–î–æ—Å—Ç–∞–≤–∫–∞ –µ–¥—ã\", \"–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç\", \"–¢–∞–∫—Å–∏\", \"–ü–∞—Ä–∫–æ–≤–∫–∞\", "
    "\"–ó–¥–æ—Ä–æ–≤—å–µ\", \"–ú–µ–¥–∏—Ü–∏–Ω–∞\", \"–ê–ø—Ç–µ–∫–∞\", \"–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\", \"–ö–Ω–∏–≥–∏\", "
    "\"–†–∞–∑–≤–ª–µ—á–µ–Ω–∏—è\", \"–ö–∏–Ω–æ\", \"–°–ø–æ—Ä—Ç\", \"–§–∏—Ç–Ω–µ—Å\", \"–ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è\", "
    "\"–û—Ç–µ–ª—å\", \"–ö–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ\", \"–ò–Ω—Ç–µ—Ä–Ω–µ—Ç/–°–≤—è–∑—å\", \"–ü–æ–¥–ø–∏—Å–∫–∏\", \"–î—Ä—É–≥–æ–µ\". "
    "–ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –æ—á–µ–≤–∏–¥–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–π \"–î—Ä—É–≥–æ–µ\"."
)

RECEIPT_EXTRACTION_PROMPT = os.getenv(
    "RECEIPT_OCR_PROMPT",
    f"–¢—ã –∏–∑–≤–ª–µ–∫–∞–µ—à—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–æ—Ç–æ –∫–∞—Å—Å–æ–≤—ã—Ö —á–µ–∫–æ–≤. {RECEIPT_BASE_PROMPT}",
).strip()

RECEIPT_DATA_STRUCTURING_PROMPT = os.getenv(
    "RECEIPT_DATA_PROMPT",
    f"–¢—ã –ø–æ–ª—É—á–∞–µ—à—å –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏ —É–ª—É—á—à–∏ —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ, –æ–ø—Ä–µ–¥–µ–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤. {RECEIPT_BASE_PROMPT}",
).strip()
RECEIPT_MODEL = os.getenv("RECEIPT_OCR_MODEL", "gpt-4o").strip()
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1").rstrip("/")
RECEIPT_TEMPERATURE = float(os.getenv("RECEIPT_OCR_TEMPERATURE", "0.1"))
DEFAULT_RECEIPT_TIMEOUT = int(os.getenv("RECEIPT_OCR_TIMEOUT", "120"))
RECEIPT_PIPELINE_MODE = os.getenv("RECEIPT_PIPELINE_MODE", "text").strip().lower()
USE_OPENAI_FOR_RECEIPTS = RECEIPT_PIPELINE_MODE == "ai"
RECEIPT_FALLBACK_LANG = os.getenv("RECEIPT_FALLBACK_LANG", "rus+kaz+eng").strip() or "rus+kaz+eng"
TESSERACT_CONFIG = os.getenv("TESSERACT_CONFIG", "--oem 3 --psm 6").strip()
# –ú–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —É–≥–ª–æ–≤: "brightness" (–∞–Ω–∞–ª–∏–∑ —è—Ä–∫–æ—Å—Ç–∏), "contour" (–∫–æ–Ω—Ç—É—Ä—ã), "text" (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏)
CORNER_DETECTION_METHOD = os.getenv("CORNER_DETECTION_METHOD", "brightness").strip().lower()
# OCR –¥–≤–∏–∂–æ–∫: "tesseract", "paddleocr" –∏–ª–∏ "both" (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ–±–æ–∏—Ö)
OCR_ENGINE = os.getenv("OCR_ENGINE", "both").strip().lower()

_receipt_parser: Optional["ReceiptParserAI"] = None
_paddleocr_instance: Optional[Any] = None


def get_paddleocr_instance():
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä PaddleOCR (–ª–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)."""
    global _paddleocr_instance
    if not PADDLEOCR_AVAILABLE or PaddleOCR is None:
        return None
    if _paddleocr_instance is None:
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π, –∫–∞–∑–∞—Ö—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
            # –ü—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –∫–∏—Ç–∞–π—Å–∫—É—é –º–æ–¥–µ–ª—å (–º–Ω–æ–≥–æ—è–∑—ã—á–Ω—É—é), –æ–Ω–∞ –±–æ–ª–µ–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è
            logging.info("Initializing PaddleOCR...")
            try:
                _paddleocr_instance = PaddleOCR(
                    use_angle_cls=True,
                    lang='ch',  # –ö–∏—Ç–∞–π—Å–∫–∞—è –º–æ–¥–µ–ª—å –≤–∫–ª—é—á–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∏ –¥—Ä—É–≥–∏–µ —è–∑—ã–∫–∏
                    use_gpu=False,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU, –º–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                    show_log=False
                )
                logging.info("PaddleOCR initialized with Chinese (multilingual) model")
            except Exception as exc_ch:
                logging.warning(f"Failed to initialize PaddleOCR with 'ch' model: {exc_ch}, trying 'ru'...")
                try:
                    _paddleocr_instance = PaddleOCR(
                        use_angle_cls=True,
                        lang='ru',  # –†—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å
                        use_gpu=False,
                        show_log=False
                    )
                    logging.info("PaddleOCR initialized with Russian model")
                except Exception as exc_ru:
                    logging.error(f"Failed to initialize PaddleOCR with 'ru' model: {exc_ru}")
                    # –ü—Ä–æ–±—É–µ–º –±–µ–∑ use_angle_cls
                    try:
                        _paddleocr_instance = PaddleOCR(
                            use_angle_cls=False,
                            lang='ch',
                            use_gpu=False,
                            show_log=False
                        )
                        logging.info("PaddleOCR initialized without angle classification")
                    except Exception as exc_no_cls:
                        logging.error(f"Failed to initialize PaddleOCR without cls: {exc_no_cls}")
                        raise exc_no_cls
            logging.info("PaddleOCR initialized successfully")
        except Exception as exc:
            logging.error(f"Failed to initialize PaddleOCR: {exc}")
            return None
    return _paddleocr_instance


class ReceiptParsingError(RuntimeError):
    """Raised when AI receipt parsing fails."""


class StatementParsingError(RuntimeError):
    """Raised when bank statement parsing fails."""


class ReceiptParserAI:
    """Minimal wrapper around OpenAI Chat Completions for receipt extraction."""

    def __init__(
        self,
        api_key: str,
        model: str = RECEIPT_MODEL,
        base_url: str = OPENAI_BASE_URL,
        prompt: str = RECEIPT_EXTRACTION_PROMPT,
        data_prompt: str = RECEIPT_DATA_STRUCTURING_PROMPT,
        temperature: float = RECEIPT_TEMPERATURE,
        timeout: int = DEFAULT_RECEIPT_TIMEOUT,
    ) -> None:
        if not api_key:
            raise ReceiptParsingError("OPENAI_API_KEY is required for receipt parsing.")
        self.api_key = api_key
        self.model = model
        self.base_url = base_url.rstrip("/")
        self.prompt = prompt
        self.data_prompt = data_prompt
        self.temperature = temperature
        self.timeout = timeout
        self._session = requests.Session()

    async def parse(
        self, 
        file_bytes: bytes, 
        mime_type: str, 
        qr_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ OpenAI –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π JSON response –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
        –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω qr_data, –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è (–±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è).
        """
        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ QR-–∫–æ–¥–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        if qr_data:
            logging.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ QR-–∫–æ–¥–∞ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è")
            payload = self._build_payload("", qr_data=qr_data)
        else:
            if not mime_type.startswith("image/"):
                raise ReceiptParsingError("–ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–∫–æ–≤.")
            data_url = build_data_url(file_bytes, mime_type)
            payload = self._build_payload(data_url)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –≤ OpenAI
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é payload –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–º data_url –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        payload_for_log = json.loads(json.dumps(payload))
        if "messages" in payload_for_log:
            for msg in payload_for_log["messages"]:
                if "content" in msg and isinstance(msg["content"], list):
                    for content_item in msg["content"]:
                        if content_item.get("type") == "image_url" and "image_url" in content_item:
                            url = content_item["image_url"].get("url", "")
                            if len(url) > 100:
                                content_item["image_url"]["url"] = url[:100] + f"... (truncated, total length: {len(url)})"
        
        logging.info(f"OpenAI request payload: {json.dumps(payload_for_log, ensure_ascii=False, indent=2)}")
        logging.info(f"System prompt length: {len(self.prompt)} chars, prompt_cache_key: {payload.get('prompt_cache_key', 'not set')}")
        
        response_json = await asyncio.to_thread(self._post_payload, payload)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤–µ—Å—å body –æ—Ç–≤–µ—Ç–∞
        logging.info(f"OpenAI full response body: {json.dumps(response_json, ensure_ascii=False, indent=2)}")
        
        return response_json

    async def improve_receipt_data(self, receipt_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –£–ª—É—á—à–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ —á–µ—Ä–µ–∑ OpenAI –±–µ–∑ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ QR-–∫–æ–¥–∞, –Ω–æ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
        """
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        improvement_prompt = (
            "–¢—ã —É–ª—É—á—à–∞–µ—à—å –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –±—ã–ª–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ QR-–∫–æ–¥–∞. "
            "–í–µ—Ä–Ω–∏ —É–ª—É—á—à–µ–Ω–Ω—ã–π JSON –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π: "
            '{"store": str, "merchant_address": str | null, '
            '"purchased_at": iso8601 datetime, "currency": ISO4217, '
            '"total": float, "tax_amount": float | null, '
            '"items": [{"name": str, "quantity": float, "price": float, "category": str | null}]}. '
            "–£–ª—É—á—à–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π. "
            "–ò—Å–ø–æ–ª—å–∑—É–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: \"–ü—Ä–æ–¥—É–∫—Ç—ã\", \"–ú—è—Å–æ/–†—ã–±–∞\", \"–ú–æ–ª–æ—á–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã\", \"–•–ª–µ–±/–í—ã–ø–µ—á–∫–∞\", "
            "\"–û–≤–æ—â–∏/–§—Ä—É–∫—Ç—ã\", \"–ù–∞–ø–∏—Ç–∫–∏\", \"–ê–ª–∫–æ–≥–æ–ª—å\", \"–°–ª–∞–¥–æ—Å—Ç–∏\", \"–û–¥–µ–∂–¥–∞\", \"–û–±—É–≤—å\", "
            "\"–ë—ã—Ç–æ–≤–∞—è —Ö–∏–º–∏—è\", \"–ö–æ—Å–º–µ—Ç–∏–∫–∞/–ì–∏–≥–∏–µ–Ω–∞\", \"–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞\", \"–¢–µ—Ö–Ω–∏–∫–∞\", \"–ú–µ–±–µ–ª—å\", "
            "\"–†–µ—Å—Ç–æ—Ä–∞–Ω/–ö–∞—Ñ–µ\", \"–î–æ—Å—Ç–∞–≤–∫–∞ –µ–¥—ã\", \"–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç\", \"–¢–∞–∫—Å–∏\", \"–ü–∞—Ä–∫–æ–≤–∫–∞\", "
            "\"–ó–¥–æ—Ä–æ–≤—å–µ\", \"–ú–µ–¥–∏—Ü–∏–Ω–∞\", \"–ê–ø—Ç–µ–∫–∞\", \"–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\", \"–ö–Ω–∏–≥–∏\", "
            "\"–†–∞–∑–≤–ª–µ—á–µ–Ω–∏—è\", \"–ö–∏–Ω–æ\", \"–°–ø–æ—Ä—Ç\", \"–§–∏—Ç–Ω–µ—Å\", \"–ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è\", "
            "\"–û—Ç–µ–ª—å\", \"–ö–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ\", \"–ò–Ω—Ç–µ—Ä–Ω–µ—Ç/–°–≤—è–∑—å\", \"–ü–æ–¥–ø–∏—Å–∫–∏\", \"–î—Ä—É–≥–æ–µ\". "
            "–ò—Å–ø—Ä–∞–≤—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã. "
            "–°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, —Ç–æ–ª—å–∫–æ —É–ª—É—á—à–∏ –∏—Ö."
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –¥–∞–Ω–Ω—ã–º–∏ —á–µ–∫–∞
        receipt_json = json.dumps(receipt_data, ensure_ascii=False, indent=2)
        user_message = f"–£–ª—É—á—à–∏ –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞:\n\n{receipt_json}"
        
        payload = {
            "model": self.model,
            "response_format": {"type": "json_object"},
            "temperature": self.temperature,
            "messages": [
                {
                    "role": "system",
                    "content": improvement_prompt,
                },
                {
                    "role": "user",
                    "content": user_message,
                },
            ],
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º prompt_cache_key
        import hashlib
        prompt_hash = hashlib.md5(improvement_prompt.encode()).hexdigest()[:16]
        payload["prompt_cache_key"] = f"receipt_improve_{prompt_hash}"
        
        logging.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ –≤ OpenAI –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è (–±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)")
        logging.info(f"OpenAI improvement request payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        response_json = await asyncio.to_thread(self._post_payload, payload)
        
        logging.info(f"OpenAI improvement response: {json.dumps(response_json, ensure_ascii=False, indent=2)}")
        
        return response_json

    def _build_payload(
        self, 
        data_url: str, 
        qr_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        # OpenAI –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫—ç—à–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã >= 1024 —Ç–æ–∫–µ–Ω–æ–≤
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        # –†–∞–∑–Ω–∏—Ü–∞ —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ –ø—Ä–æ–º–ø—Ç–∞ (–ø—Ä–æ —Ñ–æ—Ç–æ –∏–ª–∏ –ø—Ä–æ URL), –æ—Å—Ç–∞–ª—å–Ω–æ–µ –æ–¥–∏–Ω–∞–∫–æ–≤–æ
        
        import hashlib
        import json
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ QR-–∫–æ–¥–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        if qr_data is not None:
            user_text = f"–í–æ—Ç –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã:\n\n{json.dumps(qr_data, ensure_ascii=False, indent=2)}\n\n–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –∏ –≤–µ—Ä–Ω–∏ JSON —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ —Ç–æ–≤–∞—Ä–æ–≤."
            logging.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ QR-–∫–æ–¥–∞ –≤ OpenAI –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            system_prompt = self.data_prompt
            payload = {
                "model": self.model,
                "response_format": {"type": "json_object"},
                "temperature": self.temperature,
                "messages": [
                    {
                        "role": "system",
                        "content": system_prompt,
                    },
                    {
                        "role": "user",
                        "content": user_text,
                    },
                ],
            }
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç URL, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –æ–±—ã—á–Ω–æ
            user_text = "–ò–∑–≤–ª–µ–∫–∏ –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ –∏ –≤–µ—Ä–Ω–∏ JSON."
            system_prompt = self.prompt
            payload = {
                "model": self.model,
                "response_format": {"type": "json_object"},
                "temperature": self.temperature,
                "messages": [
                    {
                        "role": "system",
                        "content": system_prompt,
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": user_text,
                            },
                            {
                                "type": "image_url",
                                "image_url": {"url": data_url},
                            },
                        ],
                    },
                ],
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º prompt_cache_key –¥–ª—è –ª—É—á—à–µ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–µ—à —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∫–∞–∫ –∫–ª—é—á –∫—ç—à–∞
        # –û–±–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –±–∞–∑–æ–≤—É—é —á–∞—Å—Ç—å (RECEIPT_BASE_PROMPT), —á—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
        prompt_hash = hashlib.md5(system_prompt.encode()).hexdigest()[:16]
        payload["prompt_cache_key"] = f"receipt_{prompt_hash}"
        
        return payload

    def _post_payload(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        # –õ–æ–≥–∏—Ä—É–µ–º URL –∏ headers (–±–µ–∑ API –∫–ª—é—á–∞)
        headers_for_log = {k: (v[:20] + "..." if k == "Authorization" else v) for k, v in headers.items()}
        logging.info(f"OpenAI request URL: {url}")
        logging.info(f"OpenAI request headers: {json.dumps(headers_for_log, ensure_ascii=False)}")
        resp = self._session.post(url, headers=headers, json=payload, timeout=self.timeout)
        if resp.status_code >= 400:
            raise ReceiptParsingError(
                f"OpenAI error {resp.status_code}: {resp.text[:500]}"
            )
        return resp.json()


class SupabaseGateway:
    """Async helper around Supabase client used by LedgerFox."""
    # TODO: –¥–æ–±–∞–≤–∏—Ç—å —Ç–∞–±–ª–∏—Ü—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –±—é–¥–∂–µ—Ç–æ–≤ –∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –ø–ª–∞—Ç–µ–∂–µ–π.

    def __init__(
        self,
        url: str,
        service_key: str,
        receipts_table: str = "receipts",
        bank_table: str = "bank_transactions",
        expenses_table: str = "expenses",
    ) -> None:
        if not SUPABASE_AVAILABLE or create_client is None:
            raise RuntimeError("Supabase client is not installed. Run `pip install supabase`.")
        self._client: Client = create_client(url, service_key)
        self.receipts_table = receipts_table
        self.bank_table = bank_table
        self.expenses_table = expenses_table

    async def check_receipt_exists(self, receipt_hash: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —á–µ–∫ —Å –¥–∞–Ω–Ω—ã–º —Ö–µ—à–µ–º."""
        try:
            result = await asyncio.to_thread(
                lambda: self._client.table(self.receipts_table)
                .select("id")
                .eq("receipt_hash", receipt_hash)
                .limit(1)
                .execute()
            )
            return len(result.data) > 0 if result.data else False
        except Exception as exc:
            logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–∞ —á–µ–∫–∞: {exc}")
            return False

    async def upsert_receipt(self, payload: Dict[str, Any]) -> tuple[Dict[str, Any], bool]:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —á–µ–∫ –≤ –±–∞–∑–µ.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞, is_duplicate) –≥–¥–µ is_duplicate=True –µ—Å–ª–∏ —á–µ–∫ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª.
        """
        receipt_hash = payload.get("receipt_hash")
        logging.info("Upserting receipt %s", receipt_hash)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —á–µ–∫
        is_duplicate = await self.check_receipt_exists(receipt_hash)
        
        stored_receipt = await asyncio.to_thread(
            self._table_upsert,
            self.receipts_table,
            payload,
            on_conflict="receipt_hash",
        )
        
        return stored_receipt, is_duplicate

    async def upsert_bank_transactions(self, payloads: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        if not payloads:
            return []
        logging.info("Upserting %d bank transactions", len(payloads))
        return await asyncio.to_thread(
            self._table_upsert_many,
            self.bank_table,
            payloads,
            "transaction_hash",
        )

    async def check_duplicate_expense(self, user_id: int, date: str, amount: float, currency: str, tolerance_days: int = 1, tolerance_percent: float = 0.01) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ä–∞—Å—Ö–æ–¥ —Å –ø–æ—Ö–æ–∂–µ–π –¥–∞—Ç–æ–π –∏ —Å—É–º–º–æ–π.
        tolerance_days - –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ –¥–∞—Ç–µ (–¥–Ω–∏)
        tolerance_percent - –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ —Å—É–º–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.01 = 1%)
        """
        try:
            # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É (–º–æ–∂–µ—Ç –±—ã—Ç—å ISO —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –¥–∞—Ç–∞)
            try:
                if 'T' in date or '+' in date or 'Z' in date:
                    date_obj = datetime.fromisoformat(date.replace('Z', '+00:00'))
                else:
                    # –ü—Ä–æ—Å—Ç–æ –¥–∞—Ç–∞ –±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏
                    date_obj = datetime.fromisoformat(date)
            except (ValueError, AttributeError):
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç
                try:
                    date_obj = datetime.strptime(date[:10], "%Y-%m-%d")
                except:
                    logging.warning(f"Could not parse date: {date}")
                    return False
            
            date_center = date_obj.date() if hasattr(date_obj, 'date') else date_obj
            date_start = date_center - timedelta(days=tolerance_days)
            date_end = date_center + timedelta(days=tolerance_days)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å—É–º–º
            amount_min = amount * (1 - tolerance_percent)
            amount_max = amount * (1 + tolerance_percent)
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ä–∞—Å—Ö–æ–¥—ã (–ø–æ –¥–∞—Ç–µ –∏ —Å—É–º–º–µ)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º gte/lte –¥–ª—è –¥–∞—Ç—ã –∏ —Å—É–º–º—ã
            result = (
                self._client.table(self.expenses_table)
                .select("id,date,amount,currency,source")
                .eq("user_id", user_id)
                .eq("currency", currency)
                .gte("amount", amount_min)
                .lte("amount", amount_max)
                .gte("date", date_start.isoformat())
                .lte("date", date_end.isoformat())
                .execute()
            )
            
            if result.data:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ä–∞—Å—Ö–æ–¥
                for existing in result.data:
                    existing_date_str = existing.get("date", "")
                    existing_amount = existing.get("amount", 0.0)
                    existing_source = existing.get("source", "")
                    
                    if not existing_date_str or not existing_amount:
                        continue
                    
                    try:
                        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ä–∞—Å—Ö–æ–¥–∞
                        if 'T' in existing_date_str or '+' in existing_date_str or 'Z' in existing_date_str:
                            existing_date_obj = datetime.fromisoformat(existing_date_str.replace('Z', '+00:00'))
                        else:
                            existing_date_obj = datetime.fromisoformat(existing_date_str)
                        
                        existing_date = existing_date_obj.date() if hasattr(existing_date_obj, 'date') else existing_date_obj
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞—Ç–∞ –∏ —Å—É–º–º–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–æ–ø—É—Å–∫–∞
                        if date_start <= existing_date <= date_end and amount_min <= existing_amount <= amount_max:
                            logging.info(
                                f"Found duplicate expense: existing={existing_source} date={existing_date_str} amount={existing_amount}, "
                                f"new date={date} amount={amount}"
                            )
                            return True
                    except Exception as e:
                        logging.debug(f"Error parsing existing date {existing_date_str}: {e}")
                        continue
            
            return False
        except Exception as exc:
            logging.exception(f"Error checking duplicate expense: {exc}")
            return False

    async def record_expense(self, payload: Dict[str, Any], check_duplicates: bool = True) -> Dict[str, Any]:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—Ö–æ–¥ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
        check_duplicates - –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –¥–∞—Ç–µ –∏ —Å—É–º–º–µ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º.
        """
        user_id = payload.get("user_id")
        date = payload.get("date")
        amount = payload.get("amount")
        currency = payload.get("currency")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if check_duplicates and user_id and date and amount and currency:
            is_duplicate = await self.check_duplicate_expense(user_id, date, amount, currency)
            if is_duplicate:
                logging.info(
                    f"Skipping duplicate expense: user={user_id} date={date} amount={amount} {currency}"
                )
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ None, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∑–∞–ø–∏—Å—å –Ω–µ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞
                return {"duplicate": True}
        
        logging.info(
            "Recording expense user=%s source=%s",
            payload.get("user_id"),
            payload.get("source"),
        )
        return await asyncio.to_thread(
            self._table_upsert,
            self.expenses_table,
            payload,
            on_conflict="expense_hash",
        )

    async def fetch_monthly_report(self, user_id: int, period: str) -> Dict[str, Any]:
        logging.info("Fetching report for user=%s period=%s", user_id, period)
        return await asyncio.to_thread(
            self._fetch_report_sync,
            user_id,
            period,
        )

    async def export_expenses_csv(self, user_id: int, period: Optional[str]) -> str:
        logging.info("Exporting expenses for user=%s period=%s", user_id, period or "all")
        return await asyncio.to_thread(
            self._export_expenses_csv_sync,
            user_id,
            period,
        )

    async def delete_all_user_data(self, user_id: int) -> Dict[str, int]:
        """
        –£–¥–∞–ª—è–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º.
        """
        logging.warning(f"Deleting all data for user={user_id}")
        return await asyncio.to_thread(
            self._delete_all_user_data_sync,
            user_id,
        )

    def _table_upsert(self, table: str, payload: Dict[str, Any], on_conflict: str) -> Dict[str, Any]:
        try:
            result = (
                self._client.table(table)
                .upsert(payload, on_conflict=on_conflict, returning="representation")
                .execute()
            )
            if result.data and len(result.data) > 0:
                logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {table}: {result.data[0].get('id')}")
                return result.data[0]
            else:
                logging.warning(f"‚ö†Ô∏è Supabase –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {table}, –∏—Å–ø–æ–ª—å–∑—É–µ–º payload")
                return payload
        except Exception as exc:
            # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–π –∫–æ–ª–æ–Ω–∫–æ–π category, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –Ω–µ—ë
            error_str = str(exc)
            if "category" in error_str.lower() and "column" in error_str.lower():
                logging.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'category' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ {table}, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –Ω–µ—ë")
                payload_without_category = {k: v for k, v in payload.items() if k != "category"}
                try:
                    result = (
                        self._client.table(table)
                        .upsert(payload_without_category, on_conflict=on_conflict, returning="representation")
                        .execute()
                    )
                    if result.data and len(result.data) > 0:
                        logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {table} (–±–µ–∑ category): {result.data[0].get('id')}")
                        return result.data[0]
                    else:
                        logging.warning(f"‚ö†Ô∏è Supabase –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {table}, –∏—Å–ø–æ–ª—å–∑—É–µ–º payload")
                        return payload_without_category
                except Exception as retry_exc:
                    logging.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ {table}: {retry_exc}")
                    logging.error(f"Payload: {json.dumps(payload_without_category, ensure_ascii=False, default=str)}")
                    raise
            
            logging.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ {table}: {exc}")
            logging.error(f"Payload: {json.dumps(payload, ensure_ascii=False, default=str)}")
            raise

    def _table_upsert_many(
        self,
        table: str,
        payloads: List[Dict[str, Any]],
        on_conflict: str,
    ) -> List[Dict[str, Any]]:
        result = (
            self._client.table(table)
            .upsert(payloads, on_conflict=on_conflict, returning="representation")
            .execute()
        )
        return result.data if result.data else payloads

    def _fetch_report_sync(self, user_id: int, period: str) -> Dict[str, Any]:
        data = (
            self._client.table(self.expenses_table)
            .select("*")
            .eq("user_id", user_id)
            .ilike("period", period)
            .execute()
            .data
            or []
        )
        total = sum(entry.get("amount", 0.0) for entry in data)
        
        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        categories = {}
        for entry in data:
            category = entry.get("category") or "–î—Ä—É–≥–æ–µ"
            amount = entry.get("amount", 0.0)
            categories[category] = categories.get(category, 0.0) + amount
        
        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º
        stores = {}
        for entry in data:
            store = entry.get("store") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            amount = entry.get("amount", 0.0)
            stores[store] = stores.get(store, 0.0) + amount
        
        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –¥–Ω—è–º
        daily = {}
        for entry in data:
            date_str = entry.get("date", "")
            if date_str:
                day = date_str[:10]  # YYYY-MM-DD
                amount = entry.get("amount", 0.0)
                daily[day] = daily.get(day, 0.0) + amount
        
        return {
            "period": period,
            "total": total,
            "entries": data,
            "by_category": categories,
            "by_store": stores,
            "by_day": daily,
        }

    def _export_expenses_csv_sync(self, user_id: int, period: Optional[str]) -> str:
        query = self._client.table(self.expenses_table).select("*").eq("user_id", user_id)
        if period:
            query = query.ilike("period", f"{period}%")
        data = query.execute().data or []
        if not data:
            return "user_id,store,amount,currency,date,source,note\n"
        fieldnames = sorted({field for row in data for field in row.keys()})
        buffer = io.StringIO()
        writer = csv.DictWriter(buffer, fieldnames=fieldnames)
        writer.writeheader()
        for row in data:
            writer.writerow({key: row.get(key) for key in fieldnames})
        return buffer.getvalue()

    def _delete_all_user_data_sync(self, user_id: int) -> Dict[str, int]:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü.
        """
        result = {}
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ expenses
        try:
            expenses_result = (
                self._client.table(self.expenses_table)
                .delete()
                .eq("user_id", user_id)
                .execute()
            )
            result["expenses"] = len(expenses_result.data) if expenses_result.data else 0
            logging.info(f"Deleted {result['expenses']} expenses for user={user_id}")
        except Exception as exc:
            logging.exception(f"Error deleting expenses for user={user_id}: {exc}")
            result["expenses"] = 0
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ receipts
        try:
            receipts_result = (
                self._client.table(self.receipts_table)
                .delete()
                .eq("user_id", user_id)
                .execute()
            )
            result["receipts"] = len(receipts_result.data) if receipts_result.data else 0
            logging.info(f"Deleted {result['receipts']} receipts for user={user_id}")
        except Exception as exc:
            logging.exception(f"Error deleting receipts for user={user_id}: {exc}")
            result["receipts"] = 0
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ bank_transactions
        try:
            bank_result = (
                self._client.table(self.bank_table)
                .delete()
                .eq("user_id", user_id)
                .execute()
            )
            result["bank_transactions"] = len(bank_result.data) if bank_result.data else 0
            logging.info(f"Deleted {result['bank_transactions']} bank transactions for user={user_id}")
        except Exception as exc:
            logging.exception(f"Error deleting bank transactions for user={user_id}: {exc}")
            result["bank_transactions"] = 0
        
        total_deleted = sum(result.values())
        logging.warning(f"Total deleted records for user={user_id}: {total_deleted}")
        return result


def truncate_message_for_telegram(text: str, max_length: int = 4000) -> str:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –¥–ª—è Telegram.
    Telegram –∏–º–µ–µ—Ç –ª–∏–º–∏—Ç 4096 —Å–∏–º–≤–æ–ª–æ–≤, –æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å.
    """
    if len(text) <= max_length:
        return text
    # –û–±—Ä–µ–∑–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ–±—Ä–µ–∑–∫–∏
    truncated = text[:max_length - 50]
    # –ü—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–µ–∑–∞—Ç—å –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –ø–µ—Ä–µ–Ω–æ—Å—É —Å—Ç—Ä–æ–∫–∏
    last_newline = truncated.rfind('\n')
    if last_newline > max_length - 200:
        truncated = truncated[:last_newline]
    return truncated + "\n\n... (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ, —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ)"


class LedgerFoxBot:
    """Telegram bot orchestrating OCR, bank parsing, and Supabase storage."""

    def __init__(self, token: str, supabase_gateway: Optional[SupabaseGateway] = None) -> None:
        self.bot = Bot(token=token)
        self.dp = Dispatcher()
        self.router = Router(name="ledgerfox")
        self.supabase = supabase_gateway
        self._media_group_cache: Dict[str, List[Message]] = {}
        self._media_group_tasks: Dict[str, asyncio.Task] = {}
        self.dp.include_router(self.router)
        self._register_handlers()

    @classmethod
    def from_env(cls) -> "LedgerFoxBot":
        token = os.getenv("LEDGERFOX_BOT_TOKEN")
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        if not token:
            raise RuntimeError("LEDGERFOX_BOT_TOKEN is required to run LedgerFox.")
        gateway = None
        if supabase_url and supabase_key:
            gateway = SupabaseGateway(url=supabase_url, service_key=supabase_key)
        else:
            logging.warning(
                "Supabase credentials not found. Persistence features are disabled until configured."
            )
        return cls(token=token, supabase_gateway=gateway)

    async def run(self) -> None:
        logging.info("Starting LedgerFox bot")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–µ–Ω—é –∫–æ–º–∞–Ω–¥
        commands = [
            BotCommand(command="receipt", description="–î–æ–±–∞–≤–∏—Ç—å —á–µ–∫ (—Ñ–æ—Ç–æ)"),
            BotCommand(command="expense", description="–î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—Ö–æ–¥ –≤—Ä—É—á–Ω—É—é"),
            BotCommand(command="statement", description="–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—ã–ø–∏—Å–∫—É"),
            BotCommand(command="report", description="–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á—ë—Ç"),
            BotCommand(command="export", description="–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ CSV"),
            BotCommand(command="qr", description="–ù–∞–π—Ç–∏ QR-–∫–æ–¥—ã –Ω–∞ —Ñ–æ—Ç–æ"),
            BotCommand(command="delete_all", description="–£–¥–∞–ª–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ"),
            BotCommand(command="cancel", description="–û—Ç–º–µ–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é"),
        ]
        await self.bot.set_my_commands(commands)
        logging.info("Bot commands menu configured")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö OCR –¥–≤–∏–∂–∫–∞—Ö
        ocr_status = []
        if TESSERACT_AVAILABLE:
            ocr_status.append("Tesseract ‚úì")
        if PADDLEOCR_AVAILABLE:
            ocr_status.append("PaddleOCR ‚úì")
        logging.info(f"Available OCR engines: {', '.join(ocr_status) if ocr_status else 'None'}")
        logging.info(f"Selected OCR engine: {OCR_ENGINE}")
        await self.dp.start_polling(
            self.bot, allowed_updates=self.dp.resolve_used_update_types()
        )

    def _register_handlers(self) -> None:
        @self.router.message(CommandStart())
        async def handle_start(message: Message, state: FSMContext) -> None:
            await state.clear()
            await message.answer(
                "–ü—Ä–∏–≤–µ—Ç! –Ø LedgerFox ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞—é —á–µ–∫–∏, —Å–≤–µ—Ä—è—é —Å –≤—ã–ø–∏—Å–∫–∞–º–∏ –∏ –¥–µ–ª–∞—é –æ—Ç—á—ë—Ç—ã.\n\n"
                "–ö–æ–º–∞–Ω–¥—ã:\n"
                "/receipt ‚Äî –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ–∫\n"
                "/statement ‚Äî –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—ã–ø–∏—Å–∫—É\n"
                "/report ‚Äî –ø–æ–ª—É—á–∏—Ç—å –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç\n"
                "/cancel ‚Äî —Å–±—Ä–æ—Å –¥–µ–π—Å—Ç–≤–∏—è"
            )

        @self.router.message(Command("cancel"))
        async def handle_cancel(message: Message, state: FSMContext) -> None:
            await state.clear()
            await message.answer("–û–∫, –æ—Ç–º–µ–Ω–∏–ª–∏.")

        @self.router.message(Command("receipt"))
        async def handle_receipt_entry(message: Message, state: FSMContext) -> None:
            await state.set_state(ReceiptStates.waiting_for_photo)
            instructions = (
                "üì∏ –ü—Ä–∏—à–ª–∏—Ç–µ —Ñ–æ—Ç–æ/—Å–∫–∞–Ω —á–µ–∫–∞ (jpg/png/pdf).\n\n"
                "üí° –°–æ–≤–µ—Ç—ã –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:\n"
                "‚Ä¢ –ß–µ–∫ –¥–æ–ª–∂–µ–Ω –∑–∞–Ω–∏–º–∞—Ç—å –≤—Å—ë –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –Ω–∞ —Ñ–æ—Ç–æ\n"
                "‚Ä¢ –ï—Å–ª–∏ —á–µ–∫ –¥–ª–∏–Ω–Ω—ã–π, —Å–¥–µ–ª–∞–π—Ç–µ –ø–∞–Ω–æ—Ä–∞–º—É (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ —Ñ–æ—Ç–æ)\n"
                "‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ç–µ–∫—Å—Ç —á–µ—Ç–∫–∏–π –∏ —á–∏—Ç–∞–µ–º—ã–π\n"
                "‚Ä¢ –ï—Å–ª–∏ –Ω–∞ —á–µ–∫–µ –µ—Å—Ç—å QR-–∫–æ–¥, –º–æ–∂–Ω–æ —Å—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –µ–≥–æ - —ç—Ç–æ —É—Å–∫–æ—Ä–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É"
            )
            await message.answer(instructions)

        @self.router.message(ReceiptStates.waiting_for_photo, F.photo | F.document)
        async def handle_receipt_upload(message: Message, state: FSMContext) -> None:
            if message.media_group_id:
                await self._collect_media_group(message)
                return
            await self._process_receipt_message(message, state)

        @self.router.message(Command("statement"))
        async def handle_statement_entry(message: Message, state: FSMContext) -> None:
            await state.set_state(StatementStates.waiting_for_statement)
            await message.answer("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/XLSX/PDF –±–∞–Ω–∫–æ–≤—Å–∫–æ–π –≤—ã–ø–∏—Å–∫–∏.")

        @self.router.message(StatementStates.waiting_for_statement, F.document)
        async def handle_statement_upload(message: Message, state: FSMContext) -> None:
            if message.media_group_id:
                await self._collect_media_group(message)
                return
            await self._process_statement_message(message)
            await state.clear()

        @self.router.message(Command("qr"))
        async def handle_qr_command(message: Message, state: FSMContext) -> None:
            await state.clear()
            if not message.photo and not message.document:
                await message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Å QR-–∫–æ–¥–æ–º.")
                return
            file = await self._resolve_file(message)
            if file is None:
                await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª.")
                return
            file_bytes = await self._download_file(file.file_path)
            qr_codes = read_qr_codes(file_bytes)
            if not qr_codes:
                await message.answer("QR-–∫–æ–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.")
                return
            result_text = "üì± –ù–∞–π–¥–µ–Ω–Ω—ã–µ QR-–∫–æ–¥—ã:\n\n"
            for i, qr in enumerate(qr_codes, 1):
                result_text += f"{i}. –¢–∏–ø: {qr['type']}\n"
                result_text += f"   –î–∞–Ω–Ω—ã–µ: {qr['data']}\n\n"
            truncated_result = truncate_message_for_telegram(result_text)
            await message.answer(truncated_result)

        @self.router.message(F.photo | F.document)
        async def handle_smart_upload(message: Message, state: FSMContext) -> None:
            if message.media_group_id:
                await self._collect_media_group(message)
                return
            classification = classify_upload_kind(message)
            if classification == "receipt":
                await state.clear()
                await self._process_receipt_message(message, state)
                return
            if classification == "statement":
                await state.clear()
                await self._process_statement_message(message)
                return
            instructions = (
                "–ù–µ –ø–æ–Ω—è–ª, —ç—Ç–æ —á–µ–∫ –∏–ª–∏ –≤—ã–ø–∏—Å–∫–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /receipt –∏–ª–∏ /statement.\n\n"
                "üí° –ï—Å–ª–∏ —ç—Ç–æ —á–µ–∫:\n"
                "‚Ä¢ –ß–µ–∫ –¥–æ–ª–∂–µ–Ω –∑–∞–Ω–∏–º–∞—Ç—å –≤—Å—ë –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –Ω–∞ —Ñ–æ—Ç–æ\n"
                "‚Ä¢ –ï—Å–ª–∏ —á–µ–∫ –¥–ª–∏–Ω–Ω—ã–π, —Å–¥–µ–ª–∞–π—Ç–µ –ø–∞–Ω–æ—Ä–∞–º—É\n"
                "‚Ä¢ –ï—Å–ª–∏ –µ—Å—Ç—å QR-–∫–æ–¥, –º–æ–∂–Ω–æ —Å—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –µ–≥–æ"
            )
            await message.answer(instructions)

        @self.router.message(Command("export"))
        async def handle_export(message: Message, state: FSMContext) -> None:
            await state.clear()
            if not self.supabase:
                await message.answer("–≠–∫—Å–ø–æ—Ä—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è Supabase.")
                return
            period = None
            if message.text:
                parts = message.text.split(maxsplit=1)
                if len(parts) == 2:
                    period = parts[1].strip()
            await message.answer("–§–æ—Ä–º–∏—Ä—É—é –≤—ã–≥—Ä—É–∑–∫—É, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥‚Ä¶")
            csv_blob = await self.supabase.export_expenses_csv(message.from_user.id, period)
            filename = f"ledgerfox_export_{period or 'all'}.csv"
            file = BufferedInputFile(csv_blob.encode("utf-8"), filename=filename)
            await message.answer_document(
                document=file,
                caption="–ì–æ—Ç–æ–≤–æ. –ò—Å–ø–æ–ª—å–∑—É–π CSV –≤ Excel/Sheets –∏–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π –æ–±—Ä–∞—Ç–Ω–æ.",
            )

        @self.router.message(Command("import"))
        async def handle_import(message: Message, state: FSMContext) -> None:
            await state.clear()
            await message.answer(
                "–î–ª—è –∏–º–ø–æ—Ä—Ç–∞ –ø—Ä–∏—à–ª–∏ CSV/XLSX/PDF –≤—ã–ø–∏—Å–∫—É –∏–ª–∏ –æ—Ç—á—ë—Ç –∏–∑ –¥—Ä—É–≥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞. "
                "–ú—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –∏ –ø–æ–¥—Å–∫–∞–∂–µ–º, —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ."
            )

        @self.router.message(Command("report"))
        async def handle_report(message: Message, state: FSMContext) -> None:
            await state.clear()
            if not self.supabase:
                await message.answer(
                    "–û—Ç—á—ë—Ç—ã –ø–æ —Ä–∞—Å—Ö–æ–¥–∞–º –ø–æ—è–≤—è—Ç—Å—è –ø–æ—Å–ª–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –±–∞–∑—ã (Supabase)."
                )
                return
            period = datetime.utcnow().strftime("%Y-%m")
            report = await self.supabase.fetch_monthly_report(message.from_user.id, period)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç —Å —Ä–∞–∑–±–∏–≤–∫–æ–π
            report_text = format_report(report)
            
            # –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
            truncated_report = truncate_message_for_telegram(report_text)
            await message.answer(truncated_report)

        @self.router.message(Command("delete_all"))
        async def handle_delete_all(message: Message, state: FSMContext) -> None:
            if not self.supabase:
                await message.answer(
                    "–£–¥–∞–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–Ω–æ–π –±–∞–∑–µ (Supabase)."
                )
                return
            
            if not message.from_user:
                await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º user_id –≤ state –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            await state.update_data(user_id=message.from_user.id)
            await state.set_state(DeleteStates.waiting_for_confirmation)
            
            # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            keyboard = InlineKeyboardMarkup(inline_keyboard=[
                [
                    InlineKeyboardButton(text="‚ö†Ô∏è –î–∞, —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ", callback_data="delete_confirm"),
                ],
                [
                    InlineKeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∏—Ç—å", callback_data="delete_cancel"),
                ]
            ])
            
            await message.answer(
                "‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï!\n\n"
                "–í—ã —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å —É–¥–∞–ª–∏—Ç—å –í–°–ï –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ:\n"
                "‚Ä¢ –í—Å–µ —á–µ–∫–∏\n"
                "‚Ä¢ –í—Å–µ —Ä–∞—Å—Ö–æ–¥—ã\n"
                "‚Ä¢ –í—Å–µ –±–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏\n\n"
                "–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –ù–ï–û–ë–†–ê–¢–ò–ú–û!\n\n"
                "–í—ã —É–≤–µ—Ä–µ–Ω—ã?",
                reply_markup=keyboard
            )

        @self.router.message(Command("expense"))
        async def handle_expense_entry(message: Message, state: FSMContext) -> None:
            await state.clear()
            instructions = (
                "üí≥ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—Ö–æ–¥–∞ –≤—Ä—É—á–Ω—É—é\n\n"
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ä–∞—Å—Ö–æ–¥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
                "‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞/–º–µ—Å—Ç–∞ —Å—É–º–º–∞ –≤–∞–ª—é—Ç–∞\n"
                "‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ —Å—É–º–º–∞ –≤–∞–ª—é—Ç–∞ –¥–∞—Ç–∞\n\n"
                "–ü—Ä–∏–º–µ—Ä—ã:\n"
                "‚Ä¢ –ö–∞—Ñ–µ 500 —Ä—É–±\n"
                "‚Ä¢ –¢–∞–∫—Å–∏ 1200 KZT\n"
                "‚Ä¢ –ü—Ä–æ–¥—É–∫—Ç—ã 2500 —Ä—É–± 03.12\n"
                "‚Ä¢ –†–µ—Å—Ç–æ—Ä–∞–Ω 5000 KZT 2025-12-03\n\n"
                "–í–∞–ª—é—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (RUB, KZT, USD –∏ –¥—Ä.)\n"
                "–ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–µ–≥–æ–¥–Ω—è—à–Ω—è—è."
            )
            await message.answer(instructions)

        @self.router.message(F.text)
        async def handle_text_expense(message: Message, state: FSMContext) -> None:
            if not message.text or message.text.startswith("/"):
                return
            parsed = parse_manual_expense(message.text)
            if not parsed:
                return
            await state.clear()
            await message.answer(format_manual_summary(parsed))
            if not self.supabase or not message.from_user:
                return
            # SECURITY: —É–¥–æ—Å—Ç–æ–≤–µ—Ä–∏—Ç—å—Å—è, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø–∏—Å–∞—Ç—å –≤ –±–∞–∑—É.
            payload = build_manual_expense_payload(message.from_user.id, parsed)
            expense_result = await self.supabase.record_expense(payload)
            if expense_result.get("duplicate"):
                await message.answer("‚ö†Ô∏è –†–∞—Å—Ö–æ–¥ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω: –Ω–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç —Å —Ç–∞–∫–æ–π –∂–µ –¥–∞—Ç–æ–π –∏ —Å—É–º–º–æ–π.")
            else:
                await message.answer("‚úÖ –†–∞—Å—Ö–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ω –≤—Ä—É—á–Ω—É—é.")

        @self.router.callback_query(F.data == "receipt_confirm")
        async def handle_receipt_confirm(callback: CallbackQuery, state: FSMContext) -> None:
            """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —á–µ–∫–∞"""
            await callback.answer()
            data = await state.get_data()
            parsed_receipt = data.get("parsed_receipt")
            receipt_payload = data.get("receipt_payload")
            
            if not receipt_payload or not callback.from_user:
                await callback.message.answer("–û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                await state.clear()
                return
            
            try:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫ –≤ –±–∞–∑—É
                stored_receipt, is_duplicate = await self.supabase.upsert_receipt(receipt_payload)
                if is_duplicate:
                    await callback.message.answer("‚ö†Ô∏è –≠—Ç–æ—Ç —á–µ–∫ —É–∂–µ –±—ã–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Ä–∞–Ω–µ–µ (–¥—É–±–ª–∏–∫–∞—Ç)")
                else:
                    # –°–æ–∑–¥–∞–µ–º expense –∑–∞–ø–∏—Å—å –∏–∑ receipt —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–æ–≤—ã–π —á–µ–∫
                    expense_payload = build_expense_payload_from_receipt(stored_receipt)
                    expense_result = await self.supabase.record_expense(expense_payload)
                    if expense_result.get("duplicate"):
                        await callback.message.answer("‚úÖ –ß–µ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö\n‚ö†Ô∏è –†–∞—Å—Ö–æ–¥ –Ω–µ —Å–æ–∑–¥–∞–Ω: –Ω–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç (–≤–æ–∑–º–æ–∂–Ω–æ, —É–∂–µ –µ—Å—Ç—å –≤ –≤—ã–ø–∏—Å–∫–µ)")
                    else:
                        await callback.message.answer("‚úÖ –ß–µ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
                await state.clear()
            except Exception as exc:
                logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —á–µ–∫–∞: {exc}")
                await callback.message.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—É: {str(exc)[:100]}")
                await state.clear()

        @self.router.callback_query(F.data == "receipt_reject")
        async def handle_receipt_reject(callback: CallbackQuery, state: FSMContext) -> None:
            """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —á–µ–∫–∞"""
            await callback.answer()
            await callback.message.answer("–ü–æ–Ω—è–ª, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —á–µ–∫–∞ –∑–∞–Ω–æ–≤–æ –¥–ª—è –ø–µ—Ä–µ—Å–Ω—è—Ç–∏—è.")
            await state.clear()

        @self.router.callback_query(F.data == "delete_confirm")
        async def handle_delete_confirm(callback: CallbackQuery, state: FSMContext) -> None:
            """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
            await callback.answer()
            
            if not self.supabase or not callback.from_user:
                await callback.message.answer("–û—à–∏–±–∫–∞: –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
                await state.clear()
                return
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ user_id –∏–∑ state —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å user_id –∏–∑ callback
            data = await state.get_data()
            stored_user_id = data.get("user_id")
            
            if stored_user_id != callback.from_user.id:
                await callback.message.answer("–û—à–∏–±–∫–∞: –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
                await state.clear()
                return
            
            try:
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                await callback.message.answer("–£–¥–∞–ª—è—é –≤—Å–µ –¥–∞–Ω–Ω—ã–µ...")
                result = await self.supabase.delete_all_user_data(callback.from_user.id)
                
                total_deleted = sum(result.values())
                message_text = (
                    f"‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–µ–Ω—ã!\n\n"
                    f"–£–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π:\n"
                    f"‚Ä¢ –ß–µ–∫–æ–≤: {result.get('receipts', 0)}\n"
                    f"‚Ä¢ –†–∞—Å—Ö–æ–¥–æ–≤: {result.get('expenses', 0)}\n"
                    f"‚Ä¢ –ë–∞–Ω–∫–æ–≤—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {result.get('bank_transactions', 0)}\n\n"
                    f"–í—Å–µ–≥–æ: {total_deleted}"
                )
                await callback.message.answer(message_text)
            except Exception as exc:
                logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {exc}")
                await callback.message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(exc)[:200]}")
            finally:
                await state.clear()

        @self.router.callback_query(F.data == "delete_cancel")
        async def handle_delete_cancel(callback: CallbackQuery, state: FSMContext) -> None:
            """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç–º–µ–Ω—ã —É–¥–∞–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
            await callback.answer()
            await callback.message.answer("–£–¥–∞–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ. –í–∞—à–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
            await state.clear()

    async def _process_receipt_message(self, message: Message, state: FSMContext) -> None:
        await message.answer("–ß–µ–∫ –ø—Ä–∏–Ω—è—Ç, —Ä–∞—Å–ø–æ–∑–Ω–∞—é‚Ä¶")
        result = await self._handle_receipt_from_message(message)
        logging.info(f"Receipt processing result: success={result.success}, has_summary={bool(result.summary)}, has_error={bool(result.error)}")
        if result.success and result.summary:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ –≤ FSM –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            if result.parsed_receipt and result.receipt_payload:
                await state.update_data(
                    parsed_receipt=result.parsed_receipt,
                    receipt_payload=result.receipt_payload,
                )
                await state.set_state(ReceiptStates.waiting_for_confirmation)
            
            # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (–≤ —Ä–∞–∑–Ω—ã—Ö —Ä—è–¥–∞—Ö)
            keyboard = InlineKeyboardMarkup(inline_keyboard=[
                [
                    InlineKeyboardButton(text="‚úÖ –í—Å–µ –≤–µ—Ä–Ω–æ", callback_data="receipt_confirm"),
                ],
                [
                    InlineKeyboardButton(text="‚ùå –ï—Å—Ç—å –æ—à–∏–±–∫–∞ (–ø–µ—Ä–µ—Å–Ω—è—Ç—å)", callback_data="receipt_reject"),
                ]
            ])
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if result.parsed_receipt:
                img_bytes = generate_receipt_image(result.parsed_receipt)
                if img_bytes:
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    photo = BufferedInputFile(img_bytes, filename="receipt.png")
                    await message.answer_photo(photo, reply_markup=keyboard)
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
                    items_sum = sum(item.price for item in result.parsed_receipt.items)
                    total = result.parsed_receipt.total or 0.0
                    difference = abs(items_sum - total)
                    tolerance = max(total * 0.01, 1.0)
                    
                    if difference > tolerance:
                        validation_text = (
                            f"‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—É–º–º—ã:\n"
                            f"–°—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π: {items_sum:.2f} {result.parsed_receipt.currency}\n"
                            f"–ò—Ç–æ–≥–æ: {total:.2f} {result.parsed_receipt.currency}\n"
                            f"–†–∞–∑–Ω–∏—Ü–∞: {difference:.2f} {result.parsed_receipt.currency}"
                        )
                    else:
                        validation_text = (
                            f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞:\n"
                            f"–°—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π: {items_sum:.2f} {result.parsed_receipt.currency}\n"
                            f"–ò—Ç–æ–≥–æ: {total:.2f} {result.parsed_receipt.currency}"
                        )
                    await message.answer(validation_text)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–æ–º, –µ—Å–ª–∏ –µ—Å—Ç—å
                    additional_info = ""
                    if "QR-–∫–æ–¥–∞" in result.summary or "QR" in result.summary:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ QR-–∫–æ–¥–µ –∏–∑ summary
                        qr_part = result.summary.split("üì±")[-1] if "üì±" in result.summary else ""
                        if qr_part:
                            additional_info = f"\n\nüì±{qr_part}"
                    
                    if additional_info:
                        await message.answer(additional_info.strip())
                    return
            
            # Fallback: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–º –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            truncated_summary = truncate_message_for_telegram(result.summary)
            logging.info(f"Sending receipt summary to user (text fallback): {len(result.summary)} chars")
            await message.answer(truncated_summary, reply_markup=keyboard)
            return
        error_msg = result.error or "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–µ–∫."
        logging.warning(f"Sending error to user: {error_msg}")
        await message.answer(error_msg)

    async def _process_statement_message(self, message: Message) -> None:
        await message.answer("–í—ã–ø–∏—Å–∫–∞ –ø—Ä–∏–Ω—è—Ç–∞, —Ä–∞—Å–ø–æ–∑–Ω–∞—é‚Ä¶")
        result = await self._handle_statement_from_message(message)
        if result.success and result.summary:
            truncated_summary = truncate_message_for_telegram(result.summary)
            await message.answer(truncated_summary)
            return
        await message.answer(result.error or "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—ã–ø–∏—Å–∫—É.")

    async def _handle_receipt_from_message(self, message: Message) -> ProcessingResult:
        file = await self._resolve_file(message)
        if file is None:
            return ProcessingResult(success=False, error="–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª.")
        mime_type = detect_mime_type(message, file.file_path)
        file_bytes = await self._download_file(file.file_path)
        try:
            file_bytes, mime_type = convert_heic_if_needed(file_bytes, mime_type)
        except ReceiptParsingError as exc:
            return ProcessingResult(success=False, error=str(exc))
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º QR-–∫–æ–¥—ã
        qr_codes = read_qr_codes(file_bytes)
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ QR-–∫–æ–¥–æ–≤: {len(qr_codes)}")
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ QR-–∫–æ–¥–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ OpenAI
        qr_data_from_url = None
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å QR-–∫–æ–¥ –∏–ª–∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥ —Å URL, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç—Ç—É–¥–∞
        if qr_codes:
            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º QR-–∫–æ–¥—ã —Å URL (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º CODE39 –∏ –¥—Ä—É–≥–∏–µ –Ω–µ-URL –∫–æ–¥—ã)
            for qr in qr_codes:
                qr_data = qr.get("data", "")
                qr_type = qr.get("type", "")
                
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º CODE39 –∏ –¥—Ä—É–≥–∏–µ —à—Ç—Ä–∏—Ö-–∫–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è URL
                if qr_type == "CODE39" or (not is_url(qr_data) and qr_type != "QRCODE"):
                    logging.info(f"–ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–¥ —Ç–∏–ø–∞ {qr_type}: {qr_data[:50]}... (–Ω–µ URL –∏ –Ω–µ QR-–∫–æ–¥)")
                    continue
                
                logging.info(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥: {qr_data[:100]}... (—Ç–∏–ø: {qr_type})")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ URL
                if is_url(qr_data):
                    logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –∫–æ–¥ —Å URL (—Ç–∏–ø: {qr_type}): {qr_data}")
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å URL
                    qr_data_from_url = await fetch_receipt_from_qr_url(qr_data)
                    if qr_data_from_url:
                        logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Å URL, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –≤ OpenAI –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è")
                    else:
                        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å URL, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                        qr_data_from_url = None  # –°–±—Ä–æ—Å, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω QR-–∫–æ–¥ —Å URL, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–¥—ã
                    break
                else:
                    logging.info(f"QR-–∫–æ–¥ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è URL: {qr_data[:50]}... (—Ç–∏–ø: {qr_type})")
        
        # –ï—Å–ª–∏ QR-–∫–æ–¥–∞ –Ω–µ—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º OpenAI
        try:
            logging.info(f"Using original image: {len(file_bytes)} bytes ({len(file_bytes) / 1024:.1f} –ö–ë)")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º mime_type
            if Image is not None:
                try:
                    image = Image.open(io.BytesIO(file_bytes))
                    mime_type = f"image/{image.format.lower()}" if image.format else "image/jpeg"
                except Exception:
                    mime_type = "image/jpeg"
            else:
                mime_type = "image/jpeg"
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenAI (—Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ QR-–∫–æ–¥–∞, –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º)
            if qr_data_from_url:
                logging.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ QR-–∫–æ–¥–∞ –≤ OpenAI –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è")
                response_json = await parse_receipt_with_ai(file_bytes, mime_type, qr_data=qr_data_from_url)
            else:
                logging.info("Starting OpenAI receipt parsing...")
                response_json = await parse_receipt_with_ai(file_bytes, mime_type)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ content –∏–∑ message –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–∞—Ö
            try:
                choices = response_json.get("choices", [])
                if not choices:
                    raise ReceiptParsingError("OpenAI response –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç choices")
                
                ai_message = choices[0].get("message", {})
                content = ai_message.get("content")
                refusal = ai_message.get("refusal")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–∫–∞–∑–∞–ª–∞—Å—å –ª–∏ –º–æ–¥–µ–ª—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å
                if refusal:
                    refusal_msg = f"OpenAI –æ—Ç–∫–∞–∑–∞–ª—Å—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å: {refusal}"
                    logging.warning(refusal_msg)
                    raise ReceiptParsingError(refusal_msg)
                
                if not content:
                    raise ReceiptParsingError("OpenAI response –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç content")
                
                # –ü–∞—Ä—Å–∏–º JSON –∏–∑ content
                content_json = None
                try:
                    # –ü–∞—Ä—Å–∏–º JSON –∏–∑ content
                    content_json = json.loads(content)
                except json.JSONDecodeError:
                    # –ï—Å–ª–∏ –Ω–µ JSON, –ø—ã—Ç–∞–µ–º—Å—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    try:
                        content_decoded = content.encode().decode('unicode_escape')
                        content_json = json.loads(content_decoded)
                    except (json.JSONDecodeError, UnicodeDecodeError):
                        logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ content")
                        raise ReceiptParsingError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç OpenAI")
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ ParsedReceipt –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                parsed_receipt = build_parsed_receipt(content_json)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: —Å—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π –¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —Ç–æ—Ç–∞–ª–æ–º
                items_sum = sum(item.price for item in parsed_receipt.items)
                total = parsed_receipt.total or 0.0
                difference = abs(items_sum - total)
                
                # –î–æ–ø—É—Å–∫–∞–µ–º –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –¥–æ 1% –∏–ª–∏ 1 –µ–¥–∏–Ω–∏—Ü—É –≤–∞–ª—é—Ç—ã (—á—Ç–æ –±–æ–ª—å—à–µ)
                tolerance = max(total * 0.01, 1.0)
                
                validation_message = ""
                if difference > tolerance:
                    validation_message = (
                        f"\n\n‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—É–º–º—ã:\n"
                        f"–°—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π: {items_sum:.2f} {parsed_receipt.currency}\n"
                        f"–ò—Ç–æ–≥–æ: {total:.2f} {parsed_receipt.currency}\n"
                        f"–†–∞–∑–Ω–∏—Ü–∞: {difference:.2f} {parsed_receipt.currency}"
                    )
                    logging.warning(
                        f"‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—É–º–º—ã: —Å—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π={items_sum:.2f}, "
                        f"–∏—Ç–æ–≥–æ={total:.2f}, —Ä–∞–∑–Ω–∏—Ü–∞={difference:.2f} (–¥–æ–ø—É—Å—Ç–∏–º–æ {tolerance:.2f})"
                    )
                else:
                    validation_message = (
                        f"\n\n‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞:\n"
                        f"–°—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π: {items_sum:.2f} {parsed_receipt.currency}\n"
                        f"–ò—Ç–æ–≥–æ: {total:.2f} {parsed_receipt.currency}"
                    )
                    logging.info(f"‚úÖ –°—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∏—Ç–æ–≥–æ: {items_sum:.2f} = {total:.2f}")
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–µ–∫ –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã
                receipt_table = format_receipt_table(parsed_receipt)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–∞—Ö
                usage = response_json.get("usage", {})
                prompt_tokens = usage.get("prompt_tokens", 0)
                completion_tokens = usage.get("completion_tokens", 0)
                total_tokens = usage.get("total_tokens", 0)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
                prompt_tokens_details = usage.get("prompt_tokens_details", {})
                cached_tokens = prompt_tokens_details.get("cached_tokens", 0)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                summary = receipt_table + validation_message
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ QR-–∫–æ–¥–∞—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã
                if qr_codes:
                    qr_info = "\n\nüì± –ù–∞–π–¥–µ–Ω–Ω—ã–µ QR-–∫–æ–¥—ã:\n"
                    for i, qr in enumerate(qr_codes, 1):
                        qr_info += f"{i}. –¢–∏–ø: {qr['type']}\n"
                        qr_info += f"   –î–∞–Ω–Ω—ã–µ: {qr['data']}\n"
                    summary += qr_info
                
                # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏
                if cached_tokens > 0:
                    logging.info(f"‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç! –ö—ç—à–∏—Ä–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {cached_tokens} –∏–∑ {prompt_tokens}")
                else:
                    logging.warning(f"‚ö†Ô∏è –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç. Prompt tokens: {prompt_tokens}. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (< 1024 —Ç–æ–∫–µ–Ω–æ–≤)")
                
                logging.info(f"Parsed receipt: store={parsed_receipt.store}, total={parsed_receipt.total}, items={len(parsed_receipt.items)}, tokens: {total_tokens}")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É)
                receipt_payload = None
                if self.supabase and message.from_user:
                    try:
                        # –°–æ–∑–¥–∞–µ–º payload –¥–ª—è –±–∞–∑—ã
                        receipt_payload = build_receipt_payload(message.from_user.id, parsed_receipt)
                        logging.info(f"–°–æ–∑–¥–∞–Ω payload –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: store={receipt_payload.get('store')}, total={receipt_payload.get('total')}")
                    except Exception as db_exc:
                        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ payload: {db_exc}")
                
                return ProcessingResult(
                    success=True,
                    summary=summary,
                    parsed_receipt=parsed_receipt,
                    receipt_payload=receipt_payload,
                )
            except Exception as exc:
                logging.error(f"Error extracting content: {exc}", exc_info=True)
                # Fallback: –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏ –ø–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –∏–ª–∏ JSON
                response_str = ""
                
                # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—É –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
                if self.supabase and message.from_user:
                    try:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ response_json –Ω–∞–ø—Ä—è–º—É—é
                        choices = response_json.get("choices", [])
                        if choices:
                            ai_message = choices[0].get("message", {})
                            content = ai_message.get("content", "")
                            if content:
                                try:
                                    fallback_data = json.loads(content)
                                    parsed_receipt = build_parsed_receipt(fallback_data)
                                    
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: —Å—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π –¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —Ç–æ—Ç–∞–ª–æ–º
                                    items_sum = sum(item.price for item in parsed_receipt.items)
                                    total = parsed_receipt.total or 0.0
                                    difference = abs(items_sum - total)
                                    tolerance = max(total * 0.01, 1.0)
                                    
                                    validation_message = ""
                                    if difference > tolerance:
                                        validation_message = (
                                            f"\n\n‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—É–º–º—ã:\n"
                                            f"–°—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π: {items_sum:.2f} {parsed_receipt.currency}\n"
                                            f"–ò—Ç–æ–≥–æ: {total:.2f} {parsed_receipt.currency}\n"
                                            f"–†–∞–∑–Ω–∏—Ü–∞: {difference:.2f} {parsed_receipt.currency}"
                                        )
                                        logging.warning(
                                            f"‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—É–º–º—ã (fallback): —Å—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π={items_sum:.2f}, "
                                            f"–∏—Ç–æ–≥–æ={total:.2f}, —Ä–∞–∑–Ω–∏—Ü–∞={difference:.2f}"
                                        )
                                    else:
                                        validation_message = (
                                            f"\n\n‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞:\n"
                                            f"–°—É–º–º–∞ –ø–æ–∑–∏—Ü–∏–π: {items_sum:.2f} {parsed_receipt.currency}\n"
                                            f"–ò—Ç–æ–≥–æ: {total:.2f} {parsed_receipt.currency}"
                                        )
                                    
                                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É
                                    response_str = format_receipt_table(parsed_receipt) + validation_message
                                    
                                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É)
                                    receipt_payload = None
                                    if self.supabase and message.from_user:
                                        try:
                                            receipt_payload = build_receipt_payload(message.from_user.id, parsed_receipt)
                                            logging.info(f"–°–æ–∑–¥–∞–Ω payload –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (fallback): store={receipt_payload.get('store')}, total={receipt_payload.get('total')}")
                                        except Exception as payload_exc:
                                            logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ payload (fallback): {payload_exc}")
                                    
                                    return ProcessingResult(
                                        success=True,
                                        summary=response_str,
                                        parsed_receipt=parsed_receipt,
                                        receipt_payload=receipt_payload,
                                    )
                                except Exception as fallback_exc:
                                    logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤ fallback: {fallback_exc}")
                                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º JSON
                                    response_str = json.dumps(response_json, ensure_ascii=False, indent=2)
                    except Exception as db_exc:
                        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–∞–∑—É (fallback): {db_exc}")
                        if not response_str:
                            response_str = json.dumps(response_json, ensure_ascii=False, indent=2)
                
                if not response_str:
                    response_str = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {exc}\n\n–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç:\n{json.dumps(response_json, ensure_ascii=False, indent=2)}"
                
                return ProcessingResult(
                    success=True,
                    summary=response_str,
                )
        except ReceiptParsingError as exc:
            logging.exception("Receipt parsing failed")
            return ProcessingResult(success=False, error=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —á–µ–∫: {exc}")
        except Exception as exc:
            logging.exception("Image preprocessing or parsing failed")
            return ProcessingResult(success=False, error=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {exc}")

    async def _handle_statement_from_message(self, message: Message) -> ProcessingResult:
        file = await self._resolve_file(message)
        if file is None:
            return ProcessingResult(success=False, error="–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –≤—ã–ø–∏—Å–∫–∏.")
        file_bytes = await self._download_file(file.file_path)
        try:
            transactions = await parse_bank_statement(file_bytes)
        except StatementParsingError as exc:
            logging.exception("Bank statement parsing failed")
            return ProcessingResult(success=False, error=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤—ã–ø–∏—Å–∫—É: {exc}")

        if not transactions:
            return ProcessingResult(success=False, error="–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª–µ.")

        summary = format_statement_summary(transactions)
        if not self.supabase or not message.from_user:
            return ProcessingResult(success=True, summary=summary)

        payloads = [build_bank_payload(message.from_user.id, txn) for txn in transactions]
        stored = await self.supabase.upsert_bank_transactions(payloads)
        await reconcile_transactions(self.supabase, message.from_user.id, stored)
        return ProcessingResult(
            success=True,
            summary=f"{summary}\n\n–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {len(stored)}",
        )

    async def _collect_media_group(self, message: Message) -> None:
        if not message.media_group_id:
            return
        group_id = str(message.media_group_id)
        # SECURITY: –¥–æ–±–∞–≤–∏—Ç—å rate-limiting –∏ –ø—Ä–æ–≤–µ—Ä–∫—É –∫–≤–æ—Ç –ø–µ—Ä–µ–¥ –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∞–ª—å–±–æ–º–æ–≤.
        bucket = self._media_group_cache.setdefault(group_id, [])
        bucket.append(message)
        if group_id not in self._media_group_tasks:
            self._media_group_tasks[group_id] = asyncio.create_task(
                self._finalize_media_group(group_id)
            )

    async def _finalize_media_group(self, group_id: str) -> None:
        await asyncio.sleep(1.2)
        messages = self._media_group_cache.pop(group_id, [])
        self._media_group_tasks.pop(group_id, None)
        if not messages:
            return
        chat_id = messages[0].chat.id
        await self.bot.send_message(chat_id, f"–ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Ñ–∞–π–ª–æ–≤, —Ä–∞—Å–ø–æ–∑–Ω–∞—é –±–∞—Ç—á‚Ä¶")
        summaries: List[str] = []
        for idx, message in enumerate(messages, start=1):
            classification = classify_upload_kind(message)
            if classification == "receipt":
                result = await self._handle_receipt_from_message(message)
            elif classification == "statement":
                result = await self._handle_statement_from_message(message)
            else:
                result = ProcessingResult(success=False, error="–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ñ–∞–π–ª–∞.")
            prefix = f"[{idx}]"
            if result.success and result.summary:
                # –û–±—Ä–µ–∑–∞–µ–º –∫–∞–∂–¥—ã–π summary, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º
                truncated_summary = truncate_message_for_telegram(result.summary, max_length=3000)
                summaries.append(f"{prefix}\n{truncated_summary}")
            else:
                summaries.append(f"{prefix} –û—à–∏–±–∫–∞: {result.error}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        full_message = "–ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ñ–∞–π–ª–∞–º:\n\n" + "\n\n".join(summaries)
        
        # –û–±—Ä–µ–∑–∞–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        truncated_message = truncate_message_for_telegram(full_message)
        
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –±—ã–ª–æ –æ–±—Ä–µ–∑–∞–Ω–æ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ —á–∞—Å—Ç—è–º–∏
        if len(full_message) > 4000:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            await self.bot.send_message(chat_id, "–ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ñ–∞–π–ª–∞–º:")
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π summary –æ—Ç–¥–µ–ª—å–Ω–æ
            for summary in summaries:
                await self.bot.send_message(chat_id, summary)
        else:
            await self.bot.send_message(chat_id, truncated_message)

    async def _resolve_file(self, message: Message) -> Optional[Any]:
        if message.photo:
            return await self.bot.get_file(message.photo[-1].file_id)
        if message.document:
            return await self.bot.get_file(message.document.file_id)
        return None

    async def _download_file(self, file_path: str) -> bytes:
        stream = await self.bot.download_file(file_path)
        buffer = io.BytesIO()
        buffer.write(stream.read())
        return buffer.getvalue()

    async def _send_snapshot(self, chat_id: int, snapshot: Snapshot) -> None:
        try:
            print(f"[DEBUG] _send_snapshot called for step: {snapshot.step}")
            if snapshot.pil_image is None:
                logging.error(f"Snapshot {snapshot.step} has None pil_image!")
                print(f"[ERROR] Snapshot {snapshot.step} has None pil_image!")
                return
            png_bytes = image_to_png_bytes(snapshot.pil_image)
            if not png_bytes:
                logging.warning(f"Failed to convert snapshot {snapshot.step} to PNG bytes")
                print(f"[WARNING] Failed to convert snapshot {snapshot.step} to PNG bytes")
                return
            caption = f"{snapshot.step}: {snapshot.description}"
            print(f"[DEBUG] Sending photo to Telegram: {snapshot.step} ({len(png_bytes)} bytes)")
            logging.info(f"Sending snapshot {snapshot.step} ({len(png_bytes)} bytes)")
            await self.bot.send_photo(
                chat_id=chat_id,
                photo=BufferedInputFile(png_bytes, filename=f"{snapshot.step}.png"),
                caption=caption,
            )
            print(f"[DEBUG] Successfully sent snapshot {snapshot.step} to Telegram")
            logging.info(f"Successfully sent snapshot {snapshot.step}")
        except Exception as exc:
            print(f"[ERROR] Exception sending snapshot {snapshot.step}: {exc}")
            logging.exception(f"Error sending snapshot {snapshot.step}: {exc}")


def detect_mime_type(message: Message, file_path: str) -> str:
    if message.document and message.document.mime_type:
        return message.document.mime_type
    guessed, _ = mimetypes.guess_type(file_path)
    return guessed or "image/jpeg"


STATEMENT_EXTENSIONS = (".csv", ".tsv", ".xls", ".xlsx", ".pdf")
STATEMENT_MIME_PREFIXES = (
    "text/csv",
    "text/tab-separated-values",
    "application/pdf",
    "application/vnd.ms-excel",
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)


def classify_upload_kind(message: Message) -> Optional[str]:
    if message.photo:
        return "receipt"
    document = message.document
    if not document:
        return None
    mime_type = (document.mime_type or "").lower()
    file_name = (document.file_name or "").lower()
    if mime_type.startswith("image/"):
        return "receipt"
    if any(file_name.endswith(ext) for ext in STATEMENT_EXTENSIONS):
        return "statement"
    if mime_type in STATEMENT_MIME_PREFIXES:
        return "statement"
    caption = (message.caption or "").lower()
    if "–≤—ã–ø–∏—Å" in caption or "statement" in caption:
        return "statement"
    if "—á–µ–∫" in caption or "receipt" in caption:
        return "receipt"
    return None


def format_receipt_summary(parsed: ParsedReceipt) -> str:
    lines = [
        "–í–æ—Ç —á—Ç–æ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å:",
        f"‚Ä¢ –ú–∞–≥–∞–∑–∏–Ω: {parsed.store}",
        f"‚Ä¢ –î–∞—Ç–∞: {parsed.purchased_at.strftime('%Y-%m-%d %H:%M')}",
        f"‚Ä¢ –°—É–º–º–∞: {parsed.total:.2f} {parsed.currency}",
    ]
    if parsed.tax_amount is not None:
        lines.append(f"‚Ä¢ –ù–∞–ª–æ–≥: {parsed.tax_amount:.2f} {parsed.currency}")
    if parsed.merchant_address:
        lines.append(f"‚Ä¢ –ê–¥—Ä–µ—Å: {parsed.merchant_address}")
    if parsed.items:
        lines.append("‚Ä¢ –ü–æ–∑–∏—Ü–∏–∏:")
        for item in parsed.items[:10]:
            lines.append(
                f"   - {item.name} √ó{item.quantity:g} = {item.price:.2f} {parsed.currency}"
            )
        if len(parsed.items) > 10:
            lines.append(f"   ‚Ä¶ –∏ –µ—â—ë {len(parsed.items) - 10} –ø–æ–∑–∏—Ü–∏–π")
    return "\n".join(lines)


def format_receipt_table(parsed: ParsedReceipt) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —á–µ–∫ –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã: –Ω–∞–∑–≤–∞–Ω–∏–µ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –æ–±—â–∞—è —Ü–µ–Ω–∞ –ø–æ–∑–∏—Ü–∏–∏, –∏—Ç–æ–≥.
    """
    lines = []
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –º–∞–≥–∞–∑–∏–Ω–æ–º –∏ –¥–∞—Ç–æ–π
    if parsed.store:
        lines.append(f"üè™ {parsed.store}")
    if parsed.purchased_at:
        lines.append(f"üìÖ {parsed.purchased_at.strftime('%Y-%m-%d %H:%M')}")
    lines.append("")
    
    # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
    name_width = 25  # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–æ–±—Ä–µ–∑–∞–µ–º –¥–æ 25 —Å–∏–º–≤–æ–ª–æ–≤)
    qty_width = 6    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
    price_width = 12 # –°—É–º–º–∞
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
    lines.append(f"{'–¢–æ–≤–∞—Ä':<{name_width}} {'–ö–æ–ª-–≤–æ':>{qty_width}} {'–°—É–º–º–∞':>{price_width}}")
    lines.append("-" * (name_width + qty_width + price_width + 4))
    
    # –ü–æ–∑–∏—Ü–∏–∏
    for item in parsed.items:
        # –û–±—Ä–µ–∑–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
        name = item.name[:25] if len(item.name) > 25 else item.name
        quantity = item.quantity
        total_price = item.price
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–ø—É—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –µ—Å–ª–∏ quantity –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
        # –ï—Å–ª–∏ quantity –±–ª–∏–∑–∫–æ –∫ total_price (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 5%), —Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ = 1
        if quantity > 0 and total_price > 0:
            if abs(quantity - total_price) / max(quantity, total_price) < 0.05:
                # quantity –∏ price –ø–æ—á—Ç–∏ —Ä–∞–≤–Ω—ã, –∑–Ω–∞—á–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ = 1
                quantity = 1.0
            else:
                # –ü—Ä–æ–±—É–µ–º –≤—ã—á–∏—Å–ª–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: price / quantity
                calculated_qty = total_price / quantity
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ä–∞–∑—É–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–æ—Ç 0.5 –¥–æ 100) –∏ –±–ª–∏–∑–∫–æ –∫ —Ü–µ–ª–æ–º—É
                if 0.5 <= calculated_qty <= 100:
                    rounded_qty = round(calculated_qty)
                    # –ï—Å–ª–∏ –æ–∫—Ä—É–≥–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –±–ª–∏–∑–∫–æ –∫ –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–º—É, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                    if abs(calculated_qty - rounded_qty) < 0.1:
                        quantity = float(rounded_qty)
                    else:
                        quantity = calculated_qty
                # –ï—Å–ª–∏ quantity –±–æ–ª—å—à–µ total_price, —Ç–æ—á–Ω–æ –ø–µ—Ä–µ–ø—É—Ç–∞–Ω–æ
                elif quantity > total_price and calculated_qty >= 0.5:
                    quantity = round(calculated_qty) if calculated_qty <= 100 else calculated_qty
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Ç–∞–±–ª–∏—Ü—ã
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –¥–ª—è quantity, –µ—Å–ª–∏ –æ–Ω–æ —Ü–µ–ª–æ–µ
        if quantity == int(quantity):
            qty_str = f"{int(quantity)}"
        else:
            qty_str = f"{quantity:g}"
        price_str = f"{total_price:.2f}"
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏
        lines.append(f"{name:<{name_width}} {qty_str:>{qty_width}} {price_str:>{price_width}}")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
    lines.append("-" * (name_width + qty_width + price_width + 4))
    total_str = f"{parsed.total:.2f} {parsed.currency}"
    lines.append(f"{'–ò–¢–û–ì–û':<{name_width}} {'':>{qty_width}} {total_str:>{price_width}}")
    
    # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ –∫–æ–¥-–±–ª–æ–∫ –¥–ª—è –º–æ–Ω–æ—à–∏—Ä–∏–Ω–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞
    table_text = "\n".join(lines)
    return f"```\n{table_text}\n```"


def generate_receipt_image(parsed: ParsedReceipt) -> Optional[bytes]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–∞–±–ª–∏—Ü–µ–π —á–µ–∫–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ PNG –∏–ª–∏ None –µ—Å–ª–∏ PIL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.
    """
    if Image is None or ImageDraw is None:
        return None
    
    try:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        padding = 40
        line_height = 35
        font_size = 24
        header_font_size = 28
        title_font_size = 32
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —à—Ä–∏—Ñ—Ç, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
        try:
            title_font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", title_font_size)
            header_font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", header_font_size)
            font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", font_size)
        except:
            try:
                title_font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", title_font_size)
                header_font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", header_font_size)
                font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", font_size)
            except:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —à—Ä–∏—Ñ—Ç
                title_font = ImageFont.load_default()
                header_font = ImageFont.load_default()
                font = ImageFont.load_default()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã (–±–µ–∑ —ç–º–æ–¥–∑–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        store_text = parsed.store if parsed.store else ""
        date_text = parsed.purchased_at.strftime('%Y-%m-%d %H:%M') if parsed.purchased_at else ""
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä—ã
        items_data = []
        for item in parsed.items:
            name = item.name[:30] if len(item.name) > 30 else item.name
            quantity = item.quantity
            total_price = item.price
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–ø—É—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–∞ –∂–µ –ª–æ–≥–∏–∫–∞ —á—Ç–æ –∏ –≤ format_receipt_table)
            if quantity > 0 and total_price > 0:
                if abs(quantity - total_price) / max(quantity, total_price) < 0.05:
                    quantity = 1.0
                else:
                    calculated_qty = total_price / quantity
                    if 0.5 <= calculated_qty <= 100:
                        rounded_qty = round(calculated_qty)
                        if abs(calculated_qty - rounded_qty) < 0.1:
                            quantity = float(rounded_qty)
                        else:
                            quantity = calculated_qty
                    elif quantity > total_price and calculated_qty >= 0.5:
                        quantity = round(calculated_qty) if calculated_qty <= 100 else calculated_qty
            
            qty_str = f"{int(quantity)}" if quantity == int(quantity) else f"{quantity:g}"
            price_str = f"{total_price:.2f}"
            
            items_data.append({
                "name": name,
                "qty": qty_str,
                "price": price_str
            })
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–µ–∫—Å—Ç–∞
        temp_img = Image.new('RGB', (2000, 100), color='white')
        temp_draw = ImageDraw.Draw(temp_img)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —à–∏—Ä–∏–Ω—É –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤
        max_name_width_px = 0
        for item in items_data:
            bbox = temp_draw.textbbox((0, 0), item["name"], font=font)
            name_width_px = bbox[2] - bbox[0]
            max_name_width_px = max(max_name_width_px, name_width_px)
        
        # –®–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ –≤ –ø–∏–∫—Å–µ–ª—è—Ö (–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–µ–º—Å—è –Ω–∞ —Ç–∞–±–ª–∏—Ü—É)
        name_col_width = max(max_name_width_px, 300)  # –ú–∏–Ω–∏–º—É–º 300px –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è
        qty_col_width = 100  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        price_col_width = 150
        
        # –®–∏—Ä–∏–Ω–∞ —Ç–∞–±–ª–∏—Ü—ã –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —à–∏—Ä–∏–Ω—É –≤—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        table_width = name_col_width + qty_col_width + price_col_width + 80  # 80px –¥–ª—è –æ—Ç—Å—Ç—É–ø–æ–≤ –º–µ–∂–¥—É –∫–æ–ª–æ–Ω–∫–∞–º–∏
        total_width = table_width + padding * 2
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –æ–Ω–æ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è
        store_lines = []
        if store_text:
            max_store_width = total_width - padding * 2  # –î–æ—Å—Ç—É–ø–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            words = store_text.split()
            current_line = ""
            
            for word in words:
                test_line = current_line + (" " if current_line else "") + word
                bbox = temp_draw.textbbox((0, 0), test_line, font=title_font)
                test_width = bbox[2] - bbox[0]
                
                if test_width <= max_store_width:
                    current_line = test_line
                else:
                    if current_line:
                        store_lines.append(current_line)
                    current_line = word
            
            if current_line:
                store_lines.append(current_line)
        else:
            store_lines = []
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—ã—Å–æ—Ç—É
        header_lines = len(store_lines)  # –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫
        if date_text:
            header_lines += 1
        header_lines += 1  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        
        table_lines = 2 + len(items_data) + 1  # –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å + —Å—Ç—Ä–æ–∫–∏ + –∏—Ç–æ–≥
        total_height = padding * 2 + header_lines * line_height + table_lines * line_height
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = Image.new('RGB', (total_width, total_height), color='white')
        draw = ImageDraw.Draw(img)
        
        y = padding
        x = padding
        
        # –†–∏—Å—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –º–∞–≥–∞–∑–∏–Ω–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫)
        for store_line in store_lines:
            draw.text((x, y), store_line, fill='black', font=title_font)
            y += line_height
        
        # –†–∏—Å—É–µ–º –¥–∞—Ç—É
        if date_text:
            draw.text((x, y), date_text, fill='black', font=header_font)
            y += line_height
        
        y += line_height // 2  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∫–æ–ª–æ–Ω–æ–∫
        name_col_x = x
        qty_col_x = x + name_col_width + 40  # 40px –æ—Ç—Å—Ç—É–ø –º–µ–∂–¥—É –∫–æ–ª–æ–Ω–∫–∞–º–∏
        price_col_x = qty_col_x + qty_col_width + 40
        
        # –†–∏—Å—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
        draw.text((name_col_x, y), "–¢–æ–≤–∞—Ä", fill='black', font=header_font)
        draw.text((qty_col_x, y), "–ö–æ–ª-–≤–æ", fill='black', font=header_font)
        draw.text((price_col_x, y), "–°—É–º–º–∞", fill='black', font=header_font)
        y += line_height
        
        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
        draw.line([(x, y), (total_width - padding, y)], fill='gray', width=2)
        y += line_height
        
        # –†–∏—Å—É–µ–º —Ç–æ–≤–∞—Ä—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º
        for item in items_data:
            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (—Å–ª–µ–≤–∞)
            draw.text((name_col_x, y), item["name"], fill='black', font=font)
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ (–ø–æ —Ü–µ–Ω—Ç—Ä—É —Å–≤–æ–µ–π –∫–æ–ª–æ–Ω–∫–∏)
            qty_bbox = draw.textbbox((0, 0), item["qty"], font=font)
            qty_text_width = qty_bbox[2] - qty_bbox[0]
            qty_x = qty_col_x + (qty_col_width - qty_text_width) // 2  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º
            draw.text((qty_x, y), item["qty"], fill='black', font=font)
            # –¶–µ–Ω–∞ (—Å–ø—Ä–∞–≤–∞ –≤ —Å–≤–æ–µ–π –∫–æ–ª–æ–Ω–∫–µ)
            price_bbox = draw.textbbox((0, 0), item["price"], font=font)
            price_text_width = price_bbox[2] - price_bbox[0]
            price_x = price_col_x + (price_col_width - price_text_width)  # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–ø—Ä–∞–≤–∞
            draw.text((price_x, y), item["price"], fill='black', font=font)
            y += line_height
        
        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø–µ—Ä–µ–¥ –∏—Ç–æ–≥–æ–º
        draw.line([(x, y), (total_width - padding, y)], fill='gray', width=2)
        y += line_height
        
        # –ò—Ç–æ–≥
        total_str = f"{parsed.total:.2f} {parsed.currency}"
        draw.text((name_col_x, y), "–ò–¢–û–ì–û", fill='black', font=header_font)
        # –¶–µ–Ω–∞ –∏—Ç–æ–≥–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–ø—Ä–∞–≤–∞
        total_bbox = draw.textbbox((0, 0), total_str, font=header_font)
        total_text_width = total_bbox[2] - total_bbox[0]
        total_x = price_col_x + (price_col_width - total_text_width)  # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–ø—Ä–∞–≤–∞
        draw.text((total_x, y), total_str, fill='black', font=header_font)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ bytes
        img_bytes = io.BytesIO()
        img.save(img_bytes, format='PNG')
        img_bytes.seek(0)
        return img_bytes.getvalue()
        
    except Exception as exc:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–∫–∞: {exc}")
        return None


def format_report(report: Dict[str, Any]) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º, —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π/–º–∞–≥–∞–∑–∏–Ω–æ–≤ –∏ –≥—Ä–∞—Ñ–∏–∫–æ–º –ø–æ –¥–Ω—è–º.
    """
    period = report.get("period", "")
    total = report.get("total", 0.0)
    by_category = report.get("by_category", {})
    by_store = report.get("by_store", {})
    by_day = report.get("by_day", {})
    
    lines = [f"üìä –û—Ç—á—ë—Ç –∑–∞ {period}"]
    lines.append(f"üí∞ –í—Å–µ–≥–æ —Ä–∞—Å—Ö–æ–¥–æ–≤: {total:.2f}")
    lines.append("")
    
    # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    if by_category:
        lines.append("üìÇ –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        sorted_categories = sorted(by_category.items(), key=lambda x: x[1], reverse=True)
        for category, amount in sorted_categories[:10]:  # –¢–æ–ø 10
            percentage = (amount / total * 100) if total > 0 else 0
            lines.append(f"  ‚Ä¢ {category}: {amount:.2f} ({percentage:.1f}%)")
        lines.append("")
    
    # –¢–æ–ø –º–∞–≥–∞–∑–∏–Ω–æ–≤
    if by_store:
        lines.append("üè™ –¢–æ–ø –º–∞–≥–∞–∑–∏–Ω–æ–≤:")
        sorted_stores = sorted(by_store.items(), key=lambda x: x[1], reverse=True)
        for store, amount in sorted_stores[:5]:  # –¢–æ–ø 5
            percentage = (amount / total * 100) if total > 0 else 0
            store_name = store[:40] if len(store) > 40 else store
            lines.append(f"  ‚Ä¢ {store_name}: {amount:.2f} ({percentage:.1f}%)")
        lines.append("")
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å—Ö–æ–¥–æ–≤ –ø–æ –¥–Ω—è–º
    if by_day:
        lines.append("üìà –†–∞—Å—Ö–æ–¥—ã –ø–æ –¥–Ω—è–º:")
        sorted_days = sorted(by_day.items())
        if sorted_days:
            max_amount = max(by_day.values())
            max_bar_length = 30
            
            for day, amount in sorted_days:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
                try:
                    date_obj = datetime.strptime(day, "%Y-%m-%d")
                    day_str = date_obj.strftime("%d.%m")
                except:
                    day_str = day
                
                # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≥—Ä–∞—Ñ–∏–∫
                bar_length = int((amount / max_amount * max_bar_length)) if max_amount > 0 else 0
                bar = "‚ñà" * bar_length
                lines.append(f"  {day_str}: {bar} {amount:.2f}")
    
    return "\n".join(lines)


def format_statement_summary(transactions: List[ParsedBankTransaction]) -> str:
    totals: Dict[str, float] = {}
    for txn in transactions:
        totals[txn.currency] = totals.get(txn.currency, 0.0) + txn.amount
    lines = [
        "–í—ã–ø–∏—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞.",
        f"–û–ø–µ—Ä–∞—Ü–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(transactions)}",
        "–ò—Ç–æ–≥–∏ –ø–æ –≤–∞–ª—é—Ç–∞–º:",
    ]
    for currency, total in totals.items():
        lines.append(f"‚Ä¢ {currency}: {total:.2f}")
    lines.append("–û–ø–µ—Ä–∞—Ü–∏–∏:")
    for txn in transactions:
        lines.append(
            f"   - {txn.booked_at.strftime('%Y-%m-%d')} {txn.merchant} "
            f"{txn.amount:.2f} {txn.currency}"
        )
    return "\n".join(lines)


def convert_heic_if_needed(file_bytes: bytes, mime_type: str) -> tuple[bytes, str]:
    normalized = (mime_type or "").lower()
    if normalized not in ("image/heic", "image/heif"):
        return file_bytes, mime_type
    if not HEIF_SUPPORT or read_heif is None or Image is None:
        raise ReceiptParsingError(
            "–§–æ—Ä–º–∞—Ç HEIC –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ pillow-heif –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∫–∞–∫ JPG."
        )
    heif_file = read_heif(file_bytes)
    image = Image.frombytes(heif_file.mode, heif_file.size, heif_file.data, "raw")
    buffer = io.BytesIO()
    image.save(buffer, format="JPEG")
    return buffer.getvalue(), "image/jpeg"


def preprocess_image_for_openai(file_bytes: bytes) -> tuple[bytes, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –±–∞–π—Ç—ã, mime_type)
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º mime_type –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É —Ñ–∞–π–ª–∞
    if Image is not None:
        try:
            image = Image.open(io.BytesIO(file_bytes))
            mime_type = f"image/{image.format.lower()}" if image.format else "image/jpeg"
            logging.info(f"Original image: {len(file_bytes)} bytes, format: {mime_type}")
            return file_bytes, mime_type
        except Exception:
            pass
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ JPEG
    logging.info(f"Original image: {len(file_bytes)} bytes, format: image/jpeg (default)")
    return file_bytes, "image/jpeg"


def _find_corners_by_brightness(image: np.ndarray, gray: np.ndarray, image_bgr: np.ndarray) -> tuple[Optional[np.ndarray], Optional[np.ndarray]]:
    """
    –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ —É–≥–ª–æ–≤ —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ —è—Ä–∫–æ—Å—Ç–∏ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞.
    –ò—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥—ã –æ—Ç —Ç–µ–º–Ω–æ–≥–æ —Ñ–æ–Ω–∞ –∫ —Å–≤–µ—Ç–ª–æ–º—É —á–µ–∫—É.
    """
    h, w = gray.shape[:2]
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —è—Ä–∫–æ—Å—Ç—å –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ —Å—Ç–æ–ª–±—Ü–∞–º
    mean_h = np.mean(gray, axis=1)  # –°—Ä–µ–¥–Ω—è—è —è—Ä–∫–æ—Å—Ç—å –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    mean_w = np.mean(gray, axis=0)  # –°—Ä–µ–¥–Ω—è—è —è—Ä–∫–æ—Å—Ç—å –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã (–∏–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏) - –∏—â–µ–º —Ä–µ–∑–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
    grad_h = np.abs(np.diff(mean_h))  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
    grad_w = np.abs(np.diff(mean_w))  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (—Ä–µ–∑–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã)
    grad_h_threshold = np.percentile(grad_h, 90)  # –í–µ—Ä—Ö–Ω–∏–µ 10% —Å–∞–º—ã—Ö —Ä–µ–∑–∫–∏—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
    grad_w_threshold = np.percentile(grad_w, 90)
    
    logging.info(f"[BRIGHTNESS] Gradient thresholds: h={grad_h_threshold:.1f}, w={grad_w_threshold:.1f}")
    logging.info(f"[BRIGHTNESS] Brightness range: h=[{np.min(mean_h):.1f}, {np.max(mean_h):.1f}], w=[{np.min(mean_w):.1f}, {np.max(mean_w):.1f}]")
    
    # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã, –≥–¥–µ –µ—Å—Ç—å —Ä–µ–∑–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã (–∫—Ä–∞—è —á–µ–∫–∞)
    # –ò—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥—ã –æ—Ç —Ç–µ–º–Ω–æ–≥–æ –∫ —Å–≤–µ—Ç–ª–æ–º—É (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç)
    grad_h_pos = np.diff(mean_h)  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π = –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–≤–µ—Ç–ª–æ–º—É
    grad_w_pos = np.diff(mean_w)
    
    # –ù–∞—Ö–æ–¥–∏–º –æ–±–ª–∞—Å—Ç–∏ —Å –≤—ã—Å–æ–∫–æ–π —è—Ä–∫–æ—Å—Ç—å—é (—á–µ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–µ–ª—ã–º –∏–ª–∏ –∂–µ–ª—Ç–æ–≤–∞—Ç—ã–º)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è —É—á–µ—Ç–∞ —Ä–∞–∑–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤ —á–µ–∫–æ–≤
    brightness_threshold_h = np.percentile(mean_h, 55)  # 55-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å - –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
    brightness_threshold_w = np.percentile(mean_w, 55)
    
    # –¢–∞–∫–∂–µ –≤—ã—á–∏—Å–ª—è–µ–º –º–µ–¥–∏–∞–Ω—É –¥–ª—è –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è—Ä–∫–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π
    median_h = np.median(mean_h)
    median_w = np.median(mean_w)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º—É–º –∏–∑ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è –∏ –º–µ–¥–∏–∞–Ω—ã –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    brightness_threshold_h = max(brightness_threshold_h, median_h * 0.8)
    brightness_threshold_w = max(brightness_threshold_w, median_w * 0.8)
    
    # –®–ê–ì 1: –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã (top/bottom) –ø–æ –≤—Å–µ–π —à–∏—Ä–∏–Ω–µ
    # –í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞, –≥–¥–µ —è—Ä–∫–æ—Å—Ç—å —Ä–µ–∑–∫–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –ò –æ—Å—Ç–∞–µ—Ç—Å—è –≤—ã—Å–æ–∫–æ–π
    # –ò–ª–∏ –≥–¥–µ —è—Ä–∫–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ –∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Å—Ç—Ä–æ–∫–∞ –±—ã–ª–∞ —Ç–µ–º–Ω–µ–µ
    top = None
    for i in range(h - 1):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑–∫–∏–π –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–≤–µ—Ç–ª–æ–º—É
        if grad_h_pos[i] > grad_h_threshold and mean_h[i+1] > brightness_threshold_h:
            top = i
            break
        # –ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç —Ç–µ–º–Ω–æ–≥–æ –∫ —Å–≤–µ—Ç–ª–æ–º—É
        elif i > 0 and mean_h[i] > brightness_threshold_h and mean_h[i-1] < brightness_threshold_h * 0.7:
            top = i
            break
    
    # –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞: –∏—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç —Å–≤–µ—Ç–ª–æ–≥–æ —á–µ–∫–∞ –∫ —Ç–µ–º–Ω–æ–º—É —Ñ–æ–Ω—É
    # –ò—â–µ–º –æ—Ç –Ω–∏–∑–∞ –∫ –≤–µ—Ä—Ö—É, –Ω–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É —Å –≤—ã—Å–æ–∫–æ–π —è—Ä–∫–æ—Å—Ç—å—é,
    # –∑–∞—Ç–µ–º –∏—â–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É, –≥–¥–µ —è—Ä–∫–æ—Å—Ç—å —Ä–µ–∑–∫–æ –ø–∞–¥–∞–µ—Ç (–∫–æ–Ω–µ—Ü —á–µ–∫–∞)
    bottom = None
    # –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —è—Ä–∫—É—é —Å—Ç—Ä–æ–∫—É
    last_bright_row = None
    for i in range(h - 1, top if top is not None else 0, -1):
        if mean_h[i] > brightness_threshold_h:
            last_bright_row = i
            break
    
    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —è—Ä–∫—É—é —Å—Ç—Ä–æ–∫—É, –∏—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Ç–µ–º–Ω–æ–º—É (–∫–æ–Ω–µ—Ü —á–µ–∫–∞)
    if last_bright_row is not None:
        # –ò—â–µ–º –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π —è—Ä–∫–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–∞–ª—å—à–µ –≤–Ω–∏–∑, –≥–¥–µ —è—Ä–∫–æ—Å—Ç—å —Ä–µ–∑–∫–æ –ø–∞–¥–∞–µ—Ç
        for i in range(last_bright_row, min(h - 1, last_bright_row + 50), 1):
            if i < h - 1:
                # –ï—Å–ª–∏ —è—Ä–∫–æ—Å—Ç—å —Ä–µ–∑–∫–æ —É–ø–∞–ª–∞ (–ø–µ—Ä–µ—Ö–æ–¥ –∫ —Ç–µ–º–Ω–æ–º—É —Ñ–æ–Ω—É)
                if mean_h[i] < brightness_threshold_h * 0.7:
                    bottom = i - 1  # –ë–µ—Ä–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å—Ç—Ä–æ–∫—É (–ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ —á–µ–∫–∞)
                    break
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —è—Ä–∫—É—é —Å—Ç—Ä–æ–∫—É
        if bottom is None:
            bottom = last_bright_row
    
    logging.info(f"[BRIGHTNESS] Step 1 - Vertical boundaries: top={top}, bottom={bottom}")
    
    # –®–ê–ì 2: –í –Ω–∞–π–¥–µ–Ω–Ω–æ–π –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏—â–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã (left/right)
    # –≠—Ç–æ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –º—ã –∏—â–µ–º —Ç–æ–ª—å–∫–æ –≤ –æ–±–ª–∞—Å—Ç–∏, –≥–¥–µ –µ—Å—Ç—å —á–µ–∫
    if top is not None and bottom is not None and bottom > top:
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —è—Ä–∫–æ—Å—Ç—å –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º –¢–û–õ–¨–ö–û –≤ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ —á–µ–∫–∞
        receipt_region = gray[top:bottom+1, :]
        mean_w_receipt = np.mean(receipt_region, axis=0)  # –°—Ä–µ–¥–Ω—è—è —è—Ä–∫–æ—Å—Ç—å –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º –≤ –æ–±–ª–∞—Å—Ç–∏ —á–µ–∫–∞
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏
        grad_w_receipt = np.abs(np.diff(mean_w_receipt))
        grad_w_threshold_receipt = np.percentile(grad_w_receipt, 90)
        grad_w_pos_receipt = np.diff(mean_w_receipt)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–¥–∏–∞–Ω—É –∫–∞–∫ –ø–æ—Ä–æ–≥ - –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤–æ –∫ –≤—ã–±—Ä–æ—Å–∞–º
        # –ß–µ–∫ –¥–æ–ª–∂–µ–Ω –∑–∞–Ω–∏–º–∞—Ç—å –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å, –ø–æ—ç—Ç–æ–º—É –∏—â–µ–º —Å—Ç–æ–ª–±—Ü—ã —è—Ä—á–µ –º–µ–¥–∏–∞–Ω—ã
        median_w_receipt = np.median(mean_w_receipt)
        brightness_threshold_w_receipt = median_w_receipt * 0.9  # 90% –æ—Ç –º–µ–¥–∏–∞–Ω—ã
        
        # –¢–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        grad_w_threshold_receipt = np.percentile(grad_w_receipt, 85)  # 85-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å
        
        logging.info(f"[BRIGHTNESS] Receipt region brightness range: [{np.min(mean_w_receipt):.1f}, {np.max(mean_w_receipt):.1f}], median={median_w_receipt:.1f}")
        logging.info(f"[BRIGHTNESS] Receipt region threshold: {brightness_threshold_w_receipt:.1f} (90% of median)")
        
        # –õ–µ–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞: –∏—â–µ–º –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —á–µ–∫
        # –ò—â–µ–º –æ—Ç —Å–∞–º–æ–≥–æ –ª–µ–≤–æ–≥–æ –∫—Ä–∞—è (0) –∫ –ø—Ä–∞–≤–æ–º—É, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –ø–µ—Ä–≤—ã–π —è—Ä–∫–∏–π —Å—Ç–æ–ª–±–µ—Ü
        left = None
        
        # –ò—â–µ–º –æ—Ç –ª–µ–≤–æ–≥–æ –∫—Ä–∞—è (0) –∫ –ø—Ä–∞–≤–æ–º—É
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ–¥—Ö–æ–¥: –∏—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç —Ç–µ–º–Ω–æ–≥–æ —Ñ–æ–Ω–∞ –∫ —Å–≤–µ—Ç–ª–æ–º—É —á–µ–∫—É
        for i in range(w - 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑–∫–∏–π –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–≤–µ—Ç–ª–æ–º—É (–≥—Ä–∞–¥–∏–µ–Ω—Ç)
            if grad_w_pos_receipt[i] > grad_w_threshold_receipt:
                # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å—Ç–æ–ª–±–µ—Ü —è—Ä–∫–∏–π, –∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–µ–º–Ω—ã–π - —ç—Ç–æ –Ω–∞—á–∞–ª–æ —á–µ–∫–∞
                if i > 0 and mean_w_receipt[i+1] > brightness_threshold_w_receipt and mean_w_receipt[i-1] < brightness_threshold_w_receipt * 0.7:
                    left = i
                    logging.info(f"[BRIGHTNESS] Found left boundary at {i} (gradient transition)")
                    break
                # –ò–ª–∏ –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —Å—Ç–æ–ª–±–µ—Ü —É–∂–µ —è—Ä–∫–∏–π, –∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –±—ã–ª —Ç–µ–º–Ω—ã–º
                elif i > 0 and mean_w_receipt[i] > brightness_threshold_w_receipt and mean_w_receipt[i-1] < brightness_threshold_w_receipt * 0.7:
                    left = i
                    logging.info(f"[BRIGHTNESS] Found left boundary at {i} (brightness transition)")
                    break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã, –∏—â–µ–º –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–≤—ã–π —è—Ä–∫–∏–π —Å—Ç–æ–ª–±–µ—Ü –æ—Ç –ª–µ–≤–æ–≥–æ –∫—Ä–∞—è
        if left is None:
            for i in range(w):
                if mean_w_receipt[i] > brightness_threshold_w_receipt:
                    left = i
                    logging.info(f"[BRIGHTNESS] Found left boundary at {i} (first bright column)")
                    break
        
        # –ü—Ä–∞–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞: –∏—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç —Å–≤–µ—Ç–ª–æ–≥–æ —á–µ–∫–∞ –∫ —Ç–µ–º–Ω–æ–º—É —Ñ–æ–Ω—É
        # –ò—â–µ–º –æ—Ç –ø—Ä–∞–≤–æ–≥–æ –∫—Ä–∞—è –∫ –ª–µ–≤–æ–º—É, –Ω–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —è—Ä–∫–∏–π —Å—Ç–æ–ª–±–µ—Ü
        right = None
        last_bright_col = None
        
        # –ò—â–µ–º –æ—Ç –ø—Ä–∞–≤–æ–≥–æ –∫—Ä–∞—è –∫ –ª–µ–≤–æ–º—É, –Ω–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —è—Ä–∫–∏–π —Å—Ç–æ–ª–±–µ—Ü
        for i in range(w - 1, left if left is not None else 0, -1):
            if mean_w_receipt[i] > brightness_threshold_w_receipt:
                last_bright_col = i
                break
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —è—Ä–∫–∏–π —Å—Ç–æ–ª–±–µ—Ü, –∏—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Ç–µ–º–Ω–æ–º—É (–ø—Ä–∞–≤—ã–π –∫—Ä–∞–π —á–µ–∫–∞)
        if last_bright_col is not None:
            # –ò—â–µ–º –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —è—Ä–∫–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –¥–∞–ª—å—à–µ –≤–ø—Ä–∞–≤–æ, –≥–¥–µ —è—Ä–∫–æ—Å—Ç—å —Ä–µ–∑–∫–æ –ø–∞–¥–∞–µ—Ç
            for i in range(last_bright_col, min(w - 1, last_bright_col + 50), 1):
                if i < w - 1:
                    # –ï—Å–ª–∏ —è—Ä–∫–æ—Å—Ç—å —Ä–µ–∑–∫–æ —É–ø–∞–ª–∞ (–ø–µ—Ä–µ—Ö–æ–¥ –∫ —Ç–µ–º–Ω–æ–º—É —Ñ–æ–Ω—É)
                    if mean_w_receipt[i] < brightness_threshold_w_receipt * 0.7:
                        right = i - 1  # –ë–µ—Ä–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å—Ç–æ–ª–±–µ—Ü (–ø–æ—Å–ª–µ–¥–Ω–∏–π —Å—Ç–æ–ª–±–µ—Ü —á–µ–∫–∞)
                        logging.info(f"[BRIGHTNESS] Found right boundary at {right} (transition to dark)")
                        break
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —è—Ä–∫–∏–π —Å—Ç–æ–ª–±–µ—Ü
            if right is None:
                right = last_bright_col
                logging.info(f"[BRIGHTNESS] Found right boundary at {right} (last bright column)")
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –º–µ—Ç–æ–¥
        if right is None:
            for i in range(w - 1, left if left is not None else 0, -1):
                if mean_w_receipt[i] > brightness_threshold_w_receipt:
                    right = i
                    logging.info(f"[BRIGHTNESS] Found right boundary at {right} (fallback)")
                    break
        
        logging.info(f"[BRIGHTNESS] Step 2 - Horizontal boundaries in receipt region: left={left}, right={right}")
    else:
        # Fallback: –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
        logging.warning("[BRIGHTNESS] Could not find vertical boundaries, using full-width search")
        left = None
        for i in range(w - 1):
            if grad_w_pos[i] > grad_w_threshold and mean_w[i+1] > brightness_threshold_w:
                left = i
                break
        
        right = None
        for i in range(w - 1, 0, -1):
            if mean_w[i] > brightness_threshold_w:
                right = i
                break
    
    logging.info(f"[BRIGHTNESS] Found boundaries: top={top}, bottom={bottom}, left={left}, right={right}")
    
    if top is not None and bottom is not None and left is not None and right is not None:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –≥—Ä–∞–Ω–∏—Ü
        if bottom > top and right > left:
                area_h = bottom - top
                area_w = right - left
                area_percent = (area_h * area_w) / (h * w) * 100
                
                logging.info(f"[BRIGHTNESS] Area size: {area_w}x{area_h} ({area_percent:.1f}% of image)")
                
                # –ß–µ–∫ –¥–æ–ª–∂–µ–Ω –∑–∞–Ω–∏–º–∞—Ç—å –º–∏–Ω–∏–º—É–º 45% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–Ω–µ–º–Ω–æ–≥–æ —Å–Ω–∏–∑–∏–ª–∏ –¥–ª—è —É—á–µ—Ç–∞ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–µ–π)
                min_area_percent = 45
                max_area_percent = 95
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                left_original = left
                right_original = right
                area_w_original = area_w
                area_percent_original = area_percent
                
                # –ï—Å–ª–∏ –æ–±–ª–∞—Å—Ç—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞, –ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–µ –ø–æ—Ä–æ–≥–∏
                if area_percent < min_area_percent:
                    logging.warning(f"[BRIGHTNESS] Area too small ({area_percent:.1f}%), trying softer thresholds")
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥—Ä–∞–Ω–∏—Ü
                    brightness_threshold_w_receipt_soft = np.percentile(mean_w_receipt, 50)  # 50-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å
                    grad_w_threshold_receipt_soft = np.percentile(grad_w_receipt, 80)  # 80-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å
                    
                    # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ª–µ–≤—É—é –≥—Ä–∞–Ω–∏—Ü—É
                    left_soft = None
                    for i in range(w - 1):
                        if grad_w_pos_receipt[i] > grad_w_threshold_receipt_soft and mean_w_receipt[i+1] > brightness_threshold_w_receipt_soft:
                            left_soft = i
                            break
                    
                    # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∞–≤—É—é –≥—Ä–∞–Ω–∏—Ü—É
                    right_soft = None
                    for i in range(w - 1, 0, -1):
                        if mean_w_receipt[i] > brightness_threshold_w_receipt_soft:
                            right_soft = i
                            break
                    
                    if left_soft is not None and right_soft is not None and right_soft > left_soft:
                        area_w_soft = right_soft - left_soft
                        area_percent_soft = (area_h * area_w_soft) / (h * w) * 100
                        logging.info(f"[BRIGHTNESS] Soft thresholds: left={left_soft}, right={right_soft}, area={area_percent_soft:.1f}%")
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º soft thresholds, –µ—Å–ª–∏ –æ–Ω–∏ –ª—É—á—à–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∏–ª–∏ –≤ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
                        logging.info(f"[BRIGHTNESS] Comparing: soft={area_percent_soft:.1f}% vs original={area_percent_original:.1f}%, min={min_area_percent}%, max={max_area_percent}%")
                        if area_percent_soft > area_percent_original and area_percent_soft <= max_area_percent:
                            left = left_soft
                            right = right_soft
                            area_w = area_w_soft
                            area_percent = area_percent_soft
                            logging.info(f"[BRIGHTNESS] ‚úì Using soft thresholds (better): area={area_percent:.1f}% vs original {area_percent_original:.1f}%")
                        elif min_area_percent <= area_percent_soft <= max_area_percent:
                            left = left_soft
                            right = right_soft
                            area_w = area_w_soft
                            area_percent = area_percent_soft
                            logging.info(f"[BRIGHTNESS] ‚úì Using soft thresholds (in range): area={area_percent:.1f}%")
                        else:
                            logging.warning(f"[BRIGHTNESS] ‚úó Soft thresholds rejected: {area_percent_soft:.1f}% (better check: {area_percent_soft > area_percent_original}, in range: {min_area_percent <= area_percent_soft <= max_area_percent})")
                
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º area_percent –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
                area_w = right - left
                area_percent = (area_h * area_w) / (h * w) * 100
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±–ª–∞—Å—Ç—å –≤ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
                logging.info(f"[BRIGHTNESS] Final check: area={area_w}x{area_h} ({area_percent:.1f}%), min={min_area_percent}%, max={max_area_percent}%")
                if min_area_percent <= area_percent <= max_area_percent and area_h > 50 and area_w > 50:
                    # –°–æ–∑–¥–∞–µ–º —É–≥–ª—ã
                    box = np.array([
                        [left, top],
                        [left, bottom],
                        [right, bottom],
                        [right, top]
                    ], dtype=np.float32)
                    logging.info(f"[BRIGHTNESS] Found corners: {box}")
                    
                    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
                    result_image = image_bgr.copy()
                    
                    # 1. –†–∏—Å—É–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ —è—Ä–∫–æ—Å—Ç–∏ –ø–æ –∫—Ä–∞—è–º
                    max_h = np.max(mean_h) if np.max(mean_h) > 0 else 1
                    max_w = np.max(mean_w) if np.max(mean_w) > 0 else 1
                    
                    # –ì—Ä–∞—Ñ–∏–∫ —è—Ä–∫–æ—Å—Ç–∏ —Å–ª–µ–≤–∞ (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π)
                    graph_width = min(100, w // 10)
                    for y_idx in range(h):
                        bar_height = int((mean_h[y_idx] / max_h) * graph_width)
                        color = (0, 255, 0) if mean_h[y_idx] > brightness_threshold_h else (0, 0, 255)
                        cv2.line(result_image, (0, y_idx), (bar_height, y_idx), color, 1)
                    
                    # –ì—Ä–∞—Ñ–∏–∫ —è—Ä–∫–æ—Å—Ç–∏ —Å–≤–µ—Ä—Ö—É (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)
                    graph_height = min(100, h // 10)
                    for x_idx in range(w):
                        bar_width = int((mean_w[x_idx] / max_w) * graph_height)
                        color = (0, 255, 0) if mean_w[x_idx] > brightness_threshold_w else (0, 0, 255)
                        cv2.line(result_image, (x_idx, 0), (x_idx, bar_width), color, 1)
                    
                    # 2. –†–∏—Å—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
                    # –í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
                    if top is not None:
                        cv2.line(result_image, (0, top), (w, top), (255, 0, 255), 2)  # –ü—É—Ä–ø—É—Ä–Ω—ã–π
                        cv2.putText(result_image, f"TOP:{top}", (10, top - 5), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                    
                    # –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞
                    if bottom is not None:
                        cv2.line(result_image, (0, bottom), (w, bottom), (255, 0, 255), 2)
                        cv2.putText(result_image, f"BOTTOM:{bottom}", (10, bottom + 20), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                    
                    # –õ–µ–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞
                    if left is not None:
                        cv2.line(result_image, (left, 0), (left, h), (255, 0, 255), 2)
                        cv2.putText(result_image, f"LEFT:{left}", (left + 5, 20), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                    
                    # –ü—Ä–∞–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞
                    if right is not None:
                        cv2.line(result_image, (right, 0), (right, h), (255, 0, 255), 2)
                        cv2.putText(result_image, f"RIGHT:{right}", (right - 80, 20), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                    
                    # 3. –í—ã–¥–µ–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é –æ–±–ª–∞—Å—Ç—å
                    overlay = result_image.copy()
                    cv2.rectangle(overlay, (left, top), (right, bottom), (0, 255, 255), -1)  # –ñ–µ–ª—Ç—ã–π
                    cv2.addWeighted(overlay, 0.3, result_image, 0.7, 0, result_image)
                    
                    # 4. –†–∏—Å—É–µ–º —Ä–∞–º–∫—É
                    cv2.rectangle(result_image, (left, top), (right, bottom), (0, 255, 255), 3)
                    
                    # 5. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    info_text = f"BRIGHTNESS: {area_w}x{area_h} ({area_percent:.1f}%)"
                    cv2.putText(result_image, info_text, (left, top - 15), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                    
                    # 6. –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Ä–æ–≥–∞—Ö
                    threshold_text = f"h_th={brightness_threshold_h:.0f}, w_th={brightness_threshold_w_receipt:.0f}"
                    cv2.putText(result_image, threshold_text, (left, bottom + 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
                    
                    return box, result_image
                else:
                    logging.warning(f"[BRIGHTNESS] Area too large or too small: {area_percent:.1f}%")
                    # –í—Å–µ —Ä–∞–≤–Ω–æ —Å–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
                    result_image = image_bgr.copy()
                    if top is not None and bottom is not None and left is not None and right is not None:
                        # –†–∏—Å—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
                        if top is not None:
                            cv2.line(result_image, (0, top), (w, top), (255, 0, 255), 2)
                            cv2.putText(result_image, f"TOP:{top}", (10, top - 5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                        if bottom is not None:
                            cv2.line(result_image, (0, bottom), (w, bottom), (255, 0, 255), 2)
                            cv2.putText(result_image, f"BOTTOM:{bottom}", (10, bottom + 20), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                        if left is not None:
                            cv2.line(result_image, (left, 0), (left, h), (255, 0, 255), 2)
                            cv2.putText(result_image, f"LEFT:{left}", (left + 5, 20), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                        if right is not None:
                            cv2.line(result_image, (right, 0), (right, h), (255, 0, 255), 2)
                            cv2.putText(result_image, f"RIGHT:{right}", (right - 80, 20), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
                        info_text = f"BRIGHTNESS: Area {area_percent:.1f}% (invalid)"
                        cv2.putText(result_image, info_text, (10, 30), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    return None, result_image
        else:
            logging.warning(f"[BRIGHTNESS] Invalid boundaries: top={top}, bottom={bottom}, left={left}, right={right}")
    else:
        logging.warning(f"[BRIGHTNESS] Missing boundaries: top={top}, bottom={bottom}, left={left}, right={right}")
    
    logging.warning("[BRIGHTNESS] Failed to find corners")
    # –í—Å–µ —Ä–∞–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    result_image = image_bgr.copy()
    info_text = "BRIGHTNESS: No corners found"
    cv2.putText(result_image, info_text, (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    return None, result_image


def _find_corners_by_contour(image: np.ndarray, gray: np.ndarray, image_bgr: np.ndarray) -> tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
    """
    –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ —É–≥–ª–æ–≤ —á–µ—Ä–µ–∑ –∫–æ–Ω—Ç—É—Ä—ã.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (box, largest_contour, result_image) –∏–ª–∏ (None, None, None) –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.
    """
    h, w = gray.shape[:2]
    
    # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤
    all_contours = []
    
    # –ú–µ—Ç–æ–¥ 1: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–≤–µ—Ç–ª—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π (—á–µ–∫–∏ –æ–±—ã—á–Ω–æ —Å–≤–µ—Ç–ª—ã–µ)
    adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                             cv2.THRESH_BINARY_INV, 11, 2)
    
    # –ú–µ—Ç–æ–¥ 2: –ü–æ—Ä–æ–≥–æ–≤–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
    _, binary_white1 = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
    _, binary_white2 = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)
    _, binary_white3 = cv2.threshold(gray, 160, 255, cv2.THRESH_BINARY_INV)
    
    # –ú–µ—Ç–æ–¥ 3: Canny –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫—Ä–∞–µ–≤
    edges = cv2.Canny(gray, 50, 150)
    
    # –ú–µ—Ç–æ–¥ 4: –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫—Ä–∞–µ–≤ —á–µ–∫–∞
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    grad_mag = np.sqrt(grad_x**2 + grad_y**2)
    grad_mag = np.uint8(255 * grad_mag / (np.max(grad_mag) + 1e-5))
    _, grad_binary = cv2.threshold(grad_mag, 30, 255, cv2.THRESH_BINARY)  # –°–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥
    
    # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã
    combined = cv2.bitwise_or(adaptive_thresh, binary_white1)
    combined = cv2.bitwise_or(combined, binary_white2)
    combined = cv2.bitwise_or(combined, binary_white3)
    combined = cv2.bitwise_or(combined, edges)
    combined = cv2.bitwise_or(combined, grad_binary)
    
    # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è - –º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è
    kernel_small = np.ones((5, 5), np.uint8)
    kernel_medium = np.ones((10, 10), np.uint8)
    kernel_large = np.ones((15, 15), np.uint8)
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏
    variants = []
    
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –ú—è–≥–∫–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è
    closed1 = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel_medium, iterations=2)
    opened1 = cv2.morphologyEx(closed1, cv2.MORPH_OPEN, kernel_small, iterations=1)
    variants.append(opened1)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 2: –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è
    closed2 = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel_large, iterations=2)
    opened2 = cv2.morphologyEx(closed2, cv2.MORPH_OPEN, kernel_medium, iterations=1)
    variants.append(opened2)
    
    # –í–∞—Ä–∏–∞–Ω—Ç 3: –î–∏–ª–∞—Ç–∞—Ü–∏—è –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Ä–∞–∑—Ä—ã–≤–æ–≤
    dilated = cv2.dilate(combined, kernel_medium, iterations=2)
    closed3 = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel_large, iterations=1)
    variants.append(closed3)
    
    # –ò—â–µ–º –∫–æ–Ω—Ç—É—Ä—ã –≤–æ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö
    all_contours = []
    for variant in variants:
        contours, _ = cv2.findContours(variant, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        all_contours.extend(contours)
        logging.info(f"[CONTOUR] Found {len(contours)} contours in variant")
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–∫–æ–Ω—Ç—É—Ä—ã —Å –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–º–∏ –ø–ª–æ—â–∞–¥—è–º–∏ –∏ —Ü–µ–Ω—Ç—Ä–∞–º–∏)
    unique_contours = []
    seen_areas = set()
    for contour in all_contours:
        area = cv2.contourArea(contour)
        M = cv2.moments(contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–ª–æ—â–∞–¥–∏ –∏ —Ü–µ–Ω—Ç—Ä—É
            area_key = (area // 1000, cx // 50, cy // 50)
            if area_key not in seen_areas:
                seen_areas.add(area_key)
                unique_contours.append(contour)
    
    contours = unique_contours
    logging.info(f"[CONTOUR] Total unique contours: {len(contours)}")
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —à–∞–≥–æ–≤
    debug_image = image_bgr.copy()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    debug_overlay = debug_image.copy()
    combined_colored = cv2.cvtColor(combined, cv2.COLOR_GRAY2BGR)
    cv2.addWeighted(debug_overlay, 0.3, combined_colored, 0.7, 0, debug_image)
    
    if not contours:
        logging.warning("[CONTOUR] No contours found")
        info_text = "CONTOUR: No contours found"
        cv2.putText(debug_image, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        return None, None, debug_image
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä—ã –ø–æ –ø–ª–æ—â–∞–¥–∏
    contours_sorted = sorted(contours, key=cv2.contourArea, reverse=True)
    
    # –†–∏—Å—É–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç—É—Ä—ã —Ä–∞–∑–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏ (–±–æ–ª—å—à–µ –∫–æ–Ω—Ç—É—Ä–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
    for idx, contour in enumerate(contours_sorted[:15]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 15 –∫–æ–Ω—Ç—É—Ä–æ–≤
        color = (
            (idx * 17) % 255,
            (idx * 37) % 255,
            (idx * 53) % 255
        )
        cv2.drawContours(debug_image, [contour], -1, color, 2)
        area = cv2.contourArea(contour)
        area_percent = area / (h * w) * 100
        # –ù–∞—Ö–æ–¥–∏–º —Ü–µ–Ω—Ç—Ä –∫–æ–Ω—Ç—É—Ä–∞ –¥–ª—è –ø–æ–¥–ø–∏—Å–∏
        M = cv2.moments(contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(debug_image, f"C{idx}:{area_percent:.1f}%", (cx, cy), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
    
    largest_contour = None
    box = None
    
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ç—É—Ä, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —É–≥–ª–∞–º–∏ –∫–∞–¥—Ä–∞
    # –°–Ω–∏–∂–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø–ª–æ—â–∞–¥—å –¥–æ 5% (–±—ã–ª–æ 10%)
    min_area_percent = 5.0
    min_area = min_area_percent / 100.0 * h * w
    
    for contour in contours_sorted:
        area = cv2.contourArea(contour)
        area_percent = area / (h * w) * 100
        
        if area < min_area:
            logging.debug(f"[CONTOUR] Skipping contour: area {area_percent:.1f}% < {min_area_percent}%")
            continue
        
        # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä –¥–æ 4 —Ç–æ—á–µ–∫
        epsilon = 0.02 * cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon, True)
        
        if len(approx) < 4:
            # –ï—Å–ª–∏ –Ω–µ 4 —Ç–æ—á–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            rect = cv2.minAreaRect(contour)
            approx_box = cv2.boxPoints(rect)
        else:
            if len(approx) == 4:
                approx_box = approx.reshape(4, 2)
            else:
                # –ë–µ—Ä–µ–º 4 –∫—Ä–∞–π–Ω–∏–µ —Ç–æ—á–∫–∏
                x_coords = approx[:, 0, 0]
                y_coords = approx[:, 0, 1]
                approx_box = np.array([
                    [np.min(x_coords), np.min(y_coords)],  # top-left
                    [np.min(x_coords), np.max(y_coords)],  # bottom-left
                    [np.max(x_coords), np.max(y_coords)],  # bottom-right
                    [np.max(x_coords), np.min(y_coords)]   # top-right
                ], dtype=np.float32)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ª–∏ —É–≥–ª—ã —É–≥–ª–∞–º–∏ –∫–∞–¥—Ä–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É - –∫–æ–Ω—Ç—É—Ä —Å—á–∏—Ç–∞–µ—Ç—Å—è —É–≥–ª–∞–º–∏ –∫–∞–¥—Ä–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏
        # –≤—Å–µ 4 —É–≥–ª–∞ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∫ –∫—Ä–∞—è–º (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 20px)
        margin = 20
        corners_near_edge = sum(
            1 for pt in approx_box
            if (pt[0] < margin or pt[0] > w - margin) and (pt[1] < margin or pt[1] > h - margin)
        )
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ç—É—Ä –Ω–µ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à—É—é –æ–±–ª–∞—Å—Ç—å (–Ω–µ –≤–µ—Å—å –∫–∞–¥—Ä)
        x_coords = approx_box[:, 0]
        y_coords = approx_box[:, 1]
        width = np.max(x_coords) - np.min(x_coords)
        height = np.max(y_coords) - np.min(y_coords)
        width_percent = width / w * 100
        height_percent = height / h * 100
        
        # –ö–æ–Ω—Ç—É—Ä —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º, –µ—Å–ª–∏:
        # 1. –ù–µ –≤—Å–µ —É–≥–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è —É –∫—Ä–∞–µ–≤ –∫–∞–¥—Ä–∞ (–º–µ–Ω—å—à–µ 3 –∏–∑ 4) - —ç—Ç–æ –≥–ª–∞–≤–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π
        # 2. –ü–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞ —Ä–∞–∑—É–º–Ω–∞—è (–Ω–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞ –∏ –Ω–µ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –≤–µ—Å—å –∫–∞–¥—Ä)
        # 3. –†–∞–∑–º–µ—Ä—ã bounding box –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        
        # –ì–ª–∞–≤–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π: –µ—Å–ª–∏ –Ω–µ –≤—Å–µ —É–≥–ª—ã —É –∫—Ä–∞–µ–≤, –∫–æ–Ω—Ç—É—Ä —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤–∞–ª–∏–¥–Ω—ã–π
        # –î–∞–∂–µ –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –±–æ–ª—å—à–∏–µ, –Ω–æ —É–≥–ª—ã –Ω–µ —É –∫—Ä–∞–µ–≤ - —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–æ–π —á–µ–∫
        is_valid_by_corners = corners_near_edge < 3
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –ø–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–∞ –∫ –ø–ª–æ—â–∞–¥–∏ –≤—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # (–µ—Å–ª–∏ –∫–æ–Ω—Ç—É—Ä –ø–æ–∫—Ä—ã–≤–∞–µ—Ç >95% –ø–ª–æ—â–∞–¥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —ç—Ç–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Ä–∞–º–∫–∞)
        area_ratio = area / (h * w)
        is_valid_by_area = area_ratio < 0.95
        
        # –†–∞–∑–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–µ –¥–ª—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
        is_valid = is_valid_by_corners and is_valid_by_area
        
        if is_valid:
            largest_contour = contour
            box = approx_box
            logging.info(f"[CONTOUR] Found valid contour: area = {area_percent:.1f}%, "
                        f"size = {width_percent:.1f}% x {height_percent:.1f}%, "
                        f"corners_near_edge = {corners_near_edge}, corners = {box}")
            break
        elif is_valid_by_corners and not is_valid_by_area:
            # –ï—Å–ª–∏ —É–≥–ª—ã –Ω–µ —É –∫—Ä–∞–µ–≤, –Ω–æ –ø–ª–æ—â–∞–¥—å –±–æ–ª—å—à–∞—è - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –±–æ–ª—å—à–æ–π —á–µ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            logging.info(f"[CONTOUR] Using contour with large area but valid corners: "
                        f"area = {area_percent:.1f}%, corners_near_edge = {corners_near_edge}")
            largest_contour = contour
            box = approx_box
            break
        else:
            logging.debug(f"[CONTOUR] Rejected contour: corners_near_edge={corners_near_edge}, "
                         f"area={area_percent:.1f}%, size={width_percent:.1f}% x {height_percent:.1f}%")
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∫–æ–Ω—Ç—É—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π
    if largest_contour is None:
        largest_contour = contours_sorted[0]
        area = cv2.contourArea(largest_contour)
        area_percent = area / (h * w) * 100
        logging.info(f"[CONTOUR] Using largest contour: area = {area_percent:.1f}%")
        
        if area < min_area:
            logging.warning(f"[CONTOUR] Contour too small ({area_percent:.1f}% < {min_area_percent}%)")
            # –í—Å–µ —Ä–∞–≤–Ω–æ —Å–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            result_image = debug_image.copy()
            cv2.drawContours(result_image, [largest_contour], -1, (0, 255, 0), 5)
            info_text = f"CONTOUR: Contour too small ({area_percent:.1f}% < {min_area_percent}%)"
            cv2.putText(result_image, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            return None, None, result_image
        
        # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä –¥–æ 4 —Ç–æ—á–µ–∫
        epsilon = 0.02 * cv2.arcLength(largest_contour, True)
        approx = cv2.approxPolyDP(largest_contour, epsilon, True)
        logging.info(f"[CONTOUR] Approximated to {len(approx)} points")
        
        if len(approx) >= 4:
            if len(approx) == 4:
                box = approx.reshape(4, 2)
            else:
                rect = cv2.minAreaRect(largest_contour)
                box = cv2.boxPoints(rect)
        else:
            rect = cv2.minAreaRect(largest_contour)
            box = cv2.boxPoints(rect)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ª–∏ —É–≥–ª—ã —É–≥–ª–∞–º–∏ –∫–∞–¥—Ä–∞ (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
        margin = 20
        corners_near_edge = sum(
            1 for pt in box
            if (pt[0] < margin or pt[0] > w - margin) and (pt[1] < margin or pt[1] > h - margin)
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã
        x_coords = box[:, 0]
        y_coords = box[:, 1]
        width = np.max(x_coords) - np.min(x_coords)
        height = np.max(y_coords) - np.min(y_coords)
        width_percent = width / w * 100
        height_percent = height / h * 100
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è—é—Ç—Å—è –ª–∏ —É–≥–ª—ã —É–≥–ª–∞–º–∏ –∫–∞–¥—Ä–∞
        # –ï—Å–ª–∏ —É–≥–ª—ã –Ω–µ —É –∫—Ä–∞–µ–≤ (corners_near_edge < 3), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç—É—Ä –Ω–∞–ø—Ä—è–º—É—é, –¥–∞–∂–µ –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –±–æ–ª—å—à–∏–µ
        if corners_near_edge < 3:
            # –ö–æ–Ω—Ç—É—Ä –≤–∞–ª–∏–¥–Ω—ã–π - —É–≥–ª—ã –Ω–µ —É –∫—Ä–∞–µ–≤, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –Ω–µ —Ä–∞–º–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            logging.info(f"[CONTOUR] Using contour directly: corners_near_edge={corners_near_edge}, "
                        f"size={width_percent:.1f}% x {height_percent:.1f}%, box={box}")
            # box —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤—ã—à–µ, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
        else:
            # –£–≥–ª—ã —É –∫—Ä–∞–µ–≤ - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ —Ä–∞–º–∫–∞, –Ω–æ –ø—Ä–æ–≤–µ—Ä–∏–º –ø–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞
            area_ratio = area / (h * w)
            if area_ratio < 0.95:
                # –ü–ª–æ—â–∞–¥—å —Ä–∞–∑—É–º–Ω–∞—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç—É—Ä
                logging.info(f"[CONTOUR] Using contour despite corners near edge: "
                            f"area={area_percent:.1f}%, corners_near_edge={corners_near_edge}")
            else:
                # –ü–ª–æ—â–∞–¥—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è –∏ —É–≥–ª—ã —É –∫—Ä–∞–µ–≤ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Ä–∞–º–∫–∞
                logging.warning(f"[CONTOUR] Contour likely is frame (area={area_percent:.1f}%, "
                              f"corners_near_edge={corners_near_edge}), trying bounding box")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º bounding box —Å–∞–º–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ –∫–æ–Ω—Ç—É—Ä–∞
                x, y, w_bb, h_bb = cv2.boundingRect(largest_contour)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –≤–µ—Å—å –∫–∞–¥—Ä
                if w_bb < w * 0.98 and h_bb < h * 0.98:
                    box = np.array([
                        [x, y],
                        [x, y + h_bb],
                        [x + w_bb, y + h_bb],
                        [x + w_bb, y]
                    ], dtype=np.float32)
                    logging.info(f"[CONTOUR] Using bounding box corners: {box}")
                else:
                    # –î–∞–∂–µ bounding box –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –ø–æ—á—Ç–∏ –≤–µ—Å—å –∫–∞–¥—Ä - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–º –∫–æ–Ω—Ç—É—Ä
                    logging.warning(f"[CONTOUR] Bounding box also covers too much ({w_bb/w*100:.1f}% x {h_bb/h*100:.1f}%), "
                                  f"using contour directly")
                    # box —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ –∫–æ–Ω—Ç—É—Ä–∞ –≤—ã—à–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    result_image = debug_image.copy()
    
    # –†–∏—Å—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç—É—Ä –∑–µ–ª–µ–Ω—ã–º
    if largest_contour is not None:
        cv2.drawContours(result_image, [largest_contour], -1, (0, 255, 0), 5)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Ç–æ–¥–µ
    if box is not None:
        area = (box[2][0] - box[0][0]) * (box[2][1] - box[0][1])
        area_percent = area / (h * w) * 100
        info_text = f"CONTOUR: {len(contours)} contours, area={area_percent:.1f}%"
        cv2.putText(result_image, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    return box, largest_contour, result_image


def _find_corners_by_text(image: np.ndarray, gray: np.ndarray, image_bgr: np.ndarray) -> tuple[Optional[np.ndarray], Optional[np.ndarray]]:
    """
    –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ —É–≥–ª–æ–≤ —á–µ—Ä–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (box, result_image) –∏–ª–∏ (None, None) –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.
    """
    h, w = gray.shape[:2]
    
    # –ò—â–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ —á–µ—Ä–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏
    _, binary_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    text_mask = 255 - binary_otsu
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    result_image = image_bgr.copy()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–∞—Å–∫—É (–ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω–æ)
    text_mask_colored = cv2.cvtColor(text_mask, cv2.COLOR_GRAY2BGR)
    overlay = result_image.copy()
    cv2.addWeighted(overlay, 0.7, text_mask_colored, 0.3, 0, result_image)
    
    # –ò—â–µ–º –∫—Ä–∞—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –æ–±–ª–∞—Å—Ç–∏
    horizontal_proj = np.sum(text_mask, axis=1)
    vertical_proj = np.sum(text_mask, axis=0)
    
    h_threshold = np.max(horizontal_proj) * 0.10
    v_threshold = np.max(vertical_proj) * 0.10
    
    # –†–∏—Å—É–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–æ–µ–∫—Ü–∏–π
    max_h_proj = np.max(horizontal_proj) if np.max(horizontal_proj) > 0 else 1
    max_v_proj = np.max(vertical_proj) if np.max(vertical_proj) > 0 else 1
    
    # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è —Å–ª–µ–≤–∞ (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–¥–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –ø–æ —Å—Ç—Ä–æ–∫–∞–º)
    graph_width = min(150, w // 8)
    for y_idx in range(h):
        bar_width = int((horizontal_proj[y_idx] / max_h_proj) * graph_width)
        color = (0, 255, 0) if horizontal_proj[y_idx] > h_threshold else (0, 0, 255)
        cv2.line(result_image, (0, y_idx), (bar_width, y_idx), color, 1)
    
    # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è —Å–≤–µ—Ä—Ö—É (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–¥–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º)
    graph_height = min(150, h // 8)
    for x_idx in range(w):
        bar_height = int((vertical_proj[x_idx] / max_v_proj) * graph_height)
        color = (0, 255, 0) if vertical_proj[x_idx] > v_threshold else (0, 0, 255)
        cv2.line(result_image, (x_idx, 0), (x_idx, bar_height), color, 1)
    
    h_indices = np.where(horizontal_proj > h_threshold)[0]
    v_indices = np.where(vertical_proj > v_threshold)[0]
    
    if len(h_indices) > 0 and len(v_indices) > 0:
        top = h_indices[0]
        bottom = h_indices[-1]
        left = v_indices[0]
        right = v_indices[-1]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –≤–µ—Å—å –∫–∞–¥—Ä
        if (bottom - top) < h * 0.85 and (right - left) < w * 0.85:
            # –°–æ–∑–¥–∞–µ–º —É–≥–ª—ã –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –≥—Ä–∞–Ω–∏—Ü
            box = np.array([
                [left, top],
                [left, bottom],
                [right, bottom],
                [right, top]
            ], dtype=np.float32)
            logging.info(f"[TEXT] Found corners: {box}")
            
            # –†–∏—Å—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –ø—É—Ä–ø—É—Ä–Ω—ã–º
            cv2.line(result_image, (0, top), (w, top), (255, 0, 255), 3)
            cv2.line(result_image, (0, bottom), (w, bottom), (255, 0, 255), 3)
            cv2.line(result_image, (left, 0), (left, h), (255, 0, 255), 3)
            cv2.line(result_image, (right, 0), (right, h), (255, 0, 255), 3)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            area = (right - left) * (bottom - top)
            area_percent = area / (h * w) * 100
            info_text = f"TEXT: h_th={h_threshold:.0f}, v_th={v_threshold:.0f}, area={area_percent:.1f}%"
            cv2.putText(result_image, info_text, (left, top - 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
            
            return box, result_image
    
    logging.warning("[TEXT] Failed to find corners")
    # –í—Å–µ —Ä–∞–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    info_text = f"TEXT: No corners found, h_th={h_threshold:.0f}, v_th={v_threshold:.0f}"
    cv2.putText(result_image, info_text, (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    return None, result_image


def _find_and_align_white_receipt_color_with_corners(image: np.ndarray) -> tuple[np.ndarray, bool, list]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —É–≥–ª—ã –±–µ–ª–æ–≥–æ —á–µ–∫–∞ –∏ —Ä–∏—Å—É–µ—Ç –∏—Ö –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ç–æ–¥, —É–∫–∞–∑–∞–Ω–Ω—ã–π –≤ CORNER_DETECTION_METHOD.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ—Ç–º–µ—á–µ–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏ (–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥)
    - —Ñ–ª–∞–≥, –±—ã–ª–∏ –ª–∏ –Ω–∞–π–¥–µ–Ω—ã —É–≥–ª—ã
    - —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ [(method_name, image, area_percent), ...]
    """
    try:
        h, w = image.shape[:2]
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–µ–ª–æ–≥–æ —á–µ–∫–∞
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        else:
            gray = image
            image_bgr = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        
        method = CORNER_DETECTION_METHOD
        logging.info(f"Using corner detection method: {method} (will run all methods for visualization)")
        
        box = None
        largest_contour = None
        result_image = None
        all_method_results = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        # –í–°–ï–ì–î–ê –ø—Ä–æ–≥–æ–Ω—è–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, –Ω–æ –≤—ã–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ –º–µ—Ç–æ–¥—É
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ
        method_results = {}  # {method_name: (box, image, area_percent, contour)}
        
        # –ú–µ—Ç–æ–¥ 1: Brightness
        try:
            box_b, img_b = _find_corners_by_brightness(image, gray, image_bgr)
            if img_b is not None:
                if box_b is not None:
                    area_b = (box_b[2][0] - box_b[0][0]) * (box_b[2][1] - box_b[0][1])
                    area_percent_b = area_b / (h * w) * 100
                else:
                    area_percent_b = 0.0
                method_results["brightness"] = (box_b, img_b, area_percent_b, None)
                all_method_results.append(("brightness", img_b.copy(), area_percent_b))
                logging.info(f"[VISUALIZATION] Brightness method: area {area_percent_b:.1f}%")
        except Exception as exc:
            logging.warning(f"[VISUALIZATION] Brightness method failed: {exc}")
        
        # –ú–µ—Ç–æ–¥ 2: Contour
        try:
            box_c, contour_c, img_c = _find_corners_by_contour(image, gray, image_bgr)
            if img_c is not None:
                if box_c is not None:
                    area_c = (box_c[2][0] - box_c[0][0]) * (box_c[2][1] - box_c[0][1])
                    area_percent_c = area_c / (h * w) * 100
                    if largest_contour is None:
                        largest_contour = contour_c
                else:
                    area_percent_c = 0.0
                method_results["contour"] = (box_c, img_c, area_percent_c, contour_c)
                all_method_results.append(("contour", img_c.copy(), area_percent_c))
                logging.info(f"[VISUALIZATION] Contour method: area {area_percent_c:.1f}%")
        except Exception as exc:
            logging.warning(f"[VISUALIZATION] Contour method failed: {exc}")
        
        # –ú–µ—Ç–æ–¥ 3: Text
        try:
            box_t, img_t = _find_corners_by_text(image, gray, image_bgr)
            if img_t is not None:
                if box_t is not None:
                    area_t = (box_t[2][0] - box_t[0][0]) * (box_t[2][1] - box_t[0][1])
                    area_percent_t = area_t / (h * w) * 100
                else:
                    area_percent_t = 0.0
                method_results["text"] = (box_t, img_t, area_percent_t, None)
                all_method_results.append(("text", img_t.copy(), area_percent_t))
                logging.info(f"[VISUALIZATION] Text method: area {area_percent_t:.1f}%")
        except Exception as exc:
            logging.warning(f"[VISUALIZATION] Text method failed: {exc}")
        
        # –¢–µ–ø–µ—Ä—å –≤—ã–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞
        if method == "all":
            logging.info("Selecting best result from all methods...")
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏
            results = []
            for method_name, (method_box, method_img, method_area, method_contour) in method_results.items():
                if method_box is not None:
                    results.append((method_name, method_box, method_img, method_area))
                    if method_contour is not None and largest_contour is None:
                        largest_contour = method_contour
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if results:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ –∏–¥–µ–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É (50-70% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                ideal_min, ideal_max = 50, 70
                results.sort(key=lambda x: abs(x[3] - (ideal_min + ideal_max) / 2))
                
                best_method, box, result_image, area_percent = results[0]
                logging.info(f"[ALL] Selected best method: {best_method} with area {area_percent:.1f}%")
                
                # –ï—Å–ª–∏ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—à–∫–æ–º –º–∞–ª –∏–ª–∏ –≤–µ–ª–∏–∫, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ
                if area_percent < 40 or area_percent > 90:
                    for method_name, method_box, method_img, method_area in results[1:]:
                        if 40 <= method_area <= 90:
                            best_method, box, result_image, area_percent = method_name, method_box, method_img, method_area
                            logging.info(f"[ALL] Switched to {best_method} with better area {method_area:.1f}%")
                            break
            else:
                logging.warning("[ALL] All methods failed to find corners")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤–æ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ
                if all_method_results:
                    result_image = all_method_results[0][1].copy()
                else:
                    result_image = image_bgr.copy()
                return result_image, False, all_method_results
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
            if method in method_results:
                box, result_image, area_percent, method_contour = method_results[method]
                if method_contour is not None:
                    largest_contour = method_contour
                logging.info(f"[{method.upper()}] Using {method} method result: area {area_percent:.1f}%")
            else:
                logging.warning(f"[{method.upper()}] Method {method} result not found, using brightness")
                if "brightness" in method_results:
                    box, result_image, area_percent, _ = method_results["brightness"]
                else:
                    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    result_image = image_bgr.copy()
                    box = None
            
            if box is None:
                logging.warning(f"[{method.upper()}] Failed to find corners")
                if result_image is None:
                    result_image = image_bgr.copy()
                return result_image, False, all_method_results
        
        # –†–∏—Å—É–µ–º –∫–æ–Ω—Ç—É—Ä (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏ —É–≥–ª—ã
        # –î–ª—è –º–µ—Ç–æ–¥–∞ contour –∏ —Ä–µ–∂–∏–º–∞ all —Ä–∏—Å—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç—É—Ä
        if (method == "contour" or method == "all") and largest_contour is not None:
            cv2.drawContours(result_image, [largest_contour], -1, (0, 255, 0), 5)
        
        logging.info(f"Drawing corners: final box points = {box}")
        
        # –†–∏—Å—É–µ–º –ª–∏–Ω–∏–∏ –º–µ–∂–¥—É —É–≥–ª–∞–º–∏ (—Å–∏–Ω–∏–µ, —Ç–æ–ª—Å—Ç—ã–µ)
        for i in range(4):
            pt1 = tuple(map(int, box[i]))
            pt2 = tuple(map(int, box[(i + 1) % 4]))
            cv2.line(result_image, pt1, pt2, (255, 0, 0), 5)
            logging.info(f"Drawing line from {pt1} to {pt2}")
        
        # –†–∏—Å—É–µ–º —É–≥–ª—ã –±–æ–ª—å—à–∏–º–∏ –∫—Ä–∞—Å–Ω—ã–º–∏ –∫—Ä—É–∂–∫–∞–º–∏
        for i, point in enumerate(box):
            pt = tuple(map(int, point))
            # –ë–æ–ª—å—à–æ–π –∫—Ä–∞—Å–Ω—ã–π –∫—Ä—É–∂–æ–∫
            cv2.circle(result_image, pt, 20, (0, 0, 255), -1)
            # –ë–µ–ª–∞—è –æ–±–≤–æ–¥–∫–∞ –¥–ª—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            cv2.circle(result_image, pt, 20, (255, 255, 255), 2)
            # –ù–æ–º–µ—Ä —É–≥–ª–∞
            cv2.putText(result_image, f"{i+1}", (pt[0] + 25, pt[1] + 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
            logging.info(f"Drawing corner {i+1} at {pt}")
        
        logging.info("Drawing corners: success, returning image with corners")
        return result_image, True, all_method_results
    except Exception as exc:
        logging.debug(f"Drawing corners failed: {exc}")
        if len(image.shape) == 3:
            return cv2.cvtColor(image, cv2.COLOR_RGB2BGR), False, []
        return cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), False, []


def _find_and_align_white_receipt_color(image: np.ndarray) -> np.ndarray:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –±–µ–ª—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π —á–µ–∫ –Ω–∞ —Ü–≤–µ—Ç–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –µ–≥–æ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–æ–π.
    –†–∞–±–æ—Ç–∞–µ—Ç —Å —Ü–≤–µ—Ç–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ grayscale –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    """
    try:
        h, w = image.shape[:2]
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–µ–ª–æ–≥–æ —á–µ–∫–∞
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image
        
        # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –±–µ–ª–æ–≥–æ —á–µ–∫–∞
        # –ú–µ—Ç–æ–¥ 1: –ü—Ä–æ—Å—Ç–æ–π –ø–æ—Ä–æ–≥ –¥–ª—è –±–µ–ª–æ–≥–æ (—á–µ–∫ –æ–±—ã—á–Ω–æ –æ—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã–π)
        _, binary_white = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
        
        # –ú–µ—Ç–æ–¥ 2: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–∞–∫ fallback
        binary_adaptive = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é: –±–µ—Ä–µ–º –±–µ–ª—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑ –æ–±–æ–∏—Ö –º–µ—Ç–æ–¥–æ–≤
        binary = cv2.bitwise_or(binary_white, binary_adaptive)
        
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º: –±–µ–ª—ã–π —á–µ–∫ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —á–µ—Ä–Ω—ã–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤
        inverted = 255 - binary
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Ä–∞–∑—Ä–æ–∑–Ω–µ–Ω–Ω—ã—Ö —á–∞—Å—Ç–µ–π —á–µ–∫–∞
        kernel = np.ones((20, 20), np.uint8)
        closed = cv2.morphologyEx(inverted, cv2.MORPH_CLOSE, kernel, iterations=3)
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=2)
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
        contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            logging.debug("No contours found for receipt alignment")
            return image
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç—É—Ä (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —á–µ–∫)
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∞—è –æ–±–ª–∞—Å—Ç—å (–º–∏–Ω–∏–º—É–º 15% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        if area < 0.15 * h * w:
            logging.debug(f"Contour area too small: {area / (h * w) * 100:.1f}%")
            return image
        
        # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä –¥–æ 4 —Ç–æ—á–µ–∫ (—É–≥–ª—ã –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞)
        epsilon = 0.02 * cv2.arcLength(largest_contour, True)
        approx = cv2.approxPolyDP(largest_contour, epsilon, True)
        
        if len(approx) >= 4:
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ 4+ —Ç–æ—á–∫–∏, –±–µ—Ä–µ–º 4 —É–≥–ª–∞
            if len(approx) == 4:
                box = approx.reshape(4, 2)
            else:
                # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 4 —Ç–æ—á–µ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
                rect = cv2.minAreaRect(largest_contour)
                box = cv2.boxPoints(rect)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (–Ω–∞ —Ü–≤–µ—Ç–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏)
            warped = _four_point_transform_color(image, box)
            logging.info(f"Receipt aligned (color): found {len(approx)} points, area: {area / (h * w) * 100:.1f}%")
            return warped
        else:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ 4 —É–≥–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            rect = cv2.minAreaRect(largest_contour)
            box = cv2.boxPoints(rect)
            warped = _four_point_transform_color(image, box)
            logging.info(f"Receipt aligned (color, using minAreaRect): area: {area / (h * w) * 100:.1f}%")
            return warped
    except Exception as exc:
        logging.debug(f"Receipt alignment (color) failed: {exc}")
        return image


def _crop_white_receipt_color(image: np.ndarray) -> np.ndarray:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç —Ü–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º —á–µ–∫–∞.
    –ò—â–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏ (—Ç–µ–º–Ω—ã–µ –Ω–∞ —Å–≤–µ—Ç–ª–æ–º) –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥—Ä–∞–Ω–∏—Ü —á–µ–∫–∞.
    """
    try:
        h, w = image.shape[:2]
        original_size = w * h
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥—Ä–∞–Ω–∏—Ü
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image
        
        # –ú–µ—Ç–æ–¥: –ò—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏ (—Ç–µ–º–Ω—ã–µ –Ω–∞ —Å–≤–µ—Ç–ª–æ–º —Ñ–æ–Ω–µ)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Otsu –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞
        _, binary_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º: —Ç–µ–∫—Å—Ç —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –±–µ–ª—ã–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤
        text_mask = 255 - binary_otsu
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
        kernel = np.ones((10, 10), np.uint8)
        closed = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel, iterations=2)
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        logging.info(f"Found {len(contours)} contours for receipt cropping")
        if not contours:
            logging.warning("No contours found for receipt cropping, trying white areas method")
            # Fallback: –∏—â–µ–º –±–µ–ª—ã–µ –æ–±–ª–∞—Å—Ç–∏
            _, binary_white = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
            inverted = 255 - binary_white
            kernel = np.ones((20, 20), np.uint8)
            closed = cv2.morphologyEx(inverted, cv2.MORPH_CLOSE, kernel, iterations=3)
            contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if not contours:
                return image
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç—É—Ä (—á–µ–∫)
        largest_contour = max(contours, key=cv2.contourArea)
        x, y, w_cont, h_cont = cv2.boundingRect(largest_contour)
        area = cv2.contourArea(largest_contour)
        area_percent = area / original_size * 100
        logging.info(f"Largest contour: x={x}, y={y}, w={w_cont}, h={h_cont}, area={area_percent:.1f}%")
        
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç—É—Ä –∑–∞–Ω–∏–º–∞–µ—Ç –ø–æ—á—Ç–∏ –≤–µ—Å—å –∫–∞–¥—Ä (>90%), –∑–Ω–∞—á–∏—Ç –æ–±—Ä–µ–∑–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞ –∏–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
        # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –º–µ—Ç–æ–¥ - –∏—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏
        if area_percent > 90:
            logging.warning(f"Contour covers {area_percent:.1f}% of image, trying text-based cropping")
            # –ú–µ—Ç–æ–¥ 2: –ò—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–µ–∫—Ü–∏–∏
            _, binary_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            text_mask = 255 - binary_otsu
            
            horizontal_proj = np.sum(text_mask, axis=1)
            vertical_proj = np.sum(text_mask, axis=0)
            
            h_threshold = max(np.max(horizontal_proj) * 0.01, np.mean(horizontal_proj) * 0.5)
            v_threshold = max(np.max(vertical_proj) * 0.01, np.mean(vertical_proj) * 0.5)
            
            h_indices = np.where(horizontal_proj > h_threshold)[0]
            v_indices = np.where(vertical_proj > v_threshold)[0]
            
            if len(h_indices) > 0 and len(v_indices) > 0:
                padding = 10
                top = max(0, h_indices[0] - padding)
                bottom = min(h, h_indices[-1] + 1 + padding)
                left = max(0, v_indices[0] - padding)
                right = min(w, v_indices[-1] + 1 + padding)
                
                crop_h = bottom - top
                crop_w = right - left
                crop_size = crop_w * crop_h
                crop_percent = crop_size / original_size * 100
                
                if crop_percent < 95 and crop_h > 50 and crop_w > 50:
                    cropped = image[top:bottom, left:right]
                    logging.info(f"Cropped receipt (text projections): {w}x{h} -> {crop_w}x{crop_h} ({crop_percent:.1f}%)")
                    return cropped
            
            logging.warning(f"Text-based cropping also failed, contour covers {area_percent:.1f}%")
            return image
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–∏–µ –æ—Ç—Å—Ç—É–ø—ã (2% –∏–ª–∏ –º–∏–Ω–∏–º—É–º 10px)
        padding_x = max(10, int(w_cont * 0.02))
        padding_y = max(10, int(h_cont * 0.02))
        x = max(0, x - padding_x)
        y = max(0, y - padding_y)
        w_cont = min(w - x, w_cont + 2 * padding_x)
        h_cont = min(h - y, h_cont + 2 * padding_y)
        
        crop_size = w_cont * h_cont
        crop_percent = crop_size / original_size * 100
        logging.info(f"Crop check: crop_size={crop_size}, original_size={original_size}, percent={crop_percent:.1f}%, h_cont={h_cont}, w_cont={w_cont}")
        if crop_size > original_size * 0.1 and h_cont > 50 and w_cont > 50:
            cropped = image[y : y + h_cont, x : x + w_cont]
            logging.info(f"Cropped receipt (color): {w}x{h} -> {w_cont}x{h_cont} ({crop_percent:.1f}%)")
            return cropped
        else:
            logging.warning(f"Crop conditions not met: crop_size={crop_size}, threshold={original_size * 0.1}, h_cont={h_cont}, w_cont={w_cont}")
        
        return image
    except Exception as exc:
        logging.debug(f"Receipt cropping (color) failed: {exc}")
        return image


def _four_point_transform_color(image: np.ndarray, pts: np.ndarray) -> np.ndarray:
    """
    –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    rect = _order_points(np.array(pts, dtype="float32"))
    (tl, tr, br, bl) = rect
    width_a = np.linalg.norm(br - bl)
    width_b = np.linalg.norm(tr - tl)
    max_width = int(max(width_a, width_b))
    height_a = np.linalg.norm(tr - br)
    height_b = np.linalg.norm(tl - bl)
    max_height = int(max(height_a, height_b))
    destination = np.array(
        [
            [0, 0],
            [max_width - 1, 0],
            [max_width - 1, max_height - 1],
            [0, max_height - 1],
        ],
        dtype="float32",
    )
    matrix = cv2.getPerspectiveTransform(rect, destination)
    warped = cv2.warpPerspective(image, matrix, (max_width, max_height))
    return warped


def _find_and_align_white_receipt(image: np.ndarray) -> np.ndarray:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –±–µ–ª—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π —á–µ–∫ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –µ–≥–æ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–æ–π.
    –ß–µ–∫–∏ –≤—Å–µ–≥–¥–∞ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ –∏ –±–µ–ª—ã–µ, –ø–æ—ç—Ç–æ–º—É –∏—â–µ–º –±–æ–ª—å—à–æ–π –±–µ–ª—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫.
    –†–∞–±–æ—Ç–∞–µ—Ç —Å grayscale –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º.
    """
    try:
        h, w = image.shape[:2]
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ grayscale
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # –®–∞–≥ 1: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –±–µ–ª—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥, —á—Ç–æ–±—ã —É—á–µ—Å—Ç—å —Ä–∞–∑–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è
        binary = cv2.adaptiveThreshold(
            image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º: –±–µ–ª—ã–π —á–µ–∫ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —á–µ—Ä–Ω—ã–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤
        inverted = 255 - binary
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Ä–∞–∑—Ä–æ–∑–Ω–µ–Ω–Ω—ã—Ö —á–∞—Å—Ç–µ–π —á–µ–∫–∞
        kernel = np.ones((20, 20), np.uint8)
        # –ó–∞–∫—Ä—ã—Ç–∏–µ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
        closed = cv2.morphologyEx(inverted, cv2.MORPH_CLOSE, kernel, iterations=3)
        # –û—Ç–∫—Ä—ã—Ç–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —à—É–º–∞
        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=2)
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
        contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            logging.debug("No contours found for receipt alignment")
            return image
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç—É—Ä (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —á–µ–∫)
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∞—è –æ–±–ª–∞—Å—Ç—å (–º–∏–Ω–∏–º—É–º 15% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        if area < 0.15 * h * w:
            logging.debug(f"Contour area too small: {area / (h * w) * 100:.1f}%")
            return image
        
        # –®–∞–≥ 2: –ê–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä –¥–æ 4 —Ç–æ—á–µ–∫ (—É–≥–ª—ã –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞)
        epsilon = 0.02 * cv2.arcLength(largest_contour, True)
        approx = cv2.approxPolyDP(largest_contour, epsilon, True)
        
        if len(approx) >= 4:
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ 4+ —Ç–æ—á–∫–∏, –±–µ—Ä–µ–º 4 —É–≥–ª–∞
            if len(approx) == 4:
                box = approx.reshape(4, 2)
            else:
                # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 4 —Ç–æ—á–µ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
                rect = cv2.minAreaRect(largest_contour)
                box = cv2.boxPoints(rect)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è
            warped = _four_point_transform(image, box)
            logging.info(f"Receipt aligned: found {len(approx)} points, area: {area / (h * w) * 100:.1f}%")
            return warped
        else:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ 4 —É–≥–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            rect = cv2.minAreaRect(largest_contour)
            box = cv2.boxPoints(rect)
            warped = _four_point_transform(image, box)
            logging.info(f"Receipt aligned (using minAreaRect): area: {area / (h * w) * 100:.1f}%")
            return warped
    except Exception as exc:
        logging.debug(f"Receipt alignment failed: {exc}")
        return image


def _crop_white_receipt(image: np.ndarray) -> np.ndarray:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º —á–µ–∫–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏ –æ—Å–≤–µ—â–µ–Ω–∏—è.
    """
    try:
        h, w = image.shape[:2]
        original_size = w * h
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ grayscale
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è —á–µ–∫–∞
        binary = cv2.adaptiveThreshold(
            image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤
        inverted = 255 - binary
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —á–∞—Å—Ç–µ–π
        kernel = np.ones((15, 15), np.uint8)
        closed = cv2.morphologyEx(inverted, cv2.MORPH_CLOSE, kernel, iterations=2)
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return image
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç—É—Ä (—á–µ–∫)
        largest_contour = max(contours, key=cv2.contourArea)
        x, y, w_cont, h_cont = cv2.boundingRect(largest_contour)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–∏–µ –æ—Ç—Å—Ç—É–ø—ã (2% –∏–ª–∏ –º–∏–Ω–∏–º—É–º 10px)
        padding_x = max(10, int(w_cont * 0.02))
        padding_y = max(10, int(h_cont * 0.02))
        x = max(0, x - padding_x)
        y = max(0, y - padding_y)
        w_cont = min(w - x, w_cont + 2 * padding_x)
        h_cont = min(h - y, h_cont + 2 * padding_y)
        
        crop_size = w_cont * h_cont
        if crop_size > original_size * 0.1 and h_cont > 50 and w_cont > 50:
            cropped = image[y : y + h_cont, x : x + w_cont]
            logging.info(f"Cropped receipt: {w}x{h} -> {w_cont}x{h_cont} ({crop_size/original_size*100:.1f}%)")
            return cropped
        
        return image
    except Exception as exc:
        logging.debug(f"Receipt cropping failed: {exc}")
        return image


def _perspective_correct(image: np.ndarray) -> np.ndarray:
    """
    –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—É —á–µ–∫–∞ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∫—Ä–∞–µ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏—é —É–≥–ª–æ–≤ —á–µ–∫–∞ –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ.
    """
    try:
        h, w = image.shape[:2]
        
        # –ù–∞—Ö–æ–¥–∏–º –∫—Ä–∞—è —á–µ–∫–∞ —á–µ—Ä–µ–∑ –¥–µ—Ç–µ–∫—Ü–∏—é –∫–æ–Ω—Ç—É—Ä–æ–≤
        edges = cv2.Canny(image, 50, 150, apertureSize=3)
        # –†–∞—Å—à–∏—Ä—è–µ–º –∫—Ä–∞—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        kernel = np.ones((3, 3), np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=2)
        
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return image
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç—É—Ä (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —á–µ–∫)
        contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(contour)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ç—É—Ä –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π (–º–∏–Ω–∏–º—É–º 30% –æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        if area < 0.3 * h * w:
            return image
        
        # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä –¥–æ 4 —Ç–æ—á–µ–∫ (—É–≥–ª—ã —á–µ–∫–∞)
        epsilon = 0.02 * cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon, True)
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ 4 —É–≥–ª–∞, –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        if len(approx) == 4:
            box = approx.reshape(4, 2)
            warped = _four_point_transform(image, box)
            logging.info("Perspective correction applied")
            return warped
        else:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ 4 —É–≥–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            rect = cv2.minAreaRect(contour)
            box = cv2.boxPoints(rect)
            warped = _four_point_transform(image, box)
            logging.info("Perspective correction applied (using minAreaRect)")
            return warped
    except Exception as exc:
        logging.debug(f"Perspective correction failed: {exc}")
        return image


def _auto_crop_aggressive(image: np.ndarray) -> np.ndarray:
    """
    –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –∞–≤—Ç–æ–∫—Ä–æ–ø: –æ–±—Ä–µ–∑–∞–µ—Ç –ø–æ —Å–∞–º–æ–º—É –∫—Ä–∞—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –±–µ–∑ –æ—Ç—Å—Ç—É–ø–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
    """
    try:
        h, w = image.shape[:2]
        original_size = w * h
        
        # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –±–µ–ª—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π (—á–µ–∫ –æ–±—ã—á–Ω–æ –±–µ–ª—ã–π –Ω–∞ —Ç–µ–º–Ω–æ–º —Ñ–æ–Ω–µ)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –±–µ–ª–æ–≥–æ —á–µ–∫–∞
        _, white_mask = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY)
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã –±–µ–ª—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
        contours_white, _ = cv2.findContours(white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours_white:
            # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –±–µ–ª—ã–π –∫–æ–Ω—Ç—É—Ä (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —á–µ–∫)
            largest_contour = max(contours_white, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            if area > original_size * 0.1:  # –ß–µ–∫ –¥–æ–ª–∂–µ–Ω –∑–∞–Ω–∏–º–∞—Ç—å –º–∏–Ω–∏–º—É–º 10% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                x, y, w_cont, h_cont = cv2.boundingRect(largest_contour)
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã 2% —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–µ–∑–∞—Ç—å —Å–∞–º —á–µ–∫
                padding_x = max(10, int(w_cont * 0.02))
                padding_y = max(10, int(h_cont * 0.02))
                x = max(0, x - padding_x)
                y = max(0, y - padding_y)
                w_cont = min(w - x, w_cont + 2 * padding_x)
                h_cont = min(h - y, h_cont + 2 * padding_y)
                cropped = image[y : y + h_cont, x : x + w_cont]
                crop_size = w_cont * h_cont
                logging.info(f"Aggressive crop (white areas, 2% padding): {w}x{h} -> {w_cont}x{h_cont} ({crop_size/original_size*100:.1f}%)")
                return cropped
        
        # –ú–µ—Ç–æ–¥ 2: –ü—Ä–æ–µ–∫—Ü–∏–∏ —Å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–º –ø–æ—Ä–æ–≥–æ–º (—Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π –¥–ª—è —Ç–µ–∫—Å—Ç–∞)
        _, binary_otsu = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        text_mask = 255 - binary_otsu
        
        horizontal_proj = np.sum(text_mask, axis=1)
        vertical_proj = np.sum(text_mask, axis=0)
        
        # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ - –æ–±—Ä–µ–∑–∞–µ–º –ø–æ —Å–∞–º–æ–º—É –∫—Ä–∞—é —Ç–µ–∫—Å—Ç–∞
        h_max = np.max(horizontal_proj)
        v_max = np.max(vertical_proj)
        h_mean = np.mean(horizontal_proj)
        v_mean = np.mean(vertical_proj)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        h_threshold = min(h_max * 0.0005, h_mean * 0.3, np.percentile(horizontal_proj, 10))
        v_threshold = min(v_max * 0.0005, v_mean * 0.3, np.percentile(vertical_proj, 10))
        
        h_indices = np.where(horizontal_proj > h_threshold)[0]
        v_indices = np.where(vertical_proj > v_threshold)[0]
        
        if len(h_indices) > 0 and len(v_indices) > 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–∏–µ –æ—Ç—Å—Ç—É–ø—ã (1% –∏–ª–∏ –º–∏–Ω–∏–º—É–º 5px) —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–µ–∑–∞—Ç—å —Å–∞–º —á–µ–∫
            padding_h = max(5, int((h_indices[-1] - h_indices[0]) * 0.01))
            padding_w = max(5, int((v_indices[-1] - v_indices[0]) * 0.01))
            top = max(0, h_indices[0] - padding_h)
            bottom = min(h, h_indices[-1] + 1 + padding_h)
            left = max(0, v_indices[0] - padding_w)
            right = min(w, v_indices[-1] + 1 + padding_w)
            
            crop_h = bottom - top
            crop_w = right - left
            crop_size = crop_w * crop_h
            
            if crop_size > original_size * 0.05 and crop_h > 30 and crop_w > 30:
                cropped = image[top:bottom, left:right]
                logging.info(f"Aggressive crop (projections, 1% padding): {w}x{h} -> {crop_w}x{crop_h} ({crop_size/original_size*100:.1f}%)")
                return cropped
        
        # –ú–µ—Ç–æ–¥ 2: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ + –∫–æ–Ω—Ç—É—Ä—ã (–¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –ø—Ä–æ–µ–∫—Ü–∏–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç)
        binary = cv2.adaptiveThreshold(
            image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        inverted = 255 - binary
        
        # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π
        kernel = np.ones((20, 20), np.uint8)
        dilated = cv2.dilate(inverted, kernel, iterations=3)
        closed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel, iterations=3)
        
        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            all_points = np.concatenate(contours)
            x, y, w_cont, h_cont = cv2.boundingRect(all_points)
            
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ—Ç—Å—Ç—É–ø - —Ç–æ–ª—å–∫–æ 5 –ø–∏–∫—Å–µ–ª–µ–π –∏–ª–∏ 1%
            padding_x = max(5, int(w_cont * 0.01))
            padding_y = max(5, int(h_cont * 0.01))
            x = max(0, x - padding_x)
            y = max(0, y - padding_y)
            w_cont = min(w - x, w_cont + 2 * padding_x)
            h_cont = min(h - y, h_cont + 2 * padding_y)
            
            crop_size = w_cont * h_cont
            if crop_size > original_size * 0.05 and h_cont > 30 and w_cont > 30:
                cropped = image[y : y + h_cont, x : x + w_cont]
                logging.info(f"Aggressive crop (contours, minimal padding): {w}x{h} -> {w_cont}x{h_cont} ({crop_size/original_size*100:.1f}%)")
                return cropped
        
        # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –∫—Ä–∞–µ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã (fallback)
        sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255)
        
        _, grad_binary = cv2.threshold(gradient_magnitude, 20, 255, cv2.THRESH_BINARY)
        
        h_grad_proj = np.sum(grad_binary, axis=1)
        v_grad_proj = np.sum(grad_binary, axis=0)
        
        h_grad_threshold = np.max(h_grad_proj) * 0.01
        v_grad_threshold = np.max(v_grad_proj) * 0.01
        
        h_grad_indices = np.where(h_grad_proj > h_grad_threshold)[0]
        v_grad_indices = np.where(v_grad_proj > v_grad_threshold)[0]
        
        if len(h_grad_indices) > 0 and len(v_grad_indices) > 0:
            top = h_grad_indices[0]
            bottom = h_grad_indices[-1] + 1
            left = v_grad_indices[0]
            right = v_grad_indices[-1] + 1
            
            crop_h = bottom - top
            crop_w = right - left
            crop_size = crop_w * crop_h
            
            if crop_size > original_size * 0.05 and crop_h > 30 and crop_w > 30:
                cropped = image[top:bottom, left:right]
                logging.info(f"Aggressive crop (gradients, no padding): {w}x{h} -> {crop_w}x{crop_h} ({crop_size/original_size*100:.1f}%)")
                return cropped
        
        logging.debug(f"Aggressive crop: no cropping applied (image {w}x{h})")
        return image
    except Exception as exc:
        logging.debug(f"Aggressive crop failed: {exc}")
        return image


def extract_receipt_text(file_bytes: bytes, force_engine: Optional[str] = None) -> tuple[str, Optional[bytes], List[Snapshot]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–∫–∞–ª—å–Ω—ã–π OCR.
    force_engine: "tesseract" –∏–ª–∏ "paddleocr" –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –¥–≤–∏–∂–∫–∞, None - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OCR_ENGINE
    """
    engine = force_engine or OCR_ENGINE
    
    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω "both", –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º tesseract
    if engine == "both":
        engine = "tesseract"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ OCR –¥–≤–∏–∂–∫–∞
    if engine == "paddleocr":
        if not PADDLEOCR_AVAILABLE or PaddleOCR is None:
            raise ReceiptParsingError(
                "PaddleOCR –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ paddlepaddle –∏ paddleocr."
            )
    else:
        if not TESSERACT_AVAILABLE or Image is None or pytesseract is None:
            raise ReceiptParsingError(
                "Tesseract –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Tesseract, pytesseract –∏ Pillow."
            )
    
    if Image is None:
        raise ReceiptParsingError("Pillow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    snapshots: List[Snapshot] = []
    try:
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Å—Ä–∞–∑—É –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
        image = Image.open(io.BytesIO(file_bytes))
        image = image.convert("RGB")
        snapshots_id_before = id(snapshots)
        print(f"[DEBUG] Starting prepare_image_for_ocr, snapshots count: {len(snapshots)}, id: {snapshots_id_before}")
        processed, preview_image = prepare_image_for_ocr(image, snapshots)
        snapshots_id_after = id(snapshots)
        print(f"[DEBUG] After prepare_image_for_ocr, snapshots count: {len(snapshots)}, id: {snapshots_id_after}, same object: {snapshots_id_before == snapshots_id_after}")
        logging.info(f"Created {len(snapshots)} snapshots during preprocessing")
        logging.debug(
            "OCR pipeline: processed size=%s preview=%s",
            processed.size,
            bool(preview_image),
        )
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π OCR –¥–≤–∏–∂–æ–∫
        if engine == "paddleocr":
            # –î–ª—è PaddleOCR –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ grayscale)
            # PaddleOCR –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ü–≤–µ—Ç–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            text, _ = run_paddleocr(image)
        else:
            text, _ = run_multi_pass_ocr(processed)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º preview_image (–∫–æ—Ç–æ—Ä—ã–π —Ç–µ–ø–µ—Ä—å —Ç–∞–∫–æ–π –∂–µ –∫–∞–∫ ocr_ready) –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        final_preview = preview_image or processed
        if final_preview.height < final_preview.width:
            final_preview = final_preview.rotate(90, expand=True)
        preview_bytes = image_to_png_bytes(final_preview)
    except Exception as exc:  # pragma: no cover - depends on external binary
        logging.exception("Error in extract_receipt_text")
        engine_name = engine.capitalize()
        raise ReceiptParsingError(f"{engine_name} –Ω–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.") from exc
    cleaned = text.strip()
    if not cleaned:
        engine_name = engine.capitalize()
        raise ReceiptParsingError(f"{engine_name} –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
    
    print(f"[DEBUG] extract_receipt_text returning {len(snapshots)} snapshots")
    logging.info(f"Returning {len(snapshots)} snapshots")
    return cleaned, preview_bytes, snapshots


def prepare_image_for_ocr(
    image: "Image.Image", snapshots: Optional[List[Snapshot]] = None
) -> tuple["Image.Image", Optional["Image.Image"]]:
    if not TESSERACT_AVAILABLE or Image is None:
        return image, image
    snapshots_id_incoming = id(snapshots) if snapshots is not None else None
    if snapshots is None:
        snapshots = []
        print(f"[DEBUG] prepare_image_for_ocr: snapshots was None, created new list")
    else:
        print(f"[DEBUG] prepare_image_for_ocr: received snapshots list, id: {id(snapshots)}, count: {len(snapshots)}")
    print(f"[DEBUG] prepare_image_for_ocr: initial snapshots count: {len(snapshots)}, id: {id(snapshots)}")
    logging.debug(f"Starting prepare_image_for_ocr, initial snapshots count: {len(snapshots)}")
    raw = image.convert("RGB")
    snapshots.append(Snapshot("raw", raw.copy(), "–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"))
    print(f"[DEBUG] Added raw snapshot, total: {len(snapshots)}")
    logging.debug(f"Added raw snapshot, total: {len(snapshots)}")
    pil_image = raw.convert("L")
    if ImageOps is not None:
        pil_image = ImageOps.autocontrast(pil_image)
    cv_image = np.array(pil_image)
    snapshots.append(
        Snapshot("grayscale", Image.fromarray(cv_image.copy()), "–ì—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ –ø–æ—Å–ª–µ –∞–≤—Ç–æ–∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞")
    )
    # –£–±—Ä–∞–ª–∏ denoising –∏ CLAHE - –æ–Ω–∏ –ø–æ—Ä—Ç–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    # –£–±—Ä–∞–ª–∏ auto_rotate - –æ–Ω –ø–æ—Ä—Ç–∏–ª –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ deskew –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ –Ω–∞–∫–ª–æ–Ω–∞
    cv_image = _deskew_image(cv_image)
    snapshots.append(
        Snapshot("deskew", Image.fromarray(cv_image.copy()), "–ü–æ—Å–ª–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞")
    )
    # –¢–µ–ø–µ—Ä—å –æ–±—Ä–µ–∑–∞–µ–º —É–∂–µ –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    cv_image = _auto_crop(cv_image)
    snapshots.append(
        Snapshot("autocrop", Image.fromarray(cv_image.copy()), "–ü–æ—Å–ª–µ –∞–≤—Ç–æ–∫—Ä–æ–ø–∞")
    )
    # –£–±—Ä–∞–ª–∏ perspective_refine –∏ ensure_portrait - –æ–Ω–∏ –ø–æ—Ä—Ç–∏–ª–∏ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç –≤ _final_orientation_fix
    # –£–±—Ä–∞–ª–∏ –ø–æ—Ä–æ–≥–æ–≤—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é - –æ–Ω–∞ –ø–æ—Ä—Ç–∏–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –µ—Å—Ç—å –¥–ª—è OCR
    ocr_ready = cv_image.copy()
    # Preview –±—É–¥–µ—Ç —Ç–∞–∫–∏–º –∂–µ –∫–∞–∫ ocr_ready (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
    preview = ocr_ready.copy()
    ocr_ready, preview = _final_orientation_fix(ocr_ready, preview)
    snapshots.append(
        Snapshot("ocr_ready", Image.fromarray(ocr_ready.copy()), "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø–æ–¥–∞–Ω–Ω–æ–µ –≤ Tesseract")
    )
    print(f"[DEBUG] Finished prepare_image_for_ocr, total snapshots: {len(snapshots)}")
    logging.debug(f"Finished prepare_image_for_ocr, total snapshots: {len(snapshots)}")
    max_side = 1800
    h, w = ocr_ready.shape[:2]
    if max(h, w) > max_side:
        ratio = max_side / max(h, w)
        ocr_ready = cv2.resize(
            ocr_ready,
            (int(w * ratio), int(h * ratio)),
            interpolation=cv2.INTER_CUBIC,
        )
    processed = Image.fromarray(ocr_ready)
    preview_image = Image.fromarray(preview) if preview is not None else None
    return processed, preview_image


def _auto_crop(image: np.ndarray) -> np.ndarray:
    """
    –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –∞–≤—Ç–æ–∫—Ä–æ–ø: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥—Ä–∞–Ω–∏—Ü —á–µ–∫–∞.
    –ú–µ—Ç–æ–¥ 1: –ü—Ä–æ–µ–∫—Ü–∏–∏ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
    –ú–µ—Ç–æ–¥ 2: –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è + –∫–æ–Ω—Ç—É—Ä—ã
    –ú–µ—Ç–æ–¥ 3: –ê–Ω–∞–ª–∏–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    """
    try:
        h, w = image.shape[:2]
        original_size = w * h
        
        # –ú–µ—Ç–æ–¥ 1: –ü—Ä–æ–µ–∫—Ü–∏–∏ —Å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        text_mask = 255 - binary
        
        # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏
        horizontal_proj = np.sum(text_mask, axis=1)
        vertical_proj = np.sum(text_mask, axis=0)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥: 1% –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞ –∏–ª–∏ –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        h_max = np.max(horizontal_proj)
        v_max = np.max(vertical_proj)
        h_threshold = max(h_max * 0.01, np.mean(horizontal_proj) * 2)
        v_threshold = max(v_max * 0.01, np.mean(vertical_proj) * 2)
        
        h_indices = np.where(horizontal_proj > h_threshold)[0]
        v_indices = np.where(vertical_proj > v_threshold)[0]
        
        if len(h_indices) > 0 and len(v_indices) > 0:
            top = max(0, h_indices[0] - 5)
            bottom = min(h, h_indices[-1] + 5)
            left = max(0, v_indices[0] - 5)
            right = min(w, v_indices[-1] + 5)
            
            crop_h = bottom - top
            crop_w = right - left
            crop_size = crop_w * crop_h
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—Ä–µ–∑–∞–ª–∏ —Ö–æ—Ç—è –±—ã 5% –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
            if crop_size > original_size * 0.05 and crop_h > 50 and crop_w > 50:
                cropped = image[top:bottom, left:right]
                logging.debug(f"Auto-crop (projections): {w}x{h} -> {crop_w}x{crop_h} ({crop_size/original_size*100:.1f}%)")
                return cropped
        
        # –ú–µ—Ç–æ–¥ 2: –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞, –∑–∞—Ç–µ–º –∫–æ–Ω—Ç—É—Ä—ã
        kernel = np.ones((5, 5), np.uint8)
        dilated = cv2.dilate(text_mask, kernel, iterations=2)
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç—É—Ä –∏–ª–∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ
            if len(contours) == 1:
                contour = contours[0]
            else:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∫–æ–Ω—Ç—É—Ä—ã
                all_points = np.concatenate(contours)
                contour = all_points
            
            x, y, w_cont, h_cont = cv2.boundingRect(contour)
            
            # –û—Ç—Å—Ç—É–ø—ã
            padding = 5
            x = max(0, x - padding)
            y = max(0, y - padding)
            w_cont = min(w - x, w_cont + 2 * padding)
            h_cont = min(h - y, h_cont + 2 * padding)
            
            crop_size = w_cont * h_cont
            if crop_size > original_size * 0.05 and h_cont > 50 and w_cont > 50:
                cropped = image[y : y + h_cont, x : x + w_cont]
                logging.debug(f"Auto-crop (contours): {w}x{h} -> {w_cont}x{h_cont} ({crop_size/original_size*100:.1f}%)")
                return cropped
        
        # –ú–µ—Ç–æ–¥ 3: –ê–Ω–∞–ª–∏–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫—Ä–∞–µ–≤
        sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255)
        
        # –ü–æ—Ä–æ–≥ –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        _, grad_binary = cv2.threshold(gradient_magnitude, 30, 255, cv2.THRESH_BINARY)
        
        # –ü—Ä–æ–µ–∫—Ü–∏–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        h_grad_proj = np.sum(grad_binary, axis=1)
        v_grad_proj = np.sum(grad_binary, axis=0)
        
        h_grad_threshold = np.max(h_grad_proj) * 0.02
        v_grad_threshold = np.max(v_grad_proj) * 0.02
        
        h_grad_indices = np.where(h_grad_proj > h_grad_threshold)[0]
        v_grad_indices = np.where(v_grad_proj > v_grad_threshold)[0]
        
        if len(h_grad_indices) > 0 and len(v_grad_indices) > 0:
            top = max(0, h_grad_indices[0] - 5)
            bottom = min(h, h_grad_indices[-1] + 5)
            left = max(0, v_grad_indices[0] - 5)
            right = min(w, v_grad_indices[-1] + 5)
            
            crop_h = bottom - top
            crop_w = right - left
            crop_size = crop_w * crop_h
            
            if crop_size > original_size * 0.05 and crop_h > 50 and crop_w > 50:
                cropped = image[top:bottom, left:right]
                logging.debug(f"Auto-crop (gradients): {w}x{h} -> {crop_w}x{crop_h} ({crop_size/original_size*100:.1f}%)")
                return cropped
        
        logging.debug(f"Auto-crop: no cropping applied (image {w}x{h})")
        return image
    except Exception as exc:
        logging.debug(f"Auto-crop failed: {exc}")
        return image


def _auto_rotate(image: np.ndarray) -> np.ndarray:
    try:
        angle = _detect_rotation_angle(image)
        if angle is not None and abs(angle) > 0.3:
            logging.debug("Auto-rotate: rotating by %s degrees", angle)
            return _rotate_image(image, angle)
        logging.debug("Auto-rotate: no rotation applied (angle=%s)", angle)
    except Exception:
        pass
    return image


def _detect_rotation_angle(image: np.ndarray) -> Optional[float]:
    angle = _osd_angle(image)
    if angle is not None and abs(angle) > 0.1:
        logging.debug("Detect rotation: OSD angle=%s", angle)
        return angle
    hough_angle = _hough_angle(image)
    logging.debug("Detect rotation: Hough angle=%s", hough_angle)
    return hough_angle


def _osd_angle(image: np.ndarray) -> Optional[float]:
    if pytesseract is None:
        return None
    try:
        osd = pytesseract.image_to_osd(image, output_type=pytesseract.Output.DICT)
    except pytesseract.pytesseract.TesseractError:
        return None
    angle = osd.get("rotate", 0)
    if angle is None:
        return None
    if angle > 180:
        angle -= 360
    return float(angle)


def _hough_angle(image: np.ndarray) -> Optional[float]:
    edges = cv2.Canny(image, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=120, minLineLength=100, maxLineGap=10)
    if lines is None or len(lines) == 0:
        return None
    angles: List[float] = []
    for line in lines:
        x1, y1, x2, y2 = line[0]
        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))
        angles.append(angle)
    if not angles:
        return None
    avg_angle = np.median(angles)
    # Snap to closest multiple of 90 to avoid upside-down outputs
    for snap in (0, 90, -90, 180, -180):
        if abs(avg_angle - snap) < 10:
            return avg_angle - snap
    return avg_angle


def _rotate_image(image: np.ndarray, angle: float) -> np.ndarray:
    h, w = image.shape[:2]
    center = (w // 2, h // 2)
    matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
    rotated = cv2.warpAffine(
        image,
        matrix,
        (w, h),
        flags=cv2.INTER_CUBIC,
        borderMode=cv2.BORDER_REPLICATE,
    )
    return rotated


def _deskew_image(image: np.ndarray) -> np.ndarray:
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–π –Ω–∞–∫–ª–æ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (skew).
    –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞ –¥–æ ¬±5 –≥—Ä–∞–¥—É—Å–æ–≤, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ä—Ç–∏—Ç—å —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        coords = np.column_stack(np.where(binary < 250))
        if coords.size == 0:
            return image
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
        rect = cv2.minAreaRect(coords)
        angle = rect[-1]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —É–≥–æ–ª
        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞: –∏—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–±–æ–ª—å—à–∏–µ –Ω–∞–∫–ª–æ–Ω—ã (¬±5 –≥—Ä–∞–¥—É—Å–æ–≤)
        # –ï—Å–ª–∏ —É–≥–æ–ª –±–æ–ª—å—à–µ, –∑–Ω–∞—á–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–ª–∏ –Ω—É–∂–µ–Ω –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥
        max_skew_angle = 5.0
        if abs(angle) < 0.5:
            # –£–≥–æ–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª, –Ω–µ –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º
            return image
        if abs(angle) > max_skew_angle:
            # –£–≥–æ–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π - –≤–µ—Ä–æ—è—Ç–Ω–æ, —ç—Ç–æ –Ω–µ –Ω–∞–∫–ª–æ–Ω, –∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è
            # –ù–µ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –∑–¥–µ—Å—å, –ø—É—Å—Ç—å –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–∑–±–∏—Ä–∞—é—Ç—Å—è
            logging.debug(f"Deskew: angle {angle:.2f}¬∞ too large, skipping")
            return image
        
        logging.debug(f"Deskew: correcting skew by {angle:.2f}¬∞")
        h, w = image.shape[:2]
        center = (w // 2, h // 2)
        matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated = cv2.warpAffine(
            image,
            matrix,
            (w, h),
            flags=cv2.INTER_CUBIC,
            borderMode=cv2.BORDER_REPLICATE,
        )
        return rotated
    except Exception as exc:
        logging.debug(f"Deskew failed: {exc}")
        return image


def _adaptive_threshold(image: np.ndarray) -> np.ndarray:
    """–°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è —Å –∫–æ–º–±–∏–Ω–∞—Ü–∏–µ–π –¥–≤—É—Ö –ø–æ—Ä–æ–≥–æ–≤ - –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã"""
    try:
        blurred = cv2.GaussianBlur(image, (3, 3), 0)
        thresh_gauss = cv2.adaptiveThreshold(
            blurred,
            255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            35,
            11,
        )
        thresh_mean = cv2.adaptiveThreshold(
            blurred,
            255,
            cv2.ADAPTIVE_THRESH_MEAN_C,
            cv2.THRESH_BINARY,
            41,
            8,
        )
        combined = cv2.bitwise_and(thresh_gauss, thresh_mean)
        return combined
    except Exception:
        return image


def _simple_adaptive_threshold(image: np.ndarray) -> np.ndarray:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø–æ—Ä–æ–≥–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è - —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥.
    –ë–æ–ª–µ–µ –º—è–≥–∫–∞—è, –Ω–µ —Å–æ–∑–¥–∞–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –æ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –¥–≤—É—Ö –ø–æ—Ä–æ–≥–æ–≤.
    """
    try:
        # –ù–µ–±–æ–ª—å—à–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        blurred = cv2.GaussianBlur(image, (3, 3), 0)
        # –û–¥–∏–Ω –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ —Å –±–æ–ª–µ–µ –º—è–≥–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        thresh = cv2.adaptiveThreshold(
            blurred,
            255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            15,  # –ë–ª–æ–∫ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –ª—É—á—à–µ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
            10,  # –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –≤—ã—á–∏—Ç–∞–Ω–∏—è
        )
        return thresh
    except Exception as exc:
        logging.debug(f"Simple adaptive threshold failed: {exc}")
        return image


def _perspective_refine(image: np.ndarray) -> np.ndarray:
    try:
        edges = cv2.Canny(image, 50, 150, apertureSize=3)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return image
        contour = max(contours, key=cv2.contourArea)
        if cv2.contourArea(contour) < 0.3 * image.shape[0] * image.shape[1]:
            return image
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        warped = _four_point_transform(image, box)
        return warped
    except Exception:
        return image


def _ensure_portrait(image: np.ndarray) -> np.ndarray:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è: –Ω–µ –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–¥–µ—Å—å.
    –ü–æ–≤–æ—Ä–æ—Ç –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω —Ç–æ–ª—å–∫–æ –≤ _force_portrait –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.
    –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–≤–æ—Ä–æ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ä—Ç—è—Ç –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é.
    """
    # –ü—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –µ—Å—Ç—å - –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –∏—Å–ø—Ä–∞–≤–∏–º –≤ –∫–æ–Ω—Ü–µ
    return image


def _should_rotate_90(image: np.ndarray) -> bool:
    try:
        _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        text_mask = 255 - binary
        horizontal_proj = np.sum(text_mask, axis=1)
        vertical_proj = np.sum(text_mask, axis=0)
        horizontal_variation = float(np.std(horizontal_proj))
        vertical_variation = float(np.std(vertical_proj))
        decision = vertical_variation > horizontal_variation
        logging.debug(
            "Should rotate 90 decision=%s (vertical_var=%.2f horizontal_var=%.2f)",
            decision,
            vertical_variation,
            horizontal_variation,
        )
        return decision
    except Exception:
        return image.shape[1] > image.shape[0]


def _align_text_structure(image: Optional[np.ndarray]) -> Optional[np.ndarray]:
    if image is None:
        return None
    try:
        gray = image
        if len(image.shape) == 3 and image.shape[2] == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        text_mask = 255 - binary
        horizontal_proj = np.sum(text_mask, axis=1)
        vertical_proj = np.sum(text_mask, axis=0)
        horizontal_variation = float(np.std(horizontal_proj))
        vertical_variation = float(np.std(vertical_proj))
        logging.debug(
            "Align text: vertical_var=%.2f horizontal_var=%.2f",
            vertical_variation,
            horizontal_variation,
        )
        if vertical_variation > horizontal_variation * 1.2:
            logging.debug("Align text: rotating 90 degrees (vertical dominates)")
            return cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
        if horizontal_variation > vertical_variation * 1.2 and horizontal_variation > 50000:
            logging.debug("Align text: rotating -90 degrees (horizontal dominates)")
            return cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)
    except Exception as exc:
        logging.debug("Align text skipped: %s", exc)
    return image


def _force_portrait(image: Optional[np.ndarray]) -> Optional[np.ndarray]:
    if image is None:
        return None
    h, w = image.shape[:2]
    if h >= w:
        return image
    logging.debug("Force portrait: rotating image to ensure height>=width")
    return cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)


def _final_orientation_fix(
    image: np.ndarray, preview: Optional[np.ndarray]
) -> tuple[np.ndarray, Optional[np.ndarray]]:
    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞: —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–æ–π –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–≤–æ—Ä–æ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–º—É –æ—Ç—Ä–∞–∂–µ–Ω–∏—é
    rotated_image = _force_portrait(image)
    rotated_preview = (
        _force_portrait(preview) if preview is not None else None
    )
    logging.debug("Final orientation fix: applied force_portrait only")
    return rotated_image, rotated_preview


def _determine_final_rotation(image: np.ndarray) -> int:
    angle = _osd_angle(image)
    rotation = _normalize_to_quadrant(angle) if angle is not None else 0
    if rotation == 0 and _should_rotate_90(image):
        rotation = 90
    logging.debug("Final rotation decision angle=%s rotation=%s", angle, rotation)
    return rotation


def _normalize_to_quadrant(angle: Optional[float]) -> int:
    if angle is None:
        return 0
    normalized = int(round(angle / 90.0)) * 90
    normalized %= 360
    if normalized == 270:
        normalized = -90
    if normalized == 180:
        normalized = -180
    return normalized


def _rotate_numpy_array(image: np.ndarray, rotation: int) -> np.ndarray:
    if rotation == 0:
        return image
    if rotation % 360 == 90 or rotation % 360 == -270:
        return cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
    if rotation % 360 == 180 or rotation % 360 == -180:
        return cv2.rotate(image, cv2.ROTATE_180)
    if rotation % 360 == 270 or rotation % 360 == -90:
        return cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)
    return image


def _morphology_cleanup(image: np.ndarray) -> np.ndarray:
    try:
        kernel = np.ones((3, 3), np.uint8)
        opened = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations=1)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)
        return closed
    except Exception:
        return image


def _build_preview(image: np.ndarray) -> Optional[np.ndarray]:
    try:
        normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)
        blurred = cv2.GaussianBlur(normalized, (5, 5), 0)
        preview = cv2.cvtColor(blurred, cv2.COLOR_GRAY2BGR)
        return preview
    except Exception:
        return None


def _order_points(pts: np.ndarray) -> np.ndarray:
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect


def _four_point_transform(image: np.ndarray, pts: np.ndarray) -> np.ndarray:
    rect = _order_points(np.array(pts, dtype="float32"))
    (tl, tr, br, bl) = rect
    width_a = np.linalg.norm(br - bl)
    width_b = np.linalg.norm(tr - tl)
    max_width = int(max(width_a, width_b))
    height_a = np.linalg.norm(tr - br)
    height_b = np.linalg.norm(tl - bl)
    max_height = int(max(height_a, height_b))
    destination = np.array(
        [
            [0, 0],
            [max_width - 1, 0],
            [max_width - 1, max_height - 1],
            [0, max_height - 1],
        ],
        dtype="float32",
    )
    matrix = cv2.getPerspectiveTransform(rect, destination)
    warped = cv2.warpPerspective(image, matrix, (max_width, max_height))
    return warped


def translate_text_if_needed(text: str) -> str:
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å –∫–∞–∑–∞—Ö—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π, –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –∫–∞–∑–∞—Ö—Å–∫–∏–π —Ç–µ–∫—Å—Ç.
    –ï—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ —Ç–µ–∫—Å—Ç —É–∂–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª.
    """
    if not TRANSLATION_AVAILABLE or GoogleTranslator is None:
        logging.debug("Translation not available, returning original text")
        return text
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–∞–∑–∞—Ö—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞ + —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–∞–∑–∞—Ö—Å–∫–∏–µ –±—É–∫–≤—ã)
        kazakh_chars = set("”ô—ñ“£“ì“Ø“±“õ”©“ª”ò–Ü“¢“í“Æ“∞“ö”®“∫")
        has_kazakh = any(char in text for char in kazakh_chars)
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∞–∑–∞—Ö—Å–∫–∏—Ö —Å–ª–æ–≤
        kazakh_words = ["—Ç–∞—É–∞—Ä", "—Ç”©–ª–µ–º", "—Å–∞–ª—ã“õ", "“õ–∞—Ä—Ç–∞", "—á–µ–∫", "“õ–∞—Å—ã—Ä", "“õ–æ—Å—ã–º—à–∞"]
        has_kazakh_words = any(word.lower() in text.lower() for word in kazakh_words)
        
        if not (has_kazakh or has_kazakh_words):
            logging.debug("No Kazakh text detected, returning original")
            return text
        
        logging.info("Detected Kazakh text, translating to Russian...")
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å –∫–∞–∑–∞—Ö—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π
        translator = GoogleTranslator(source='kk', target='ru')
        translated = translator.translate(text)
        
        if translated and translated != text:
            logging.info(f"Translated text: {len(text)} -> {len(translated)} chars")
            return translated
        else:
            logging.debug("Translation returned same text, returning original")
            return text
    except Exception as exc:
        logging.warning(f"Translation failed: {exc}, returning original text")
        return text


def format_receipt_text(text: str) -> str:
    return "–¢–µ–∫—Å—Ç —á–µ–∫–∞ (–ª–æ–∫–∞–ª—å–Ω—ã–π OCR):\n\n" + text


def build_text_from_data(ocr_data: Dict[str, List[Any]]) -> str:
    lines: Dict[tuple, List[tuple]] = {}
    keys = ("page_num", "block_num", "par_num", "line_num")
    for idx, text in enumerate(ocr_data.get("text", [])):
        if not text or not text.strip():
            continue
        key = tuple(ocr_data[k][idx] for k in keys)
        left = ocr_data.get("left", [0])[idx]
        conf = ocr_data.get("conf", [0])[idx]
        lines.setdefault(key, []).append((left, text.strip(), conf))
    sorted_keys = sorted(lines.keys())
    collected: List[str] = []
    for key in sorted_keys:
        words = sorted(lines[key], key=lambda item: item[0])
        collected.append(" ".join(word for _, word, _ in words))
    return "\n".join(collected)


def run_paddleocr(image: "Image.Image") -> tuple[str, float]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç PaddleOCR –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –æ—Ü–µ–Ω–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏."""
    if not PADDLEOCR_AVAILABLE or PaddleOCR is None:
        raise ReceiptParsingError("PaddleOCR –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
    
    ocr_instance = get_paddleocr_instance()
    if ocr_instance is None:
        raise ReceiptParsingError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å PaddleOCR")
    
    try:
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ RGB —Ñ–æ—Ä–º–∞—Ç–µ
        if image.mode != "RGB":
            logging.info(f"Converting image from {image.mode} to RGB for PaddleOCR")
            image = image.convert("RGB")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL Image –≤ numpy array –¥–ª—è PaddleOCR
        img_array = np.array(image)
        logging.info(f"PaddleOCR input image shape: {img_array.shape}, dtype: {img_array.dtype}")
        
        # PaddleOCR –æ–∂–∏–¥–∞–µ—Ç BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV, –Ω–æ PIL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç RGB
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º RGB –≤ BGR
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            logging.info("Converted RGB to BGR for PaddleOCR")
        elif len(img_array.shape) == 2:
            # –ï—Å–ª–∏ grayscale, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR (3 –∫–∞–Ω–∞–ª–∞)
            img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
            logging.info("Converted grayscale to BGR for PaddleOCR")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º OCR
        logging.info("Calling PaddleOCR.ocr()...")
        try:
            result = ocr_instance.ocr(img_array, cls=True)
        except Exception as ocr_exc:
            logging.warning(f"PaddleOCR with cls=True failed: {ocr_exc}, trying without cls...")
            # –ü—Ä–æ–±—É–µ–º –±–µ–∑ cls (—É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞)
            result = ocr_instance.ocr(img_array, cls=False)
        
        logging.info(f"PaddleOCR returned result: {type(result)}, length: {len(result) if result else 0}")
        
        # PaddleOCR –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        # –§–æ—Ä–º–∞—Ç: [[[–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã], (—Ç–µ–∫—Å—Ç, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)], ...]
        if not result:
            logging.warning("PaddleOCR returned empty result")
            return "", 0.0
        if not result[0]:
            logging.warning("PaddleOCR returned result with empty first element")
            return "", 0.0
        
        lines = []
        total_confidence = 0.0
        count = 0
        
        logging.info(f"Processing {len(result[0])} line results from PaddleOCR")
        for idx, line_result in enumerate(result[0]):
            try:
                if not line_result or len(line_result) < 2:
                    logging.debug(f"Skipping line_result {idx}: invalid format")
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                if isinstance(line_result[1], tuple):
                    text = line_result[1][0] if len(line_result[1]) > 0 else ""
                    confidence = line_result[1][1] if len(line_result[1]) > 1 else 1.0
                else:
                    text = str(line_result[1])
                    confidence = 1.0
                
                if text and text.strip():
                    lines.append(text.strip())
                    total_confidence += confidence
                    count += 1
            except Exception as line_exc:
                logging.warning(f"Error processing line_result {idx}: {line_exc}")
                continue
        
        if not lines:
            logging.warning("PaddleOCR returned no text lines")
            return "", 0.0
        
        text = "\n".join(lines)
        avg_confidence = total_confidence / count if count > 0 else 0.0
        
        logging.info(f"PaddleOCR recognized {count} lines, avg confidence: {avg_confidence:.2f}")
        return text, avg_confidence
        
    except Exception as exc:
        error_msg = str(exc)
        logging.error(f"PaddleOCR error: {error_msg}", exc_info=True)
        # –ü—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –±–µ–∑ cls
        try:
            logging.info("Retrying PaddleOCR without angle classification...")
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ RGB
            if image.mode != "RGB":
                image = image.convert("RGB")
            img_array_simple = np.array(image)
            if len(img_array_simple.shape) == 3 and img_array_simple.shape[2] == 3:
                img_array_simple = cv2.cvtColor(img_array_simple, cv2.COLOR_RGB2BGR)
            result = ocr_instance.ocr(img_array_simple, cls=False)
            if result and result[0]:
                lines = []
                for line_result in result[0]:
                    if line_result and len(line_result) >= 2:
                        if isinstance(line_result[1], tuple):
                            text = line_result[1][0] if len(line_result[1]) > 0 else ""
                        else:
                            text = str(line_result[1])
                        if text and text.strip():
                            lines.append(text.strip())
                if lines:
                    text = "\n".join(lines)
                    logging.info(f"PaddleOCR retry successful: {len(text)} chars")
                    return text, 0.5
        except Exception as retry_exc:
            logging.error(f"PaddleOCR retry also failed: {retry_exc}", exc_info=True)
        raise ReceiptParsingError(f"PaddleOCR –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {error_msg}") from exc


def run_multi_pass_ocr(image: "Image.Image") -> tuple[str, int]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç OCR —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Tesseract)."""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Tesseract
    if not TESSERACT_AVAILABLE or pytesseract is None:
        raise ReceiptParsingError("–ù–∏ Tesseract, –Ω–∏ PaddleOCR –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")
    
    variants = build_ocr_variants(image)
    best_text = ""
    best_score = float("-inf")
    for variant in variants:
        text, score = run_ocr_pass(variant)
        if score > best_score and text.strip():
            best_score = score
            best_text = text
    logging.debug("OCR multipass: single orientation score=%.2f", best_score)
    if best_text.strip():
        return best_text, 0
    fallback_text = pytesseract.image_to_string(
        image,
        lang=RECEIPT_FALLBACK_LANG,
        config=TESSERACT_CONFIG,
    )
    return fallback_text, 0


def build_ocr_variants(image: "Image.Image") -> List["Image.Image"]:
    base = image
    variants = [base]
    if ImageOps is not None:
        variants.append(ImageOps.invert(base))
    if ImageFilter is not None:
        variants.append(base.filter(ImageFilter.UnsharpMask(radius=2, percent=150)))
    return variants


def run_ocr_pass(image: "Image.Image") -> tuple[str, float]:
    if Output is None:
        text = pytesseract.image_to_string(
            image,
            lang=RECEIPT_FALLBACK_LANG,
            config=TESSERACT_CONFIG,
        )
        return text, float(len(text))
    data = pytesseract.image_to_data(
        image,
        lang=RECEIPT_FALLBACK_LANG,
        config=TESSERACT_CONFIG,
        output_type=Output.DICT,
    )
    text = build_text_from_data(data)
    score = _score_ocr_data(data)
    return text, score


def _score_ocr_data(data: Dict[str, List[Any]]) -> float:
    numeric: List[float] = []
    for conf in data.get("conf", []):
        try:
            numeric.append(float(conf))
        except (TypeError, ValueError):
            continue
    if not numeric:
        return -float("inf")
    return sum(numeric) / len(numeric)


def image_to_png_bytes(image: "Image.Image") -> Optional[bytes]:
    try:
        buffer = io.BytesIO()
        image.save(buffer, format="PNG")
        return buffer.getvalue()
    except Exception:
        return None


ENABLE_LOCAL_OCR = os.getenv("ENABLE_LOCAL_OCR", "1").lower() not in ("0", "false")


async def parse_receipt_pipeline(file_bytes: bytes, mime_type: str) -> ParsedReceipt:
    try:
        return await parse_receipt_with_ai(file_bytes, mime_type)
    except ReceiptParsingError as exc:
        logging.warning("Primary OCR failed, trying fallback: %s", exc)
        if not ENABLE_LOCAL_OCR or not TESSERACT_AVAILABLE or not mime_type.startswith("image/"):
            raise
        return parse_receipt_with_tesseract(file_bytes)


def parse_receipt_with_tesseract(file_bytes: bytes) -> ParsedReceipt:
    if not TESSERACT_AVAILABLE or Image is None or pytesseract is None:
        raise ReceiptParsingError("–õ–æ–∫–∞–ª—å–Ω—ã–π OCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç pytesseract/Pillow).")
    try:
        with Image.open(io.BytesIO(file_bytes)) as image:
            image = image.convert("RGB")
            text = pytesseract.image_to_string(image, lang=RECEIPT_FALLBACK_LANG)
    except Exception as exc:  # pragma: no cover - depends on external binary
        raise ReceiptParsingError("–õ–æ–∫–∞–ª—å–Ω—ã–π OCR –Ω–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.") from exc
    if not text.strip():
        raise ReceiptParsingError("–õ–æ–∫–∞–ª—å–Ω—ã–π OCR –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")
    return build_parsed_receipt_from_text(text)


def build_parsed_receipt_from_text(text: str) -> ParsedReceipt:
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    store = lines[0] if lines else "Unknown store"
    total = _extract_total_from_text(lines)
    currency = _currency_from_value(text) or "RUB"
    purchased_at = parse_datetime_flexible(_find_first_date(text))
    items = [
        ParsedReceiptItem(
            name="–ü–æ–∫—É–ø–∫–∞",
            quantity=1.0,
            price=total if total is not None else 0.0,
        )
    ]
    return ParsedReceipt(
        store=store,
        total=total if total is not None else 0.0,
        currency=currency,
        purchased_at=purchased_at,
        tax_amount=None,
        items=items,
    )


def _extract_total_from_text(lines: List[str]) -> Optional[float]:
    for line in reversed(lines):
        if re.search(r"(–∏—Ç–æ–≥|–∏—Ç–æ–≥–æ|total|amount|–∫ –æ–ø–ª–∞—Ç–µ)", line, re.IGNORECASE):
            numbers = re.findall(r"(-?\d+[.,]?\d*)", line)
            if numbers:
                return safe_float(numbers[-1])
    candidates: List[float] = []
    for line in lines[-10:]:
        candidates.extend(
            safe_float(value)
            for value in re.findall(r"(-?\d+[.,]?\d*)", line)
        )
    return max(candidates) if candidates else None


def _find_first_date(text: str) -> Optional[str]:
    match = re.search(r"(\d{1,2}[./-]\d{1,2}(?:[./-]\d{2,4})?)", text)
    if match:
        token = match.group(1)
        if len(token.split(".")) == 2:
            current_year = datetime.utcnow().year
            return f"{token}.{current_year}"
        return token
    return None


def get_receipt_parser() -> "ReceiptParserAI":
    global _receipt_parser
    if _receipt_parser is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ReceiptParsingError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω, –ø–∞—Ä—Å–∏–Ω–≥ —á–µ–∫–æ–≤ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        _receipt_parser = ReceiptParserAI(api_key=api_key)
    return _receipt_parser


async def parse_receipt_with_ai(
    file_bytes: bytes, 
    mime_type: str, 
    qr_data: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ OpenAI –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π JSON response."""
    parser = get_receipt_parser()
    return await parser.parse(file_bytes, mime_type, qr_data=qr_data)


async def improve_receipt_data_with_ai(receipt_data: Dict[str, Any]) -> Dict[str, Any]:
    """–£–ª—É—á—à–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ —á–µ—Ä–µ–∑ OpenAI –±–µ–∑ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    parser = get_receipt_parser()
    return await parser.improve_receipt_data(receipt_data)


def build_data_url(file_bytes: bytes, mime_type: str) -> str:
    encoded = base64.b64encode(file_bytes).decode("ascii")
    return f"data:{mime_type};base64,{encoded}"


def read_qr_codes(file_bytes: bytes) -> List[Dict[str, Any]]:
    """
    –ß–∏—Ç–∞–µ—Ç QR-–∫–æ–¥—ã –∏ —à—Ç—Ä–∏—Ö-–∫–æ–¥—ã –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–¥–∞—Ö.
    –ü—Ä–æ–±—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç pyzbar, OpenCV QRCodeDetector –∏ OCR –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã.
    """
    all_results = []
    seen_data = set()  # –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    
    if Image is None:
        logging.warning("Pillow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —á—Ç–µ–Ω–∏–µ QR-–∫–æ–¥–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
        return []
    
    try:
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(io.BytesIO(file_bytes))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # –ú–µ—Ç–æ–¥ 1: pyzbar (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if QR_READER_AVAILABLE and pyzbar_decode is not None:
            # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è QR-–∫–æ–¥–æ–≤
            image_large = image.resize((image.width * 3, image.height * 3), Image.Resampling.LANCZOS)
            image_very_large = image.resize((image.width * 4, image.height * 4), Image.Resampling.LANCZOS)
            
            variants = [
                ("original", image),
                ("grayscale", image.convert("L").convert("RGB")),
                ("enhanced", ImageOps.autocontrast(image)),
                ("enhanced_large", ImageOps.autocontrast(image_large)),
                ("large", image_large),
                ("very_large", image_very_large),
                ("sharp", image.filter(ImageFilter.SHARPEN) if ImageFilter is not None else image),
            ]
            
            for variant_name, processed_image in variants:
                try:
                    # –ß–∏—Ç–∞–µ–º –∫–æ–¥—ã –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    codes = pyzbar_decode(processed_image)
                    
                    for code in codes:
                        try:
                            data = code.data.decode("utf-8")
                            code_type = code.type
                            
                            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º CODE39 –∏ –¥—Ä—É–≥–∏–µ —à—Ç—Ä–∏—Ö-–∫–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è URL
                            # –û–Ω–∏ –Ω–µ –Ω–µ—Å—É—Ç –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –Ω–∞—Å
                            if code_type == "CODE39" and not is_url(data):
                                logging.debug(f"–ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º CODE39 (–Ω–µ URL): {data[:50]}...")
                                continue
                            
                            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                            if data in seen_data:
                                continue
                            seen_data.add(data)
                            
                            rect = code.rect
                            result = {
                                "data": data,
                                "type": code_type,
                                "rect": {
                                    "left": rect.left,
                                    "top": rect.top,
                                    "width": rect.width,
                                    "height": rect.height,
                                },
                            }
                            all_results.append(result)
                            logging.info(f"–ù–∞–π–¥–µ–Ω –∫–æ–¥ —Ç–∏–ø–∞ {code_type} (pyzbar, –≤–∞—Ä–∏–∞–Ω—Ç {variant_name}): {data[:100]}...")
                        except UnicodeDecodeError:
                            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                            try:
                                data = code.data.decode("latin-1")
                                if data not in seen_data:
                                    seen_data.add(data)
                                    code_type = code.type
                                    rect = code.rect
                                    result = {
                                        "data": data,
                                        "type": code_type,
                                        "rect": {
                                            "left": rect.left,
                                            "top": rect.top,
                                            "width": rect.width,
                                            "height": rect.height,
                                        },
                                    }
                                    all_results.append(result)
                                    logging.info(f"–ù–∞–π–¥–µ–Ω –∫–æ–¥ —Ç–∏–ø–∞ {code_type} (latin-1, –≤–∞—Ä–∏–∞–Ω—Ç {variant_name}): {data[:100]}...")
                            except Exception:
                                continue
                except Exception as exc:
                    logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ {variant_name}: {exc}")
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–±—É–µ–º —Å OpenCV –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            if not all_results and cv2 is not None:
                try:
                    import numpy as np
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL –≤ numpy array
                    img_array = np.array(image)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º RGB –≤ BGR –¥–ª—è OpenCV
                    img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                    
                    # –ü—Ä–æ–±—É–µ–º —É–ª—É—á—à–∏—Ç—å –∫–æ–Ω—Ç—Ä–∞—Å—Ç
                    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                    # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
                    adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ RGB –¥–ª—è pyzbar
                    adaptive_rgb = cv2.cvtColor(adaptive, cv2.COLOR_GRAY2RGB)
                    adaptive_pil = Image.fromarray(adaptive_rgb)
                    
                    codes = pyzbar_decode(adaptive_pil)
                    for code in codes:
                        try:
                            data = code.data.decode("utf-8")
                            if data not in seen_data:
                                seen_data.add(data)
                                code_type = code.type
                                rect = code.rect
                                result = {
                                    "data": data,
                                    "type": code_type,
                                    "rect": {
                                        "left": rect.left,
                                        "top": rect.top,
                                        "width": rect.width,
                                        "height": rect.height,
                                    },
                                }
                                all_results.append(result)
                                logging.info(f"–ù–∞–π–¥–µ–Ω –∫–æ–¥ —Ç–∏–ø–∞ {code_type} (OpenCV+pyzbar): {data[:100]}...")
                        except Exception:
                            continue
                except Exception as exc:
                    logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ OpenCV –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª—è pyzbar: {exc}")
        
        # –ú–µ—Ç–æ–¥ 2: OpenCV QRCodeDetector (–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –¥–ª—è QR-–∫–æ–¥–æ–≤)
        # –í—ã–∑—ã–≤–∞–µ–º –í–°–ï–ì–î–ê, –¥–∞–∂–µ –µ—Å–ª–∏ pyzbar —á—Ç–æ-—Ç–æ –Ω–∞—à–µ–ª, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –º–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π QR-–∫–æ–¥
        if cv2 is not None:
            logging.info("–ü—Ä–æ–±—É–µ–º OpenCV QRCodeDetector...")
            try:
                import numpy as np
                img_array = np.array(image)
                img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º QRCodeDetector –∏–∑ OpenCV
                qr_detector = cv2.QRCodeDetector()
                
                # –£–ª—É—á—à–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                gray_clahe = clahe.apply(gray)
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (QR-–∫–æ–¥—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∏–º–∏)
                scale_factor = 3
                gray_large = cv2.resize(gray, (gray.shape[1] * scale_factor, gray.shape[0] * scale_factor), interpolation=cv2.INTER_CUBIC)
                gray_clahe_large = cv2.resize(gray_clahe, (gray_clahe.shape[1] * scale_factor, gray_clahe.shape[0] * scale_factor), interpolation=cv2.INTER_CUBIC)
                
                # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                gray_variants = [
                    ("original", gray),
                    ("original_large", gray_large),
                    ("clahe", gray_clahe),
                    ("clahe_large", gray_clahe_large),
                    ("adaptive", cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)),
                    ("adaptive_large", cv2.adaptiveThreshold(gray_large, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)),
                    ("adaptive_inv", cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)),
                    ("otsu", cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]),
                    ("otsu_large", cv2.threshold(gray_large, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]),
                    ("otsu_inv", cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]),
                ]
                
                for variant_name, processed_gray in gray_variants:
                    try:
                        # –ü—Ä–æ–±—É–µ–º detectAndDecodeMulti (–¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö QR-–∫–æ–¥–æ–≤)
                        retval, decoded_info, points, straight_qrcode = qr_detector.detectAndDecodeMulti(processed_gray)
                        logging.info(f"OpenCV QRCodeDetector ({variant_name}): retval={retval}, decoded_info={decoded_info}")
                        
                        if retval and decoded_info:
                            for i, data in enumerate(decoded_info):
                                if data and data not in seen_data:
                                    seen_data.add(data)
                                    result = {
                                        "data": data,
                                        "type": "QRCODE",
                                        "rect": {
                                            "left": 0,
                                            "top": 0,
                                            "width": processed_gray.shape[1],
                                            "height": processed_gray.shape[0],
                                        },
                                    }
                                    all_results.append(result)
                                    logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ (OpenCV QRCodeDetector, {variant_name}): {data[:100]}...")
                                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ QR-–∫–æ–¥ —Å URL, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                                    if is_url(data):
                                        logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ —Å URL, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∏—Å–∫")
                                        break
                        else:
                            # –ï—Å–ª–∏ detectAndDecodeMulti –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º detectAndDecode (–¥–ª—è –æ–¥–Ω–æ–≥–æ QR-–∫–æ–¥–∞)
                            # –í —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö OpenCV –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ç–æ–ª—å–∫–æ 3 –∑–Ω–∞—á–µ–Ω–∏—è
                            try:
                                result_single = qr_detector.detectAndDecode(processed_gray)
                                if isinstance(result_single, tuple):
                                    if len(result_single) >= 2:
                                        retval_single, decoded_info_single = result_single[0], result_single[1]
                                    else:
                                        retval_single, decoded_info_single = False, ""
                                else:
                                    # –ï—Å–ª–∏ –≤–µ—Ä–Ω—É–ª–∞—Å—å —Å—Ç—Ä–æ–∫–∞ –Ω–∞–ø—Ä—è–º—É—é
                                    retval_single, decoded_info_single = bool(result_single), result_single if result_single else ""
                                
                                logging.info(f"OpenCV QRCodeDetector single ({variant_name}): retval={retval_single}, decoded_info={decoded_info_single}")
                                
                                if retval_single and decoded_info_single and decoded_info_single not in seen_data:
                                    seen_data.add(decoded_info_single)
                                    result = {
                                        "data": decoded_info_single,
                                        "type": "QRCODE",
                                        "rect": {
                                            "left": 0,
                                            "top": 0,
                                            "width": processed_gray.shape[1],
                                            "height": processed_gray.shape[0],
                                        },
                                    }
                                    all_results.append(result)
                                    logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ (OpenCV QRCodeDetector single, {variant_name}): {decoded_info_single[:100]}...")
                                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ QR-–∫–æ–¥ —Å URL, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                                    if is_url(decoded_info_single):
                                        logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ —Å URL, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∏—Å–∫")
                                        break
                            except ValueError as ve:
                                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π —Å–ø–æ—Å–æ–±
                                logging.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç detectAndDecode: {ve}")
                                continue
                        
                        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ QR-–∫–æ–¥ —Å URL, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
                        if any(is_url(r.get("data", "")) for r in all_results):
                            logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ —Å URL, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–µ—Ä–µ–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                            break
                    except Exception as exc:
                        logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ OpenCV QRCodeDetector ({variant_name}): {exc}", exc_info=True)
                        continue
            except Exception as exc:
                logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ OpenCV QRCodeDetector: {exc}")
        else:
            logging.info("OpenCV –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º QRCodeDetector")
        
        # –ú–µ—Ç–æ–¥ 3: qreader (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Å YOLO –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ QR-–∫–æ–¥–æ–≤)
        if QREADER_AVAILABLE and qreader_instance is not None:
            logging.info("–ü—Ä–æ–±—É–µ–º qreader...")
            try:
                import numpy as np
                img_array = np.array(image)
                
                # qreader —Ä–∞–±–æ—Ç–∞–µ—Ç —Å numpy –º–∞—Å—Å–∏–≤–∞–º–∏
                try:
                    decoded_result = qreader_instance.detect_and_decode(image=img_array)
                    # qreader –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –∫–æ—Ä—Ç–µ–∂ –∏–ª–∏ —Å—Ç—Ä–æ–∫—É
                    if isinstance(decoded_result, tuple):
                        decoded_text = decoded_result[0] if decoded_result else None
                    else:
                        decoded_text = decoded_result
                    
                    if decoded_text and decoded_text not in seen_data:
                        seen_data.add(decoded_text)
                        result = {
                            "data": decoded_text,
                            "type": "QRCODE",
                            "rect": {
                                "left": 0,
                                "top": 0,
                                "width": image.width,
                                "height": image.height,
                            },
                        }
                        all_results.append(result)
                        logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ (qreader): {decoded_text[:100]}...")
                        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ QR-–∫–æ–¥ —Å URL, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                        if is_url(decoded_text):
                            logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ —Å URL —á–µ—Ä–µ–∑ qreader, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∏—Å–∫")
                            return all_results
                except Exception as exc:
                    logging.debug(f"qreader –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å QR-–∫–æ–¥: {exc}")
                
                # –ü—Ä–æ–±—É–µ–º —Ç–∞–∫–∂–µ –Ω–∞ —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ URL)
                if not any(is_url(r.get("data", "")) for r in all_results):
                    try:
                        image_large = image.resize((image.width * 3, image.height * 3), Image.Resampling.LANCZOS)
                        img_array_large = np.array(image_large)
                        decoded_result_large = qreader_instance.detect_and_decode(image=img_array_large)
                        # qreader –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –∫–æ—Ä—Ç–µ–∂ –∏–ª–∏ —Å—Ç—Ä–æ–∫—É
                        if isinstance(decoded_result_large, tuple):
                            decoded_text_large = decoded_result_large[0] if decoded_result_large else None
                        else:
                            decoded_text_large = decoded_result_large
                        
                        if decoded_text_large and decoded_text_large not in seen_data:
                            seen_data.add(decoded_text_large)
                            result = {
                                "data": decoded_text_large,
                                "type": "QRCODE",
                                "rect": {
                                    "left": 0,
                                    "top": 0,
                                    "width": image_large.width,
                                    "height": image_large.height,
                                },
                            }
                            all_results.append(result)
                            logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ (qreader, —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ): {decoded_text_large[:100]}...")
                            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ QR-–∫–æ–¥ —Å URL, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                            if is_url(decoded_text_large):
                                logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω QR-–∫–æ–¥ —Å URL —á–µ—Ä–µ–∑ qreader (—É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ), –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∏—Å–∫")
                                return all_results
                    except Exception as exc:
                        logging.debug(f"qreader –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å QR-–∫–æ–¥ –Ω–∞ —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {exc}")
            except Exception as exc:
                logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ qreader: {exc}")
        else:
            logging.info("qreader –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        
        return all_results
    except Exception as exc:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ QR-–∫–æ–¥–æ–≤: {exc}")
        return []


def is_url(text: str | tuple) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç URL."""
    if not text:
        return False
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ—Ä—Ç–µ–∂–∏ (qreader –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –∫–æ—Ä—Ç–µ–∂)
    if isinstance(text, tuple):
        text = text[0] if text else ""
    if not isinstance(text, str):
        return False
    text = text.strip()
    return text.startswith(("http://", "https://"))


def parse_ofd_kz_html(html_content: str) -> Optional[Dict[str, Any]]:
    """
    –ü–∞—Ä—Å–∏—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É ofd1.kz/ofd.kz –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞.
    """
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        logging.warning("BeautifulSoup4 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, HTML –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return None
    
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        store_elem = soup.select_one('.ticket_header span, .ticket_header div span')
        store = store_elem.get_text(strip=True) if store_elem else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        
        # –î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è
        date_elem = soup.select_one('.ticket_date_time')
        date_str = date_elem.get_text(strip=True) if date_elem else None
        
        # –ê–¥—Ä–µ—Å
        address_elem = soup.select_one('.wb-all')
        address = address_elem.get_text(strip=True) if address_elem else None
        
        # –¢–æ–≤–∞—Ä—ã
        items = []
        items_list = soup.select('.ready_ticket__items_list li')
        
        for item_elem in items_list:
            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            name_elem = item_elem.select_one('.wb-all')
            if not name_elem:
                continue
            name = name_elem.get_text(strip=True)
            if not name or len(name) < 3:
                continue
            
            # –¶–µ–Ω–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ —Å–ª–µ–¥—É—é—â–µ–º —ç–ª–µ–º–µ–Ω—Ç–µ
            price_elem = item_elem.select_one('.ready_ticket__item')
            price_text = price_elem.get_text(strip=True) if price_elem else ""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ —Ü–µ–Ω—É –∑–∞ –µ–¥–∏–Ω–∏—Ü—É (—Ñ–æ—Ä–º–∞—Ç: "3.000 X 649.00" –∏–ª–∏ "=1947.00")
            qty_price_match = re.search(r'(\d+\.?\d*)\s*[xX√ó]\s*(\d+\.?\d*)', price_text)
            if qty_price_match:
                quantity = float(qty_price_match.group(1))
                unit_price = float(qty_price_match.group(2))
                total_price = quantity * unit_price
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏—Ç–æ–≥–æ–≤—É—é —Ü–µ–Ω—É (—Ñ–æ—Ä–º–∞—Ç: "=1947.00")
                total_price_match = re.search(r'[=]\s*(\d+\.?\d*)', price_text)
                if total_price_match:
                    total_price = float(total_price_match.group(1))
                    quantity = 1.0
                    unit_price = total_price
                else:
                    # –ü—Ä–æ—Å—Ç–æ –∏—â–µ–º —á–∏—Å–ª–æ
                    price_match = re.search(r'(\d+\.?\d*)', price_text.replace(' ', ''))
                    if price_match:
                        total_price = float(price_match.group(1))
                        quantity = 1.0
                        unit_price = total_price
                    else:
                        continue
            
            items.append({
                "name": name,
                "quantity": quantity,
                "price": total_price,
                "category": None
            })
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—É–º–º–∞
        total_elem = soup.select_one('.ticket_total')
        if not total_elem:
            total_elem = soup.select_one('.total_sum, [class*="total"]')
        total_text = total_elem.get_text(strip=True) if total_elem else ""
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        total_text = re.sub(r'\s+', '', total_text)
        total_match = re.search(r'(\d+\.?\d*)', total_text)
        total = float(total_match.group(1)) if total_match else 0.0
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ total, —Å—É–º–º–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã
        if total == 0.0 and items:
            total = sum(item["price"] for item in items)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ–≤–∞—Ä—ã, –Ω–æ –µ—Å—Ç—å –æ–±—â–∞—è —Å—É–º–º–∞, —Å–æ–∑–¥–∞–µ–º –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä
        if not items and total > 0:
            items.append({
                "name": "–ü–æ–∫—É–ø–∫–∞",
                "quantity": 1.0,
                "price": total,
                "category": None
            })
        
        # –í–∞–ª—é—Ç–∞ (–æ–±—ã—á–Ω–æ KZT –¥–ª—è –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞)
        currency = "KZT"
        
        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
        purchased_at = None
        if date_str:
            try:
                # –§–æ—Ä–º–∞—Ç: "2025-12-03 19:08:23.000000" –∏–ª–∏ "3 –¥–µ–∫ 2025, 19:08"
                if '.' in date_str:
                    purchased_at = datetime.strptime(date_str.split('.')[0], "%Y-%m-%d %H:%M:%S").isoformat()
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç
                    purchased_at = datetime.utcnow().isoformat()
            except:
                purchased_at = datetime.utcnow().isoformat()
        
        result = {
            "store": store,
            "merchant_address": address,
            "purchased_at": purchased_at or datetime.utcnow().isoformat(),
            "currency": currency,
            "total": total,
            "tax_amount": None,
            "items": items
        }
        
        logging.info(f"–†–∞—Å–ø–∞—Ä—Å–∏–ª–∏ ofd.kz HTML: store={store}, items={len(items)}, total={total}")
        return result
        
    except Exception as exc:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ HTML ofd.kz: {exc}")
        return None


async def fetch_receipt_from_qr_url(qr_url: str) -> Optional[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ –ø–æ URL –∏–∑ QR-–∫–æ–¥–∞.
    –ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API endpoint –∏–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ HTML.
    """
    from urllib.parse import urlparse, parse_qs
    
    try:
        logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ–∫–∞ –ø–æ URL: {qr_url}")
        parsed_url = urlparse(qr_url)
        query_params = parse_qs(parsed_url.query)
        
        # –î–ª—è consumer.oofd.kz —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–π API endpoint
        if "consumer.oofd.kz" in qr_url and all(key in query_params for key in ['i', 'f', 's', 't']):
            api_url = f"{parsed_url.scheme}://{parsed_url.netloc}/api/tickets/get-by-url"
            api_params = {
                't': query_params['t'][0],
                'i': query_params['i'][0],
                'f': query_params['f'][0],
                's': query_params['s'][0],
            }
            
            logging.info(f"–ü—Ä–æ–±—É–µ–º API endpoint: {api_url}")
            try:
                api_response = requests.get(
                    api_url,
                    params=api_params,
                    timeout=10,
                    verify=False,
                    headers={
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                        "Referer": qr_url
                    }
                )
                
                if api_response.status_code == 200:
                    try:
                        api_data = api_response.json()
                        if api_data:
                            logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API endpoint: {list(api_data.keys()) if isinstance(api_data, dict) else 'list'}")
                            return api_data
                    except json.JSONDecodeError:
                        logging.warning("API –≤–µ—Ä–Ω—É–ª –Ω–µ JSON")
            except Exception as api_exc:
                logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API endpoint: {api_exc}")
        
        # –ï—Å–ª–∏ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –¥–µ–ª–∞–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ URL
        response = requests.get(
            qr_url,
            timeout=15,
            headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"},
            verify=False,
            allow_redirects=True
        )
        
        if response.status_code != 200:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: —Å—Ç–∞—Ç—É—Å {response.status_code}")
            return None
        
        content_type = response.headers.get("Content-Type", "").lower()
        
        # –ï—Å–ª–∏ —ç—Ç–æ JSON
        if "application/json" in content_type or response.text.strip().startswith("{"):
            try:
                data = response.json()
                logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã JSON –¥–∞–Ω–Ω—ã–µ –∏–∑ QR-–∫–æ–¥–∞: {list(data.keys())}")
                return data
            except json.JSONDecodeError:
                logging.warning("–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON")
        
        # –ï—Å–ª–∏ —ç—Ç–æ HTML, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        if "text/html" in content_type:
            html_content = response.text
            
            # –ò—â–µ–º JSON –≤ script —Ç–µ–≥–∞—Ö
            json_patterns = [
                r'window\.receiptData\s*=\s*({.+?});',
                r'var\s+receipt\s*=\s*({.+?});',
                r'const\s+receipt\s*=\s*({.+?});',
                r'let\s+receipt\s*=\s*({.+?});',
                r'__INITIAL_STATE__\s*=\s*({.+?});',
                r'window\.__data__\s*=\s*({.+?});',
            ]
            
            for pattern in json_patterns:
                match = re.search(pattern, html_content, re.DOTALL | re.IGNORECASE)
                if match:
                    try:
                        json_str = match.group(1)
                        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ–ª–Ω—ã–π JSON –æ–±—ä–µ–∫—Ç
                        brace_count = json_str.count('{') - json_str.count('}')
                        if brace_count > 0:
                            remaining = html_content[match.end():]
                            for i, char in enumerate(remaining):
                                if char == '}':
                                    brace_count -= 1
                                    if brace_count == 0:
                                        json_str = json_str + remaining[:i+1]
                                        break
                        
                        data = json.loads(json_str)
                        logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω JSON –≤ HTML: {list(data.keys()) if isinstance(data, dict) else 'list'}")
                        return data
                    except (json.JSONDecodeError, IndexError):
                        continue
            
            # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å HTML –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è ofd.kz
            if "ofd1.kz" in qr_url or "oofd.kz" in qr_url or "ofd.kz" in qr_url:
                parsed_data = parse_ofd_kz_html(html_content)
                if parsed_data:
                    items = parsed_data.get("items", [])
                    total = parsed_data.get("total", 0.0)
                    store = parsed_data.get("store", "")
                    
                    if items and total > 0 and store and store != "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
                        logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏ HTML: {list(parsed_data.keys())}")
                        return parsed_data
                    else:
                        logging.warning(f"‚ö†Ô∏è HTML –ø–∞—Ä—Å–∏–Ω–≥ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ: store={store}, items={len(items)}, total={total}")
                
                logging.warning("HTML –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.")
                return None
            
            logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –¥–∞–Ω–Ω—ã–µ –≤ HTML")
            return None
        
        logging.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {content_type}")
        return None
        
    except requests.exceptions.RequestException as exc:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ QR-–∫–æ–¥—É: {exc}")
        return None
    except Exception as exc:
        logging.exception(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ QR-–∫–æ–¥–∞: {exc}")
        return None


def extract_choice_text(response_json: Dict[str, Any]) -> str:
    choices = response_json.get("choices")
    if not choices:
        raise ReceiptParsingError("OpenAI –æ—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç choices.")
    message = choices[0].get("message", {})
    content = message.get("content")
    if isinstance(content, list):
        content = "".join(
            block.get("text", "")
            for block in content
            if isinstance(block, dict) and block.get("type") == "text"
        )
    if not isinstance(content, str):
        raise ReceiptParsingError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏.")
    stripped = content.strip()
    if not stripped:
        raise ReceiptParsingError("–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")
    return stripped


def build_parsed_receipt(data: Dict[str, Any]) -> ParsedReceipt:
    items_payload = data.get("items") or []
    items: List[ParsedReceiptItem] = []
    for item in items_payload:
        if not isinstance(item, dict):
            continue
        items.append(
            ParsedReceiptItem(
                name=str(item.get("name") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                quantity=safe_float(item.get("quantity"), default=1.0),
                price=safe_float(item.get("price")),
                category=item.get("category"),
            )
        )
    if not items:
        items = [
            ParsedReceiptItem(
                name="–ë–µ–∑ –ø–æ–∑–∏—Ü–∏–π",
                quantity=1.0,
                price=safe_float(data.get("total")),
            )
        ]
    tax_value = data.get("tax_amount")
    tax_amount = (
        safe_float(tax_value)
        if tax_value not in (None, "")
        else None
    )
    return ParsedReceipt(
        store=str(data.get("store") or "Unknown store"),
        total=safe_float(data.get("total")),
        currency=str(data.get("currency") or "RUB"),
        purchased_at=parse_datetime_flexible(data.get("purchased_at")),
        tax_amount=tax_amount,
        items=items,
        merchant_address=data.get("merchant_address"),
        external_id=data.get("external_id"),
    )


def parse_datetime_flexible(raw_value: Optional[str]) -> datetime:
    if not raw_value:
        return datetime.utcnow()
    value = raw_value.strip()
    if value.endswith("Z"):
        value = value[:-1] + "+00:00"
    for candidate in (value, f"{value}T00:00:00"):
        try:
            return datetime.fromisoformat(candidate)
        except ValueError:
            continue
    try:
        return datetime.strptime(value, "%Y-%m-%d")
    except ValueError:
        return datetime.utcnow()


def safe_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        return default


def build_receipt_payload(user_id: int, parsed: ParsedReceipt) -> Dict[str, Any]:
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ö–µ—à –∏–∑ user_id, –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏ –æ–ø–ª–∞—Ç—ã –∏ —Å—É–º–º—ã
    receipt_hash = calculate_hash(
        f"{user_id}|{parsed.purchased_at.isoformat()}|{parsed.total}"
    )
    return {
        "user_id": user_id,
        "store": parsed.store,
        "total": parsed.total,
        "currency": parsed.currency,
        "purchased_at": parsed.purchased_at.isoformat(),
        "tax_amount": parsed.tax_amount,
        "items": [asdict(item) for item in parsed.items],
        "receipt_hash": receipt_hash,
        "external_id": parsed.external_id,
        "merchant_address": parsed.merchant_address,
    }


def build_expense_payload_from_receipt(receipt_record: Dict[str, Any]) -> Dict[str, Any]:
    expense_hash = calculate_hash(
        f"{receipt_record.get('user_id')}|receipt|{receipt_record.get('receipt_hash')}"
    )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ items —á–µ–∫–∞ (–±–µ—Ä–µ–º —Å–∞–º—É—é —á–∞—Å—Ç—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é)
    category = None
    items = receipt_record.get("items", [])
    if items and isinstance(items, list):
        category_counts = {}
        for item in items:
            if isinstance(item, dict):
                item_category = item.get("category")
                if item_category:
                    category_counts[item_category] = category_counts.get(item_category, 0) + 1
        
        if category_counts:
            # –ë–µ—Ä–µ–º —Å–∞–º—É—é —á–∞—Å—Ç—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            category = max(category_counts.items(), key=lambda x: x[1])[0]
    
    payload = {
        "user_id": receipt_record.get("user_id"),
        "source": "receipt",
        "store": receipt_record.get("store"),
        "amount": receipt_record.get("total"),
        "currency": receipt_record.get("currency"),
        "date": receipt_record.get("purchased_at"),
        "receipt_id": receipt_record.get("id"),
        "expense_hash": expense_hash,
        "status": "pending_review",
        "period": (receipt_record.get("purchased_at") or "")[:7],
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –µ—Å–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏
    if category:
        payload["category"] = category
    
    return payload


def build_bank_payload(user_id: int, txn: ParsedBankTransaction) -> Dict[str, Any]:
    txn_hash = calculate_hash(
        f"{user_id}|{txn.source_id}|{txn.amount}|{txn.booked_at.isoformat()}"
    )
    return {
        "user_id": user_id,
        "amount": txn.amount,
        "currency": txn.currency,
        "merchant": txn.merchant,
        "booked_at": txn.booked_at.isoformat(),
        "description": txn.description,
        "source_id": txn.source_id,
        "transaction_hash": txn_hash,
    }


async def reconcile_transactions(
    gateway: SupabaseGateway,
    user_id: int,
    bank_records: List[Dict[str, Any]],
) -> None:
    """Simplified reconciliation placeholder."""

    if not bank_records:
        return

    for record in bank_records:
        expense_payload = {
            "user_id": user_id,
            "source": "bank",
            "store": record.get("merchant"),
            "amount": record.get("amount"),
            "currency": record.get("currency"),
            "date": record.get("booked_at"),
            "bank_transaction_id": record.get("id"),
            "expense_hash": calculate_hash(
                f"{user_id}|bank|{record.get('transaction_hash')}"
            ),
            "status": "pending_review",
            "period": (record.get("booked_at") or "")[:7],
        }
        expense_result = await gateway.record_expense(expense_payload)
        if expense_result.get("duplicate"):
            logging.info(f"Skipped duplicate expense from bank transaction: {record.get('transaction_hash')}")


def calculate_hash(value: str) -> str:
    return hashlib.sha256(value.encode("utf-8")).hexdigest()


async def parse_bank_statement(file_bytes: bytes) -> List[ParsedBankTransaction]:
    """Parse CSV/PDF bank statements into normalized transactions."""

    return await asyncio.to_thread(_parse_bank_statement_sync, file_bytes)


def _parse_bank_statement_sync(file_bytes: bytes) -> List[ParsedBankTransaction]:
    rows = _load_statement_rows(file_bytes)
    transactions: List[ParsedBankTransaction] = []
    for idx, row in enumerate(rows):
        normalized_row = _normalize_statement_row(row)
        txn = _build_transaction_from_row(normalized_row, idx)
        if txn:
            transactions.append(txn)

    if not transactions:
        raise StatementParsingError("–í—ã–ø–∏—Å–∫–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.")
    return transactions


def _load_statement_rows(file_bytes: bytes) -> List[Dict[str, Any]]:
    header = file_bytes[:4]
    if header.startswith(b"%PDF"):
        return _extract_pdf_rows(file_bytes)
    if header.startswith(b"PK\x03\x04"):
        raise StatementParsingError("XLSX –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è ‚Äî —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ CSV.")

    text = _decode_statement_text(file_bytes)
    delimiter = _detect_delimiter(text)
    reader = csv.DictReader(io.StringIO(text), delimiter=delimiter)
    if not reader.fieldnames:
        raise StatementParsingError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞.")
    rows = list(reader)
    if not rows:
        raise StatementParsingError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫ –æ–ø–µ—Ä–∞—Ü–∏–π.")
    return rows


def _extract_pdf_rows(file_bytes: bytes) -> List[Dict[str, Any]]:
    if not PDF_SUPPORT or pdfplumber is None:
        raise StatementParsingError(
            "–î–ª—è —Ä–∞–∑–±–æ—Ä–∞ PDF —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–∞–∫–µ—Ç pdfplumber. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ requirements."
        )

    rows: List[Dict[str, Any]] = []
    text_lines: List[str] = []
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:  # type: ignore[arg-type]
        for page in pdf.pages:
            text = page.extract_text() or ""
            if text:
                text_lines.extend(text.splitlines())
            for table in page.extract_tables() or []:
                if not table or len(table) < 2:
                    continue
                headers = [_normalize_pdf_header(cell) for cell in table[0]]
                if not any(headers):
                    continue
                for raw_row in table[1:]:
                    row_dict: Dict[str, Any] = {}
                    for header, cell in zip(headers, raw_row):
                        key = header.strip().lower()
                        if not key:
                            continue
                        value = cell.strip() if isinstance(cell, str) else cell
                        row_dict[key] = value
                    if row_dict:
                        rows.append(row_dict)

    if rows:
        return rows

    fallback_rows = _parse_pdf_text_lines(text_lines)
    if not fallback_rows:
        raise StatementParsingError(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ PDF. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV."
        )
    return fallback_rows


def _parse_pdf_text_lines(lines: List[str]) -> List[Dict[str, Any]]:
    structured: List[Dict[str, Any]] = []
    headers: Optional[List[str]] = None
    for line in lines:
        normalized_line = " ".join(line.strip().split())
        if not normalized_line:
            continue
        segments = [segment.strip() for segment in _split_text_row(normalized_line)]
        if not segments:
            continue
        if headers is None:
            headers = [_normalize_pdf_header(cell) for cell in segments]
            continue
        if len(segments) != len(headers):
            continue
        row_dict = {
            header: value
            for header, value in zip(headers, segments)
            if header
        }
        if row_dict:
            structured.append(row_dict)
    return structured


def _split_text_row(line: str) -> List[str]:
    return [part for part in re.split(r"\s{2,}", line) if part]


def _normalize_pdf_header(cell: Optional[str]) -> str:
    if cell is None:
        return ""
    return " ".join(str(cell).strip().lower().split())


def _decode_statement_text(file_bytes: bytes) -> str:
    for encoding in ("utf-8-sig", "utf-16", "cp1251", "windows-1251", "latin-1"):
        try:
            return file_bytes.decode(encoding)
        except UnicodeDecodeError:
            continue
    raise StatementParsingError("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –≤—ã–ø–∏—Å–∫–∏.")


def _detect_delimiter(text: str) -> str:
    sample = text[:2000]
    try:
        dialect = csv.Sniffer().sniff(sample, delimiters=",;\t|")
        return dialect.delimiter
    except csv.Error:
        for delimiter in (",", ";", "\t", "|"):
            if delimiter in sample:
                return delimiter
    return ","


def _normalize_statement_row(row: Dict[str, Any]) -> Dict[str, Any]:
    normalized: Dict[str, Any] = {}
    for key, value in row.items():
        if key is None:
            continue
        normalized_key = key.strip().lower()
        if isinstance(value, str):
            normalized[normalized_key] = value.strip()
        else:
            normalized[normalized_key] = value
    return normalized


def _build_transaction_from_row(row: Dict[str, Any], idx: int) -> Optional[ParsedBankTransaction]:
    amount = _extract_amount(row)
    if amount is None:
        return None

    currency = _first_value(row, ("currency", "–≤–∞–ª—é—Ç–∞", "–∫–æ–¥ –≤–∞–ª—é—Ç—ã"))
    if currency:
        currency = currency.upper()
    else:
        currency = _infer_currency(row) or "RUB"
    merchant = (
        _first_value(
            row,
            (
                "merchant",
                "store",
                "–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç",
                "–ø–æ–ª—É—á–∞—Ç–µ–ª—å",
                "–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å",
                "–∏–Ω—Ñ–æ",
            ),
        )
        or _first_value(row, _DESCRIPTION_KEYS)
        or "Unknown merchant"
    )
    description = _first_value(row, _DESCRIPTION_KEYS) or merchant
    booked_raw = _first_value(
        row,
        (
            "date",
            "booked_at",
            "–¥–∞—Ç–∞",
            "–¥–∞—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏",
            "posting date",
            "operation date",
            "valuedate",
        ),
    )
    booked_at = parse_datetime_flexible(booked_raw) if booked_raw else datetime.utcnow()
    source_id = _first_value(
        row,
        (
            "id",
            "transaction id",
            "–Ω–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            "doc number",
            "reference",
        ),
    ) or calculate_hash(f"{idx}|{merchant}|{booked_at.isoformat()}|{amount}")

    return ParsedBankTransaction(
        amount=amount,
        currency=currency,
        merchant=merchant,
        booked_at=booked_at,
        description=description,
        source_id=str(source_id),
    )


def _extract_amount(row: Dict[str, Any]) -> Optional[float]:
    amount_raw = _first_value(
        row,
        (
            "amount",
            "sum",
            "—Å—É–º–º–∞",
            "–∏—Ç–æ–≥–æ",
            "—Å—É–º–º–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏",
            "—Å—É–º–º–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ (—Ä.)",
        ),
    )
    if amount_raw:
        return safe_float(_normalize_number(amount_raw))

    debit_raw = _first_value(row, ("debit", "—Ä–∞—Å—Ö–æ–¥", "—Å–ø–∏—Å–∞–Ω–∏–µ"))
    credit_raw = _first_value(row, ("credit", "–ø—Ä–∏—Ö–æ–¥", "–∑–∞—á–∏—Å–ª–µ–Ω–∏–µ"))
    debit = safe_float(_normalize_number(debit_raw), default=0.0)
    credit = safe_float(_normalize_number(credit_raw), default=0.0)
    if debit and not credit:
        return -abs(debit)
    if credit and not debit:
        return abs(credit)
    if debit or credit:
        return credit - debit
    return None


def _normalize_number(value: Any) -> str:
    if value is None:
        return ""
    if isinstance(value, (int, float)):
        return str(value)
    cleaned = str(value)
    for char in ("\xa0", " ", "\t"):
        cleaned = cleaned.replace(char, "")
    cleaned = cleaned.replace(",", ".")
    allowed = set("0123456789.-")
    cleaned = "".join(ch for ch in cleaned if ch in allowed)
    return cleaned


_DESCRIPTION_KEYS = (
    "description",
    "–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–∞",
    "–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ",
    "–¥–µ—Ç–∞–ª–∏",
    "comment",
    "–æ–ø–∏—Å–∞–Ω–∏–µ",
    "details",
)


def _first_value(row: Dict[str, Any], keys: tuple) -> Optional[str]:
    for key in keys:
        if key in row and row[key] not in (None, ""):
            value = row[key]
            return str(value)
    return None


MANUAL_AMOUNT_PATTERN = re.compile(
    r"(?P<amount>-?\d+[.,]?\d{0,2})\s*(?P<currency>‚ÇΩ|—Ä\.?|—Ä—É–±|rub|‚Ç∏|—Ç–≥|kzt|\$|usd|eur|‚Ç¨|byn|—Å–æ–º|kgs)?",
    re.IGNORECASE,
)
MANUAL_DATE_PATTERN = re.compile(r"(\d{1,2}[./-]\d{1,2}(?:[./-]\d{2,4})?)")


def parse_manual_expense(text: str) -> Optional[ParsedManualExpense]:
    cleaned = " ".join((text or "").strip().split())
    if len(cleaned) < 3:
        return None
    amount_match = MANUAL_AMOUNT_PATTERN.search(cleaned)
    if not amount_match:
        return None
    amount = safe_float(amount_match.group("amount"))
    token_currency = amount_match.group("currency") or ""
    detected_currency = (
        _currency_from_value(token_currency)
        or _currency_from_value(cleaned)
        or "RUB"
    )
    date_match = MANUAL_DATE_PATTERN.search(cleaned)
    occurred_at = (
        _parse_manual_date(date_match.group(1)) if date_match else datetime.utcnow()
    )
    store_text = cleaned
    store_text = store_text.replace(amount_match.group(0), "", 1)
    if date_match:
        store_text = store_text.replace(date_match.group(0), "", 1)
    store = store_text.strip(" ,.-") or "–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"
    return ParsedManualExpense(
        store=store,
        amount=amount,
        currency=detected_currency,
        occurred_at=occurred_at,
        note=cleaned,
    )


def _parse_manual_date(token: str) -> datetime:
    token = token.replace("-", ".").replace("/", ".")
    parts = token.split(".")
    if len(parts) == 2:
        parts.append(str(datetime.utcnow().year))
    normalized = ".".join(parts)
    for fmt in ("%d.%m.%Y", "%d.%m.%y"):
        try:
            dt = datetime.strptime(normalized, fmt)
            return dt
        except ValueError:
            continue
    return datetime.utcnow()


def format_manual_summary(parsed: ParsedManualExpense) -> str:
    return (
        "–ó–∞–ø–∏—Å–∞–ª —Ä–∞—Å—Ö–æ–¥ –≤—Ä—É—á–Ω—É—é:\n"
        f"‚Ä¢ –ú–∞–≥–∞–∑–∏–Ω: {parsed.store}\n"
        f"‚Ä¢ –î–∞—Ç–∞: {parsed.occurred_at.strftime('%Y-%m-%d')}\n"
        f"‚Ä¢ –°—É–º–º–∞: {parsed.amount:.2f} {parsed.currency}"
    )


def build_manual_expense_payload(user_id: int, parsed: ParsedManualExpense) -> Dict[str, Any]:
    expense_hash = calculate_hash(
        f"{user_id}|manual|{parsed.store}|{parsed.occurred_at.isoformat()}|{parsed.amount}"
    )
    return {
        "user_id": user_id,
        "source": "manual",
        "store": parsed.store,
        "amount": parsed.amount,
        "currency": parsed.currency,
        "date": parsed.occurred_at.isoformat(),
        "note": parsed.note,
        "expense_hash": expense_hash,
        "status": "pending_review",
        "period": parsed.occurred_at.strftime("%Y-%m"),
    }


def _infer_currency(row: Dict[str, Any]) -> Optional[str]:
    for value in row.values():
        code = _currency_from_value(value)
        if code:
            return code
    return None


def _currency_from_value(value: Any) -> Optional[str]:
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return None
    text = str(value).strip()
    if not text:
        return None
    for symbol, code in _CURRENCY_SYMBOLS.items():
        if symbol in text:
            return code
    lower_text = text.lower()
    for token, code in _CURRENCY_TOKENS.items():
        if token in lower_text:
            return code
    iso_match = re.search(r"\b([A-Z]{3})\b", text.upper())
    if iso_match:
        candidate = iso_match.group(1)
        if candidate in _KNOWN_ISO_CODES:
            return "RUB" if candidate == "RUR" else candidate
    return None


_CURRENCY_SYMBOLS = {
    "‚ÇΩ": "RUB",
    "—Ä.": "RUB",
    "—Ä—É–±": "RUB",
    "‚Ç∏": "KZT",
    "—Ç–≥": "KZT",
    "$": "USD",
    "‚Ç¨": "EUR",
    "¬£": "GBP",
    "‚Çæ": "GEL",
}


_CURRENCY_TOKENS = {
    "rub": "RUB",
    "rur": "RUB",
    "—Ä–æ—Å. —Ä—É–±": "RUB",
    "—Ä–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—É–±–ª—å": "RUB",
    "—Ç–µ–Ω–≥–µ": "KZT",
    "–∫–∞–∑–∞—Ö—Å—Ç–∞–Ω": "KZT",
    "kzt": "KZT",
    "byn": "BYN",
    "–±–µ–ª. —Ä—É–±": "BYN",
    "som": "KGS",
    "kgs": "KGS",
    "—Å–æ–º": "KGS",
    "usd": "USD",
    "eur": "EUR",
    "gbp": "GBP",
    "cny": "CNY",
    "chf": "CHF",
    "aed": "AED",
    "cad": "CAD",
    "aud": "AUD",
}


_KNOWN_ISO_CODES = {
    "RUB",
    "RUR",
    "USD",
    "EUR",
    "KZT",
    "BYN",
    "KGS",
    "GBP",
    "CNY",
    "CHF",
    "AED",
    "CAD",
    "AUD",
    "GEL",
}


async def main() -> None:
    bot = LedgerFoxBot.from_env()
    await bot.run()


if __name__ == "__main__":
    asyncio.run(main())
